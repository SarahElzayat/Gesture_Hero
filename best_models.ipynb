{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "88TYUAYQQRs2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction\n",
    "This experiment developed a system that is designed to facilitate communication between people who have vocal-auditory disability. The experiment has machine learning techniques to perform the due process of recognition of hand gestures of the Colombian sign language, recognizing the numbers from 0 to 5 and the vowels. \n",
    "\n",
    "This experiment works through 4 stages: taking photographs, pre-processing the photo, extracting the characteristics of the photo and finally performs the classification process for the identification of the gesture being carried out. \n",
    "The image is captured by any camera that has a good quality shot. Then move on to the next stage of pre-processing, where you want to clean the techniques to remove the shadow, the background and leave the image clean to perform the process of segmentation where the process of eliminating the noises that this pose takes place. \n",
    "\n",
    "At the stage of extraction of characteristics, it extracts the characteristics of the image that give us the mathematical methods like: Moments of Hu, ellipticals of Fourier, histograms oriented to gradients (HOG) and geometric characteristics. \n",
    "Finally, using the vector support machine classifier (SVM) you get the value of the sign, if it is a number or a vowel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "j-nvfI7qQRs4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exploratory Analysis\n",
    "To begin this exploratory analysis, first import libraries and define functions perform pre-processing and extracting features ` Cv2` (OpenCV), ` Sklearn`, `scipy`, `skimage`. \n",
    "Use the `pyefd` library to get the Fourier ellipticals.\n",
    "For the classification processes the library of `sklearn` was used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeglP3nmQhfw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/kaggle\"\n",
    "# !kaggle datasets download -d evernext10/hand-gesture-of-the-colombian-sign-language\n",
    "# !unzip '/content/kaggle/hand-gesture-of-the-colombian-sign-language.zip' -d '/content/kaggle/dataset'\n",
    "# !rm -rf /content/kaggle/dataset/men/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xH-H6nVQRs4",
    "outputId": "f45bd6e5-c1d6-4f58-9193-355e9b296e0e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install pyefd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AbsJ6-jvQRs5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# import cv2\n",
    "import cv2 as cv2\n",
    "# import cv2.cv2 as cv2\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "import imageio\n",
    "from os import walk\n",
    "from pyefd import elliptic_fourier_descriptors\n",
    "from skimage import feature\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV  \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns;\n",
    "import collections\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import skew\n",
    "from skimage import segmentation\n",
    "from skimage.filters import sobel\n",
    "sns.set()\n",
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SURMarqrQRs5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There is 0 csv file in the current version of the dataset:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MeDg1lXWQRs5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next hidden code cells define functions for plotting data. Click on the \"Code\" button in the published kernel to reveal the hidden code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eO9FsGYxpCHt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !rm -rf /content/kaggle/dataset/dataset\n",
    "def plt_t(title, img, cmap=None):\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5wdYM_99QRs6",
    "outputId": "dfe254c4-3a89-43f4-c267-456c6ad49c3a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# Pre-processing of the images is done\n",
    "base = './'\n",
    "def segm_1(img_rgb):\n",
    "  img_ycrcb = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2YCR_CB)  \n",
    "  ycrcbmin = np.array((0, 133, 77))\n",
    "  ycrcbmax = np.array((255, 173, 127))\n",
    "  skin_ycrcb = cv2.inRange(img_ycrcb, ycrcbmin, ycrcbmax)\n",
    "  kernel = np.ones((5, 5), np.uint8)\n",
    "  img_erode = cv2.erode(skin_ycrcb, kernel, iterations=2)  \n",
    "  holesimg = ndi.binary_fill_holes(img_erode).astype(np.int) \n",
    "  return holesimg\n",
    "\n",
    "def segm_2(img_rgb):\n",
    "  lab = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2LAB)\n",
    "  # bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "  _, _, r = cv2.split(lab)\n",
    "  r = cv2.normalize(r, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "  elevation_map = sobel(r)\n",
    "  markers = np.zeros_like(r)\n",
    "  markers[r < 30] = 1\n",
    "  markers[r > 150] = 2\n",
    "  segmentation_coins = cv2.watershed(img_rgb, markers)\n",
    "  return segmentation_coins\n",
    "\n",
    "\n",
    "def segm_3(img_rgb):\n",
    "  blur = cv2.GaussianBlur(img_rgb, (3, 3), 0)\n",
    "\n",
    "  # Convert image to LAB color space\n",
    "  lab = cv2.cvtColor(blur, cv2.COLOR_BGR2LAB)\n",
    "  # bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "  # lab = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2LAB)\n",
    "  clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "  lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n",
    "\n",
    "  # Convert image back to BGR color space\n",
    "  bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "  # it was 50, 190\n",
    "  canny = cv2.Canny(bgr, 10, 170)\n",
    "  # opening = cv2.morphologyEx(canny, cv2.MORPH_OPEN, (3, 3))\n",
    "  return canny\n",
    "\n",
    "def is_lightened(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    _, _, v = cv2.split(hsv)\n",
    "    quantiles = np.quantile(v, [0.5])\n",
    "    # print(quantiles)\n",
    "    return quantiles[0] > 230\n",
    "\n",
    "def segm_4(img):\n",
    "    # Convert image to LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    # Apply CLAHE to enhance contrast in LAB lightness channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=10.0, tileGridSize=(18,18))\n",
    "    lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n",
    "\n",
    "    # Convert image back to BGR color space\n",
    "    bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    # Display original and preprocessed images side by side\n",
    "    # apply cannny edge detection\n",
    "    edges = cv2.Canny(bgr, 100, 200)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1, 8))\n",
    "    opening = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    from skimage import morphology\n",
    "    holesimg = ndi.binary_fill_holes(opening).astype(np.int8)\n",
    "    bin = holesimg>0.5\n",
    "    a = morphology.remove_small_objects(bin, 1000)\n",
    "    return (a*255).astype(np.uint8)\n",
    "\n",
    "def segm_5(img):\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mk = img_hsv > np.array([0, 0, 230])\n",
    "    mk = mk.astype(np.float32)\n",
    "    mask = (mk *0.5 + 0.5)\n",
    "    masked = (mask* img_hsv)\n",
    "    img_partly_darken = cv2.cvtColor(masked, cv2.COLOR_HSV2RGB)\n",
    "    green_mask = (img_partly_darken[:, :, 0] > img_partly_darken[:, :, 1]).astype(np.float32)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    img_erode = cv2.erode(green_mask, kernel, iterations=2)  \n",
    "    holesimg = ndi.binary_fill_holes(img_erode).astype(np.int) \n",
    "    return holesimg\n",
    "  \n",
    "def segm_6(img):\n",
    "#     blur the img then turn it into gray scale\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    gray = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "def segm_7(img):\n",
    "    # Convert BGR to HSV color space\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "    # Split HSV image into separate channels\n",
    "    _, _, B_channel = cv2.split(hsv_img)\n",
    "    _, trr2 = cv2.threshold(\n",
    "        B_channel, 1, 1.0, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    trr2 = ndi.binary_fill_holes(trr2).astype(np.int8)\n",
    "    masked_data = cv2.bitwise_and(img, img, mask=trr2)\n",
    "    return cv2.cvtColor(masked_data, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "  \n",
    "def make_to_left(img):\n",
    "  a = img.sum(axis=0)\n",
    "  a = a / a.max()\n",
    "  if(a[:int(len(a)//8)].sum() < a[int(len(a)*7//8):].sum()):\n",
    "    # flip the image\n",
    "    return cv2.flip(img, 1)\n",
    "  return img\n",
    "\n",
    "def preprocess(direc):\n",
    "  try:\n",
    "    img_rgb = cv2.imread(direc)\n",
    "    img_rgb = cv2.resize(img_rgb, (461, 260))\n",
    "  except:\n",
    "    print(\"cant read image\")\n",
    "    return None\n",
    "  # if(is_lightened(img_rgb)):\n",
    "  #   holesimg = segm_5(img_rgb)\n",
    "  # else:\n",
    "  #   holesimg = segm_1(img_rgb)\n",
    "  holesimg = segm_7(img_rgb)\n",
    "  # holesimg = segm_4(img_rgb)\n",
    "  # holesimg = segm_6(img_rgb)\n",
    "  holesimg = make_to_left(holesimg)\n",
    "  return holesimg\n",
    "\n",
    "\n",
    "def ImageSegmentation():\n",
    "    path_IS = r\"./Image-Segmentation2\"\n",
    "    if not os.path.exists(path_IS):\n",
    "        os.makedirs(path_IS)\n",
    "    lstFiles = []  # nombre de imagenes\n",
    "    path = r\"./dataset\"\n",
    "\n",
    "    for (path, _, archivos) in walk(path):\n",
    "        # print(path)\n",
    "        for arch in archivos:\n",
    "            (nomArch, ext) = os.path.splitext(arch)\n",
    "            if (ext == \".JPG\"):\n",
    "                # label = path.split(\"\\\\\")[-1]\n",
    "                # print(label)\n",
    "                lstFiles.append(nomArch + ext)\n",
    "                direc = path + \"/\" + nomArch + ext\n",
    "                name =  nomArch + ext\n",
    "                # print(path + \"/\" + nomArch + ext)\n",
    "                \n",
    "                holesimg = preprocess(direc)\n",
    "                if(holesimg is None):\n",
    "                  continue\n",
    "                # holesimage = segm_3(holesimg)\n",
    "                imageio.imwrite(os.path.join(path_IS, name), holesimg)\n",
    "                \n",
    "ImageSegmentation()\n",
    "# plt.show()\n",
    "# img = cv2.imread(r\"dataset\\men\\1\\1_men (1).JPG\")\n",
    "# img_p = preprocess(r\"dataset\\men\\1\\1_men (2).JPG\")\n",
    "# plt_t('',img_p,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# Pre-processing of the images is done\n",
    "base = './'\n",
    "def segm_1(img_rgb):\n",
    "  img_ycrcb = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2YCR_CB)  \n",
    "  ycrcbmin = np.array((0, 133, 77))\n",
    "  ycrcbmax = np.array((255, 173, 127))\n",
    "  skin_ycrcb = cv2.inRange(img_ycrcb, ycrcbmin, ycrcbmax)\n",
    "  kernel = np.ones((5, 5), np.uint8)\n",
    "  img_erode = cv2.erode(skin_ycrcb, kernel, iterations=2)  \n",
    "  holesimg = ndi.binary_fill_holes(img_erode).astype(np.int) \n",
    "  return holesimg\n",
    "\n",
    "def segm_2(img_rgb):\n",
    "  lab = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2LAB)\n",
    "  # bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "  _, _, r = cv2.split(lab)\n",
    "  r = cv2.normalize(r, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "  elevation_map = sobel(r)\n",
    "  markers = np.zeros_like(r)\n",
    "  markers[r < 30] = 1\n",
    "  markers[r > 150] = 2\n",
    "  segmentation_coins = cv2.watershed(img_rgb, markers)\n",
    "  return segmentation_coins\n",
    "\n",
    "\n",
    "def segm_3(img_rgb):\n",
    "  blur = cv2.GaussianBlur(img_rgb, (3, 3), 0)\n",
    "\n",
    "  # Convert image to LAB color space\n",
    "  lab = cv2.cvtColor(blur, cv2.COLOR_BGR2LAB)\n",
    "  # bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "  # lab = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2LAB)\n",
    "  clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "  lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n",
    "\n",
    "  # Convert image back to BGR color space\n",
    "  bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "  # it was 50, 190\n",
    "  canny = cv2.Canny(bgr, 10, 170)\n",
    "  # opening = cv2.morphologyEx(canny, cv2.MORPH_OPEN, (3, 3))\n",
    "  return canny\n",
    "\n",
    "def is_lightened(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    _, _, v = cv2.split(hsv)\n",
    "    quantiles = np.quantile(v, [0.5])\n",
    "    # print(quantiles)\n",
    "    return quantiles[0] > 230\n",
    "\n",
    "def segm_4(img):\n",
    "    # Convert image to LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    # Apply CLAHE to enhance contrast in LAB lightness channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=10.0, tileGridSize=(18,18))\n",
    "    lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n",
    "\n",
    "    # Convert image back to BGR color space\n",
    "    bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    # Display original and preprocessed images side by side\n",
    "    # apply cannny edge detection\n",
    "    edges = cv2.Canny(bgr, 100, 200)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1, 8))\n",
    "    opening = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    from skimage import morphology\n",
    "    holesimg = ndi.binary_fill_holes(opening).astype(np.int8)\n",
    "    bin = holesimg>0.5\n",
    "    a = morphology.remove_small_objects(bin, 1000)\n",
    "    return (a*255).astype(np.uint8)\n",
    "\n",
    "def segm_5(img):\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mk = img_hsv > np.array([0, 0, 230])\n",
    "    mk = mk.astype(np.float32)\n",
    "    mask = (mk *0.5 + 0.5)\n",
    "    masked = (mask* img_hsv)\n",
    "    img_partly_darken = cv2.cvtColor(masked, cv2.COLOR_HSV2RGB)\n",
    "    green_mask = (img_partly_darken[:, :, 0] > img_partly_darken[:, :, 1]).astype(np.float32)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    img_erode = cv2.erode(green_mask, kernel, iterations=2)  \n",
    "    holesimg = ndi.binary_fill_holes(img_erode).astype(np.int) \n",
    "    return holesimg\n",
    "  \n",
    "def segm_6(img):\n",
    "#     blur the img then turn it into gray scale\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    gray = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "\n",
    "def make_to_left(img):\n",
    "  a = img.sum(axis=0)\n",
    "  a = a / a.max()\n",
    "  if(a[:int(len(a)//8)].sum() < a[int(len(a)*7//8):].sum()):\n",
    "    # flip the image\n",
    "    return cv2.flip(img, 1)\n",
    "  return img\n",
    "\n",
    "def preprocess(direc):\n",
    "  try:\n",
    "    img_rgb = cv2.imread(direc)\n",
    "    img_rgb = cv2.resize(img_rgb, (461, 260))\n",
    "  except:\n",
    "    print(\"cant read image\")\n",
    "    return None\n",
    "  # if(is_lightened(img_rgb)):\n",
    "  #   holesimg = segm_5(img_rgb)\n",
    "  # else:\n",
    "  #   holesimg = segm_1(img_rgb)\n",
    "  holesimg = segm_3(img_rgb)\n",
    "  # holesimg = segm_4(img_rgb)\n",
    "  # holesimg = segm_6(img_rgb)\n",
    "  holesimg = make_to_left(holesimg)\n",
    "  return holesimg\n",
    "\n",
    "\n",
    "def ImageSegmentation():\n",
    "    path_IS = r\"./Image-Segmentation2\"\n",
    "    if not os.path.exists(path_IS):\n",
    "        os.makedirs(path_IS)\n",
    "    lstFiles = []  # nombre de imagenes\n",
    "    path = r\"./dataset\"\n",
    "\n",
    "    for (path, _, archivos) in walk(path):\n",
    "        # print(path)\n",
    "        for arch in archivos:\n",
    "            (nomArch, ext) = os.path.splitext(arch)\n",
    "            if (ext == \".JPG\"):\n",
    "                label = path.split(\"\\\\\")[-1]\n",
    "                # print(label)\n",
    "                lstFiles.append(nomArch + ext)\n",
    "                direc = path + \"/\" + nomArch + ext\n",
    "                name =  label + \"_\" + nomArch + ext\n",
    "                # print(path + \"/\" + nomArch + ext)\n",
    "                \n",
    "                holesimg = preprocess(direc)\n",
    "                if(holesimg is None):\n",
    "                  continue\n",
    "                # holesimage = segm_3(holesimg)\n",
    "                imageio.imwrite(os.path.join(path_IS, name), holesimg)\n",
    "                \n",
    "ImageSegmentation()\n",
    "# plt.show()\n",
    "# img = cv2.imread(r\"dataset\\men\\1\\1_men (1).JPG\")\n",
    "# img_p = preprocess(r\"dataset\\men\\1\\1_men (2).JPG\")\n",
    "# plt_t('',img_p,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# extratct sift key points and descriptors and draw them\n",
    "def extract_sift(img):\n",
    "  # sift = cv2.xfeatures2d.SIFT_create()\n",
    "  orb = cv2.ORB_create()\n",
    "\n",
    "  kp, des = orb.detectAndCompute(img, None)\n",
    "  return kp, des\n",
    "\n",
    "def draw_sift(img, kp):\n",
    "    img = cv2.drawKeypoints(img, kp, None)\n",
    "    return img\n",
    "\n",
    "img = cv2.imread(r\"Image-Segmentation2/0_men (3).JPG\")\n",
    "img = cv2.resize(img, (461, 260))\n",
    "kp, des = extract_sift(img)\n",
    "img = draw_sift(img, kp)\n",
    "plt.imshow(img)\n",
    "\n",
    "\n",
    "\n",
    "base = \"./\"\n",
    "def CountFlips():\n",
    "    print(\"CountFlips\\n\")\n",
    "    path_EF = base + r\"Feature-Extraction\"\n",
    "    if not os.path.exists(path_EF):\n",
    "        os.makedirs(path_EF)\n",
    "\n",
    "    file = open(base + r\"Feature-Extraction/CountFlips.txt\", \"w\")\n",
    "    lstFiles = []  # nombre de imagenes\n",
    "    path = r\"./Image-Segmentation2\"\n",
    "    all_lings = []\n",
    "    for (path, _, archivos) in walk(path):\n",
    "        for arch in archivos:\n",
    "            (nomArch, ext) = os.path.splitext(arch)\n",
    "            if (ext == \".JPG\"):\n",
    "                direc = path + \"/\" + nomArch + ext\n",
    "                name = nomArch + ext\n",
    "                # print(nomArch + ext)\n",
    "                img_binary = cv2.imread(direc)\n",
    "                kp, des = extract_sift(img_binary)\n",
    "                all_lings.append(len(kp))\n",
    "\n",
    "    all_lings = np.array(all_lings)\n",
    "    print(all_lings.mean())\n",
    "    print(all_lings.std())\n",
    "    print(all_lings.max())\n",
    "    print(all_lings.min())\n",
    "CountFlips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"./\"\n",
    "def VHist():\n",
    "    print(\"VHIST\\n\")\n",
    "    path_EF = base + r\"Feature-Extraction\"\n",
    "    if not os.path.exists(path_EF):\n",
    "        os.makedirs(path_EF)\n",
    "\n",
    "    file = open(base + r\"Feature-Extraction/VHIST.txt\", \"w\")\n",
    "    path = r\"./Image-Segmentation2\"\n",
    "    for (path, _, archivos) in walk(path):\n",
    "        for arch in archivos:\n",
    "            (nomArch, ext) = os.path.splitext(arch)\n",
    "            if (ext == \".JPG\"):\n",
    "                direc = path + \"/\" + nomArch + ext\n",
    "                name = nomArch + ext\n",
    "                # print(nomArch + ext)\n",
    "                img_binary = cv2.imread(direc)\n",
    "                img_binary = cv2.cvtColor(img_binary, cv2.COLOR_BGR2GRAY)\n",
    "                # get vertical histogram\n",
    "                ss = img_binary.sum(axis=1)\n",
    "                print(ss[0])\n",
    "                file.write(name)    \n",
    "                for item in ss:\n",
    "                    file.write(\",%.4f\" % item)\n",
    "                file.write(\",\" + name[0] + \"\\n\")\n",
    "    file.close()\n",
    "VHist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The Fourier elliptical features are extracted from each of the images and we proceed to save them in a. txt file.\n",
    "base = \"./\"\n",
    "def CountFlips():\n",
    "    print(\"CountFlips\\n\")\n",
    "    path_EF = base + r\"Feature-Extraction\"\n",
    "    if not os.path.exists(path_EF):\n",
    "        os.makedirs(path_EF)\n",
    "\n",
    "    file = open(base + r\"Feature-Extraction/CountFlips.txt\", \"w\")\n",
    "    lstFiles = []  # nombre de imagenes\n",
    "    path = r\"./Image-Segmentation\"\n",
    "    for (path, _, archivos) in walk(path):\n",
    "        for arch in archivos:\n",
    "            (nomArch, ext) = os.path.splitext(arch)\n",
    "            if (ext == \".JPG\"):\n",
    "                lstFiles.append(nomArch + ext)\n",
    "                direc = path + \"/\" + nomArch + ext\n",
    "                name = nomArch + ext\n",
    "                print(nomArch + ext)\n",
    "                img_binary = cv2.imread(direc)\n",
    "\n",
    "                img_binary = cv2.cvtColor(img_binary, cv2.COLOR_BGR2GRAY)\n",
    "                # count the number of black/white flips on the column of the image \n",
    "                counts = []\n",
    "                for col in range(0,img_binary.shape[1],10):\n",
    "                    first = img_binary[0, col]\n",
    "                    count =0\n",
    "                    for row in range(img_binary.shape[0]):\n",
    "                        if img_binary[row, col] != first:\n",
    "                            count += 1\n",
    "                            first = img_binary[row, col]\n",
    "                        \n",
    "                    counts.append(count)\n",
    "                file.write(name)    \n",
    "                for item in range(len(counts)):\n",
    "                    file.write(\",%.4f\" % counts[item])\n",
    "                file.write(\",\" + name[0] + \"\\n\")\n",
    "\n",
    "    file.close()\n",
    "CountFlips()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NwNGTksVQRs6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EF\n",
      "\n",
      "0_men (1).JPG\n",
      "0_men (10).JPG\n",
      "0_men (100).JPG\n",
      "0_men (101).JPG\n",
      "0_men (102).JPG\n",
      "0_men (103).JPG\n",
      "0_men (104).JPG\n",
      "0_men (105).JPG\n",
      "0_men (106).JPG\n",
      "0_men (107).JPG\n",
      "0_men (108).JPG\n",
      "0_men (109).JPG\n",
      "0_men (11).JPG\n",
      "0_men (110).JPG\n",
      "0_men (111).JPG\n",
      "0_men (112).JPG\n",
      "0_men (113).JPG\n",
      "0_men (114).JPG\n",
      "0_men (115).JPG\n",
      "0_men (116).JPG\n",
      "0_men (117).JPG\n",
      "0_men (118).JPG\n",
      "0_men (119).JPG\n",
      "0_men (12).JPG\n",
      "0_men (120).JPG\n",
      "0_men (121).JPG\n",
      "0_men (122).JPG\n",
      "0_men (123).JPG\n",
      "0_men (124).JPG\n",
      "0_men (125).JPG\n",
      "0_men (126).JPG\n",
      "0_men (127).JPG\n",
      "0_men (128).JPG\n",
      "0_men (129).JPG\n",
      "0_men (13).JPG\n",
      "0_men (130).JPG\n",
      "0_men (131).JPG\n",
      "0_men (132).JPG\n",
      "0_men (133).JPG\n",
      "0_men (134).JPG\n",
      "0_men (135).JPG\n",
      "0_men (136).JPG\n",
      "0_men (137).JPG\n",
      "0_men (138).JPG\n",
      "0_men (139).JPG\n",
      "0_men (14).JPG\n",
      "0_men (140).JPG\n",
      "0_men (141).JPG\n",
      "0_men (142).JPG\n",
      "0_men (143).JPG\n",
      "0_men (144).JPG\n",
      "0_men (145).JPG\n",
      "0_men (146).JPG\n",
      "0_men (147).JPG\n",
      "0_men (148).JPG\n",
      "0_men (149).JPG\n",
      "0_men (15).JPG\n",
      "0_men (150).JPG\n",
      "0_men (151).JPG\n",
      "0_men (152).JPG\n",
      "0_men (153).JPG\n",
      "0_men (154).JPG\n",
      "0_men (155).JPG\n",
      "0_men (156).JPG\n",
      "0_men (157).JPG\n",
      "0_men (158).JPG\n",
      "0_men (159).JPG\n",
      "0_men (16).JPG\n",
      "0_men (160).JPG\n",
      "0_men (161).JPG\n",
      "0_men (162).JPG\n",
      "0_men (163).JPG\n",
      "0_men (164).JPG\n",
      "0_men (165).JPG\n",
      "0_men (166).JPG\n",
      "0_men (167).JPG\n",
      "0_men (168).JPG\n",
      "0_men (169).JPG\n",
      "0_men (17).JPG\n",
      "0_men (170).JPG\n",
      "0_men (171).JPG\n",
      "0_men (172).JPG\n",
      "0_men (18).JPG\n",
      "0_men (19).JPG\n",
      "0_men (2).JPG\n",
      "0_men (20).JPG\n",
      "0_men (21).JPG\n",
      "0_men (22).JPG\n",
      "0_men (23).JPG\n",
      "0_men (24).JPG\n",
      "0_men (25).JPG\n",
      "0_men (26).JPG\n",
      "0_men (27).JPG\n",
      "0_men (28).JPG\n",
      "0_men (29).JPG\n",
      "0_men (3).JPG\n",
      "0_men (30).JPG\n",
      "0_men (31).JPG\n",
      "0_men (32).JPG\n",
      "0_men (33).JPG\n",
      "0_men (34).JPG\n",
      "0_men (35).JPG\n",
      "0_men (36).JPG\n",
      "0_men (37).JPG\n",
      "0_men (38).JPG\n",
      "0_men (39).JPG\n",
      "0_men (4).JPG\n",
      "0_men (40).JPG\n",
      "0_men (41).JPG\n",
      "0_men (42).JPG\n",
      "0_men (43).JPG\n",
      "0_men (44).JPG\n",
      "0_men (45).JPG\n",
      "0_men (46).JPG\n",
      "0_men (47).JPG\n",
      "0_men (48).JPG\n",
      "0_men (49).JPG\n",
      "0_men (5).JPG\n",
      "0_men (50).JPG\n",
      "0_men (51).JPG\n",
      "0_men (52).JPG\n",
      "0_men (53).JPG\n",
      "0_men (54).JPG\n",
      "0_men (55).JPG\n",
      "0_men (56).JPG\n",
      "0_men (57).JPG\n",
      "0_men (58).JPG\n",
      "0_men (59).JPG\n",
      "0_men (6).JPG\n",
      "0_men (60).JPG\n",
      "0_men (61).JPG\n",
      "0_men (62).JPG\n",
      "0_men (63).JPG\n",
      "0_men (64).JPG\n",
      "0_men (65).JPG\n",
      "0_men (66).JPG\n",
      "0_men (67).JPG\n",
      "0_men (68).JPG\n",
      "0_men (69).JPG\n",
      "0_men (7).JPG\n",
      "0_men (70).JPG\n",
      "0_men (71).JPG\n",
      "0_men (72).JPG\n",
      "0_men (73).JPG\n",
      "0_men (74).JPG\n",
      "0_men (75).JPG\n",
      "0_men (76).JPG\n",
      "0_men (77).JPG\n",
      "0_men (78).JPG\n",
      "0_men (79).JPG\n",
      "0_men (8).JPG\n",
      "0_men (80).JPG\n",
      "0_men (81).JPG\n",
      "0_men (82).JPG\n",
      "0_men (83).JPG\n",
      "0_men (84).JPG\n",
      "0_men (85).JPG\n",
      "0_men (86).JPG\n",
      "0_men (87).JPG\n",
      "0_men (88).JPG\n",
      "0_men (89).JPG\n",
      "0_men (9).JPG\n",
      "0_men (90).JPG\n",
      "0_men (91).JPG\n",
      "0_men (92).JPG\n",
      "0_men (93).JPG\n",
      "0_men (94).JPG\n",
      "0_men (95).JPG\n",
      "0_men (96).JPG\n",
      "0_men (97).JPG\n",
      "0_men (98).JPG\n",
      "0_men (99).JPG\n",
      "0_woman (1).JPG\n",
      "0_woman (10).JPG\n",
      "0_woman (100).JPG\n",
      "0_woman (101).JPG\n",
      "0_woman (102).JPG\n",
      "0_woman (103).JPG\n",
      "0_woman (104).JPG\n",
      "0_woman (105).JPG\n",
      "0_woman (106).JPG\n",
      "0_woman (107).JPG\n",
      "0_woman (108).JPG\n",
      "0_woman (109).JPG\n",
      "0_woman (11).JPG\n",
      "0_woman (110).JPG\n",
      "0_woman (111).JPG\n",
      "0_woman (112).JPG\n",
      "0_woman (113).JPG\n",
      "0_woman (114).JPG\n",
      "0_woman (115).JPG\n",
      "0_woman (12).JPG\n",
      "0_woman (13).JPG\n",
      "0_woman (14).JPG\n",
      "0_woman (15).JPG\n",
      "0_woman (16).JPG\n",
      "0_woman (17).JPG\n",
      "0_woman (18).JPG\n",
      "0_woman (19).JPG\n",
      "0_woman (2).JPG\n",
      "0_woman (20).JPG\n",
      "0_woman (21).JPG\n",
      "0_woman (22).JPG\n",
      "0_woman (23).JPG\n",
      "0_woman (24).JPG\n",
      "0_woman (25).JPG\n",
      "0_woman (26).JPG\n",
      "0_woman (27).JPG\n",
      "0_woman (28).JPG\n",
      "0_woman (29).JPG\n",
      "0_woman (3).JPG\n",
      "0_woman (30).JPG\n",
      "0_woman (31).JPG\n",
      "0_woman (32).JPG\n",
      "0_woman (33).JPG\n",
      "0_woman (34).JPG\n",
      "0_woman (35).JPG\n",
      "0_woman (36).JPG\n",
      "0_woman (37).JPG\n",
      "0_woman (38).JPG\n",
      "0_woman (39).JPG\n",
      "0_woman (4).JPG\n",
      "0_woman (40).JPG\n",
      "0_woman (41).JPG\n",
      "0_woman (42).JPG\n",
      "0_woman (43).JPG\n",
      "0_woman (44).JPG\n",
      "0_woman (45).JPG\n",
      "0_woman (46).JPG\n",
      "0_woman (47).JPG\n",
      "0_woman (48).JPG\n",
      "0_woman (49).JPG\n",
      "0_woman (5).JPG\n",
      "0_woman (50).JPG\n",
      "0_woman (51).JPG\n",
      "0_woman (52).JPG\n",
      "0_woman (53).JPG\n",
      "0_woman (54).JPG\n",
      "0_woman (55).JPG\n",
      "0_woman (56).JPG\n",
      "0_woman (57).JPG\n",
      "0_woman (58).JPG\n",
      "0_woman (59).JPG\n",
      "0_woman (6).JPG\n",
      "0_woman (60).JPG\n",
      "0_woman (61).JPG\n",
      "0_woman (62).JPG\n",
      "0_woman (63).JPG\n",
      "0_woman (64).JPG\n",
      "0_woman (65).JPG\n",
      "0_woman (66).JPG\n",
      "0_woman (67).JPG\n",
      "0_woman (68).JPG\n",
      "0_woman (69).JPG\n",
      "0_woman (7).JPG\n",
      "0_woman (70).JPG\n",
      "0_woman (71).JPG\n",
      "0_woman (72).JPG\n",
      "0_woman (73).JPG\n",
      "0_woman (74).JPG\n",
      "0_woman (75).JPG\n",
      "0_woman (76).JPG\n",
      "0_woman (77).JPG\n",
      "0_woman (78).JPG\n",
      "0_woman (79).JPG\n",
      "0_woman (8).JPG\n",
      "0_woman (80).JPG\n",
      "0_woman (81).JPG\n",
      "0_woman (82).JPG\n",
      "0_woman (83).JPG\n",
      "0_woman (84).JPG\n",
      "0_woman (85).JPG\n",
      "0_woman (86).JPG\n",
      "0_woman (87).JPG\n",
      "0_woman (88).JPG\n",
      "0_woman (89).JPG\n",
      "0_woman (9).JPG\n",
      "0_woman (90).JPG\n",
      "0_woman (91).JPG\n",
      "0_woman (92).JPG\n",
      "0_woman (93).JPG\n",
      "0_woman (94).JPG\n",
      "0_woman (95).JPG\n",
      "0_woman (96).JPG\n",
      "0_woman (97).JPG\n",
      "0_woman (98).JPG\n",
      "0_woman (99).JPG\n",
      "1_men (1).JPG\n",
      "1_men (10).JPG\n",
      "1_men (100).JPG\n",
      "1_men (101).JPG\n",
      "1_men (102).JPG\n",
      "1_men (103).JPG\n",
      "1_men (104).JPG\n",
      "1_men (105).JPG\n",
      "1_men (106).JPG\n",
      "1_men (107).JPG\n",
      "1_men (108).JPG\n",
      "1_men (109).JPG\n",
      "1_men (11).JPG\n",
      "1_men (110).JPG\n",
      "1_men (111).JPG\n",
      "1_men (112).JPG\n",
      "1_men (113).JPG\n",
      "1_men (114).JPG\n",
      "1_men (115).JPG\n",
      "1_men (116).JPG\n",
      "1_men (117).JPG\n",
      "1_men (118).JPG\n",
      "1_men (119).JPG\n",
      "1_men (12).JPG\n",
      "1_men (120).JPG\n",
      "1_men (121).JPG\n",
      "1_men (122).JPG\n",
      "1_men (123).JPG\n",
      "1_men (124).JPG\n",
      "1_men (125).JPG\n",
      "1_men (126).JPG\n",
      "1_men (127).JPG\n",
      "1_men (128).JPG\n",
      "1_men (129).JPG\n",
      "1_men (13).JPG\n",
      "1_men (130).JPG\n",
      "1_men (131).JPG\n",
      "1_men (132).JPG\n",
      "1_men (133).JPG\n",
      "1_men (134).JPG\n",
      "1_men (135).JPG\n",
      "1_men (136).JPG\n",
      "1_men (137).JPG\n",
      "1_men (138).JPG\n",
      "1_men (139).JPG\n",
      "1_men (14).JPG\n",
      "1_men (140).JPG\n",
      "1_men (141).JPG\n",
      "1_men (142).JPG\n",
      "1_men (143).JPG\n",
      "1_men (144).JPG\n",
      "1_men (145).JPG\n",
      "1_men (146).JPG\n",
      "1_men (147).JPG\n",
      "1_men (148).JPG\n",
      "1_men (149).JPG\n",
      "1_men (15).JPG\n",
      "1_men (150).JPG\n",
      "1_men (151).JPG\n",
      "1_men (152).JPG\n",
      "1_men (153).JPG\n",
      "1_men (154).JPG\n",
      "1_men (155).JPG\n",
      "1_men (156).JPG\n",
      "1_men (157).JPG\n",
      "1_men (158).JPG\n",
      "1_men (159).JPG\n",
      "1_men (16).JPG\n",
      "1_men (160).JPG\n",
      "1_men (161).JPG\n",
      "1_men (162).JPG\n",
      "1_men (163).JPG\n",
      "1_men (164).JPG\n",
      "1_men (165).JPG\n",
      "1_men (166).JPG\n",
      "1_men (167).JPG\n",
      "1_men (168).JPG\n",
      "1_men (169).JPG\n",
      "1_men (17).JPG\n",
      "1_men (170).JPG\n",
      "1_men (171).JPG\n",
      "1_men (172).JPG\n",
      "1_men (173).JPG\n",
      "1_men (174).JPG\n",
      "1_men (175).JPG\n",
      "1_men (18).JPG\n",
      "1_men (19).JPG\n",
      "1_men (2).JPG\n",
      "1_men (20).JPG\n",
      "1_men (21).JPG\n",
      "1_men (22).JPG\n",
      "1_men (23).JPG\n",
      "1_men (24).JPG\n",
      "1_men (25).JPG\n",
      "1_men (26).JPG\n",
      "1_men (27).JPG\n",
      "1_men (28).JPG\n",
      "1_men (29).JPG\n",
      "1_men (3).JPG\n",
      "1_men (30).JPG\n",
      "1_men (31).JPG\n",
      "1_men (32).JPG\n",
      "1_men (33).JPG\n",
      "1_men (34).JPG\n",
      "1_men (35).JPG\n",
      "1_men (36).JPG\n",
      "1_men (37).JPG\n",
      "1_men (38).JPG\n",
      "1_men (39).JPG\n",
      "1_men (4).JPG\n",
      "1_men (40).JPG\n",
      "1_men (41).JPG\n",
      "1_men (42).JPG\n",
      "1_men (43).JPG\n",
      "1_men (44).JPG\n",
      "1_men (45).JPG\n",
      "1_men (46).JPG\n",
      "1_men (47).JPG\n",
      "1_men (48).JPG\n",
      "1_men (49).JPG\n",
      "1_men (5).JPG\n",
      "1_men (50).JPG\n",
      "1_men (51).JPG\n",
      "1_men (52).JPG\n",
      "1_men (53).JPG\n",
      "1_men (54).JPG\n",
      "1_men (55).JPG\n",
      "1_men (56).JPG\n",
      "1_men (57).JPG\n",
      "1_men (58).JPG\n",
      "1_men (59).JPG\n",
      "1_men (6).JPG\n",
      "1_men (60).JPG\n",
      "1_men (61).JPG\n",
      "1_men (62).JPG\n",
      "1_men (63).JPG\n",
      "1_men (64).JPG\n",
      "1_men (65).JPG\n",
      "1_men (66).JPG\n",
      "1_men (67).JPG\n",
      "1_men (68).JPG\n",
      "1_men (69).JPG\n",
      "1_men (7).JPG\n",
      "1_men (70).JPG\n",
      "1_men (71).JPG\n",
      "1_men (72).JPG\n",
      "1_men (73).JPG\n",
      "1_men (74).JPG\n",
      "1_men (75).JPG\n",
      "1_men (76).JPG\n",
      "1_men (77).JPG\n",
      "1_men (78).JPG\n",
      "1_men (79).JPG\n",
      "1_men (8).JPG\n",
      "1_men (80).JPG\n",
      "1_men (81).JPG\n",
      "1_men (82).JPG\n",
      "1_men (83).JPG\n",
      "1_men (84).JPG\n",
      "1_men (85).JPG\n",
      "1_men (86).JPG\n",
      "1_men (87).JPG\n",
      "1_men (88).JPG\n",
      "1_men (89).JPG\n",
      "1_men (9).JPG\n",
      "1_men (90).JPG\n",
      "1_men (91).JPG\n",
      "1_men (92).JPG\n",
      "1_men (93).JPG\n",
      "1_men (94).JPG\n",
      "1_men (95).JPG\n",
      "1_men (96).JPG\n",
      "1_men (97).JPG\n",
      "1_men (98).JPG\n",
      "1_men (99).JPG\n",
      "1_woman (1).JPG\n",
      "1_woman (10).JPG\n",
      "1_woman (100).JPG\n",
      "1_woman (101).JPG\n",
      "1_woman (102).JPG\n",
      "1_woman (103).JPG\n",
      "1_woman (104).JPG\n",
      "1_woman (105).JPG\n",
      "1_woman (106).JPG\n",
      "1_woman (107).JPG\n",
      "1_woman (108).JPG\n",
      "1_woman (109).JPG\n",
      "1_woman (11).JPG\n",
      "1_woman (110).JPG\n",
      "1_woman (111).JPG\n",
      "1_woman (112).JPG\n",
      "1_woman (113).JPG\n",
      "1_woman (114).JPG\n",
      "1_woman (115).JPG\n",
      "1_woman (116).JPG\n",
      "1_woman (117).JPG\n",
      "1_woman (118).JPG\n",
      "1_woman (119).JPG\n",
      "1_woman (12).JPG\n",
      "1_woman (120).JPG\n",
      "1_woman (121).JPG\n",
      "1_woman (122).JPG\n",
      "1_woman (123).JPG\n",
      "1_woman (124).JPG\n",
      "1_woman (125).JPG\n",
      "1_woman (13).JPG\n",
      "1_woman (14).JPG\n",
      "1_woman (15).JPG\n",
      "1_woman (16).JPG\n",
      "1_woman (17).JPG\n",
      "1_woman (18).JPG\n",
      "1_woman (19).JPG\n",
      "1_woman (2).JPG\n",
      "1_woman (20).JPG\n",
      "1_woman (21).JPG\n",
      "1_woman (22).JPG\n",
      "1_woman (23).JPG\n",
      "1_woman (24).JPG\n",
      "1_woman (25).JPG\n",
      "1_woman (26).JPG\n",
      "1_woman (27).JPG\n",
      "1_woman (28).JPG\n",
      "1_woman (29).JPG\n",
      "1_woman (3).JPG\n",
      "1_woman (30).JPG\n",
      "1_woman (31).JPG\n",
      "1_woman (32).JPG\n",
      "1_woman (33).JPG\n",
      "1_woman (34).JPG\n",
      "1_woman (35).JPG\n",
      "1_woman (36).JPG\n",
      "1_woman (37).JPG\n",
      "1_woman (38).JPG\n",
      "1_woman (39).JPG\n",
      "1_woman (4).JPG\n",
      "1_woman (40).JPG\n",
      "1_woman (41).JPG\n",
      "1_woman (42).JPG\n",
      "1_woman (43).JPG\n",
      "1_woman (44).JPG\n",
      "1_woman (45).JPG\n",
      "1_woman (46).JPG\n",
      "1_woman (47).JPG\n",
      "1_woman (48).JPG\n",
      "1_woman (49).JPG\n",
      "1_woman (5).JPG\n",
      "1_woman (50).JPG\n",
      "1_woman (51).JPG\n",
      "1_woman (52).JPG\n",
      "1_woman (53).JPG\n",
      "1_woman (54).JPG\n",
      "1_woman (55).JPG\n",
      "1_woman (56).JPG\n",
      "1_woman (57).JPG\n",
      "1_woman (58).JPG\n",
      "1_woman (59).JPG\n",
      "1_woman (6).JPG\n",
      "1_woman (60).JPG\n",
      "1_woman (61).JPG\n",
      "1_woman (62).JPG\n",
      "1_woman (63).JPG\n",
      "1_woman (64).JPG\n",
      "1_woman (65).JPG\n",
      "1_woman (66).JPG\n",
      "1_woman (67).JPG\n",
      "1_woman (68).JPG\n",
      "1_woman (69).JPG\n",
      "1_woman (7).JPG\n",
      "1_woman (70).JPG\n",
      "1_woman (71).JPG\n",
      "1_woman (72).JPG\n",
      "1_woman (73).JPG\n",
      "1_woman (74).JPG\n",
      "1_woman (75).JPG\n",
      "1_woman (76).JPG\n",
      "1_woman (77).JPG\n",
      "1_woman (78).JPG\n",
      "1_woman (79).JPG\n",
      "1_woman (8).JPG\n",
      "1_woman (80).JPG\n",
      "1_woman (81).JPG\n",
      "1_woman (82).JPG\n",
      "1_woman (83).JPG\n",
      "1_woman (84).JPG\n",
      "1_woman (85).JPG\n",
      "1_woman (86).JPG\n",
      "1_woman (87).JPG\n",
      "1_woman (88).JPG\n",
      "1_woman (89).JPG\n",
      "1_woman (9).JPG\n",
      "1_woman (90).JPG\n",
      "1_woman (91).JPG\n",
      "1_woman (92).JPG\n",
      "1_woman (93).JPG\n",
      "1_woman (94).JPG\n",
      "1_woman (95).JPG\n",
      "1_woman (96).JPG\n",
      "1_woman (97).JPG\n",
      "1_woman (98).JPG\n",
      "1_woman (99).JPG\n",
      "2_men (1).JPG\n",
      "2_men (100).JPG\n",
      "2_men (101).JPG\n",
      "2_men (102).JPG\n",
      "2_men (103).JPG\n",
      "2_men (104).JPG\n",
      "2_men (105).JPG\n",
      "2_men (106).JPG\n",
      "2_men (109).JPG\n",
      "2_men (11).JPG\n",
      "2_men (110).JPG\n",
      "2_men (111).JPG\n",
      "2_men (112).JPG\n",
      "2_men (113).JPG\n",
      "2_men (114).JPG\n",
      "2_men (115).JPG\n",
      "2_men (116).JPG\n",
      "2_men (117).JPG\n",
      "2_men (118).JPG\n",
      "2_men (119).JPG\n",
      "2_men (12).JPG\n",
      "2_men (120).JPG\n",
      "2_men (121).JPG\n",
      "2_men (122).JPG\n",
      "2_men (123).JPG\n",
      "2_men (124).JPG\n",
      "2_men (125).JPG\n",
      "2_men (126).JPG\n",
      "2_men (127).JPG\n",
      "2_men (128).JPG\n",
      "2_men (129).JPG\n",
      "2_men (13).JPG\n",
      "2_men (130).JPG\n",
      "2_men (131).JPG\n",
      "2_men (132).JPG\n",
      "2_men (133).JPG\n",
      "2_men (134).JPG\n",
      "2_men (135).JPG\n",
      "2_men (136).JPG\n",
      "2_men (137).JPG\n",
      "2_men (138).JPG\n",
      "2_men (139).JPG\n",
      "2_men (14).JPG\n",
      "2_men (140).JPG\n",
      "2_men (141).JPG\n",
      "2_men (142).JPG\n",
      "2_men (143).JPG\n",
      "2_men (144).JPG\n",
      "2_men (145).JPG\n",
      "2_men (146).JPG\n",
      "2_men (147).JPG\n",
      "2_men (148).JPG\n",
      "2_men (149).JPG\n",
      "2_men (15).JPG\n",
      "2_men (150).JPG\n",
      "2_men (151).JPG\n",
      "2_men (152).JPG\n",
      "2_men (153).JPG\n",
      "2_men (154).JPG\n",
      "2_men (155).JPG\n",
      "2_men (156).JPG\n",
      "2_men (157).JPG\n",
      "2_men (158).JPG\n",
      "2_men (159).JPG\n",
      "2_men (16).JPG\n",
      "2_men (160).JPG\n",
      "2_men (161).JPG\n",
      "2_men (162).JPG\n",
      "2_men (163).JPG\n",
      "2_men (164).JPG\n",
      "2_men (165).JPG\n",
      "2_men (166).JPG\n",
      "2_men (167).JPG\n",
      "2_men (168).JPG\n",
      "2_men (169).JPG\n",
      "2_men (17).JPG\n",
      "2_men (170).JPG\n",
      "2_men (171).JPG\n",
      "2_men (172).JPG\n",
      "2_men (173).JPG\n",
      "2_men (174).JPG\n",
      "2_men (175).JPG\n",
      "2_men (176).JPG\n",
      "2_men (177).JPG\n",
      "2_men (18).JPG\n",
      "2_men (19).JPG\n",
      "2_men (2).JPG\n",
      "2_men (20).JPG\n",
      "2_men (21).JPG\n",
      "2_men (22).JPG\n",
      "2_men (23).JPG\n",
      "2_men (24).JPG\n",
      "2_men (25).JPG\n",
      "2_men (26).JPG\n",
      "2_men (27).JPG\n",
      "2_men (28).JPG\n",
      "2_men (29).JPG\n",
      "2_men (3).JPG\n",
      "2_men (30).JPG\n",
      "2_men (31).JPG\n",
      "2_men (32).JPG\n",
      "2_men (33).JPG\n",
      "2_men (34).JPG\n",
      "2_men (35).JPG\n",
      "2_men (36).JPG\n",
      "2_men (37).JPG\n",
      "2_men (38).JPG\n",
      "2_men (39).JPG\n",
      "2_men (4).JPG\n",
      "2_men (40).JPG\n",
      "2_men (41).JPG\n",
      "2_men (42).JPG\n",
      "2_men (43).JPG\n",
      "2_men (44).JPG\n",
      "2_men (45).JPG\n",
      "2_men (46).JPG\n",
      "2_men (47).JPG\n",
      "2_men (48).JPG\n",
      "2_men (49).JPG\n",
      "2_men (5).JPG\n",
      "2_men (50).JPG\n",
      "2_men (51).JPG\n",
      "2_men (52).JPG\n",
      "2_men (53).JPG\n",
      "2_men (54).JPG\n",
      "2_men (55).JPG\n",
      "2_men (56).JPG\n",
      "2_men (57).JPG\n",
      "2_men (58).JPG\n",
      "2_men (59).JPG\n",
      "2_men (6).JPG\n",
      "2_men (60).JPG\n",
      "2_men (61).JPG\n",
      "2_men (62).JPG\n",
      "2_men (63).JPG\n",
      "2_men (64).JPG\n",
      "2_men (65).JPG\n",
      "2_men (66).JPG\n",
      "2_men (67).JPG\n",
      "2_men (68).JPG\n",
      "2_men (69).JPG\n",
      "2_men (70).JPG\n",
      "2_men (71).JPG\n",
      "2_men (72).JPG\n",
      "2_men (73).JPG\n",
      "2_men (74).JPG\n",
      "2_men (75).JPG\n",
      "2_men (76).JPG\n",
      "2_men (77).JPG\n",
      "2_men (78).JPG\n",
      "2_men (79).JPG\n",
      "2_men (8).JPG\n",
      "2_men (80).JPG\n",
      "2_men (81).JPG\n",
      "2_men (82).JPG\n",
      "2_men (83).JPG\n",
      "2_men (84).JPG\n",
      "2_men (85).JPG\n",
      "2_men (86).JPG\n",
      "2_men (87).JPG\n",
      "2_men (88).JPG\n",
      "2_men (89).JPG\n",
      "2_men (9).JPG\n",
      "2_men (90).JPG\n",
      "2_men (91).JPG\n",
      "2_men (92).JPG\n",
      "2_men (93).JPG\n",
      "2_men (94).JPG\n",
      "2_men (95).JPG\n",
      "2_men (96).JPG\n",
      "2_men (97).JPG\n",
      "2_men (98).JPG\n",
      "2_men (99).JPG\n",
      "2_woman (1).JPG\n",
      "2_woman (10).JPG\n",
      "2_woman (100).JPG\n",
      "2_woman (101).JPG\n",
      "2_woman (102).JPG\n",
      "2_woman (103).JPG\n",
      "2_woman (104).JPG\n",
      "2_woman (105).JPG\n",
      "2_woman (106).JPG\n",
      "2_woman (107).JPG\n",
      "2_woman (108).JPG\n",
      "2_woman (109).JPG\n",
      "2_woman (11).JPG\n",
      "2_woman (110).JPG\n",
      "2_woman (111).JPG\n",
      "2_woman (112).JPG\n",
      "2_woman (113).JPG\n",
      "2_woman (114).JPG\n",
      "2_woman (115).JPG\n",
      "2_woman (116).JPG\n",
      "2_woman (117).JPG\n",
      "2_woman (118).JPG\n",
      "2_woman (119).JPG\n",
      "2_woman (12).JPG\n",
      "2_woman (120).JPG\n",
      "2_woman (121).JPG\n",
      "2_woman (122).JPG\n",
      "2_woman (123).JPG\n",
      "2_woman (124).JPG\n",
      "2_woman (125).JPG\n",
      "2_woman (126).JPG\n",
      "2_woman (127).JPG\n",
      "2_woman (128).JPG\n",
      "2_woman (129).JPG\n",
      "2_woman (13).JPG\n",
      "2_woman (130).JPG\n",
      "2_woman (131).JPG\n",
      "2_woman (132).JPG\n",
      "2_woman (133).JPG\n",
      "2_woman (14).JPG\n",
      "2_woman (15).JPG\n",
      "2_woman (16).JPG\n",
      "2_woman (17).JPG\n",
      "2_woman (18).JPG\n",
      "2_woman (19).JPG\n",
      "2_woman (2).JPG\n",
      "2_woman (20).JPG\n",
      "2_woman (21).JPG\n",
      "2_woman (22).JPG\n",
      "2_woman (23).JPG\n",
      "2_woman (24).JPG\n",
      "2_woman (25).JPG\n",
      "2_woman (26).JPG\n",
      "2_woman (27).JPG\n",
      "2_woman (28).JPG\n",
      "2_woman (29).JPG\n",
      "2_woman (3).JPG\n",
      "2_woman (30).JPG\n",
      "2_woman (31).JPG\n",
      "2_woman (32).JPG\n",
      "2_woman (33).JPG\n",
      "2_woman (34).JPG\n",
      "2_woman (35).JPG\n",
      "2_woman (36).JPG\n",
      "2_woman (37).JPG\n",
      "2_woman (38).JPG\n",
      "2_woman (39).JPG\n",
      "2_woman (4).JPG\n",
      "2_woman (40).JPG\n",
      "2_woman (41).JPG\n",
      "2_woman (42).JPG\n",
      "2_woman (43).JPG\n",
      "2_woman (44).JPG\n",
      "2_woman (45).JPG\n",
      "2_woman (46).JPG\n",
      "2_woman (47).JPG\n",
      "2_woman (48).JPG\n",
      "2_woman (49).JPG\n",
      "2_woman (5).JPG\n",
      "2_woman (50).JPG\n",
      "2_woman (51).JPG\n",
      "2_woman (52).JPG\n",
      "2_woman (53).JPG\n",
      "2_woman (54).JPG\n",
      "2_woman (55).JPG\n",
      "2_woman (56).JPG\n",
      "2_woman (57).JPG\n",
      "2_woman (58).JPG\n",
      "2_woman (59).JPG\n",
      "2_woman (6).JPG\n",
      "2_woman (60).JPG\n",
      "2_woman (61).JPG\n",
      "2_woman (62).JPG\n",
      "2_woman (63).JPG\n",
      "2_woman (64).JPG\n",
      "2_woman (65).JPG\n",
      "2_woman (66).JPG\n",
      "2_woman (67).JPG\n",
      "2_woman (68).JPG\n",
      "2_woman (69).JPG\n",
      "2_woman (7).JPG\n",
      "2_woman (70).JPG\n",
      "2_woman (71).JPG\n",
      "2_woman (72).JPG\n",
      "2_woman (73).JPG\n",
      "2_woman (74).JPG\n",
      "2_woman (75).JPG\n",
      "2_woman (76).JPG\n",
      "2_woman (77).JPG\n",
      "2_woman (78).JPG\n",
      "2_woman (79).JPG\n",
      "2_woman (8).JPG\n",
      "2_woman (80).JPG\n",
      "2_woman (81).JPG\n",
      "2_woman (82).JPG\n",
      "2_woman (83).JPG\n",
      "2_woman (84).JPG\n",
      "2_woman (85).JPG\n",
      "2_woman (86).JPG\n",
      "2_woman (87).JPG\n",
      "2_woman (88).JPG\n",
      "2_woman (89).JPG\n",
      "2_woman (9).JPG\n",
      "2_woman (90).JPG\n",
      "2_woman (91).JPG\n",
      "2_woman (92).JPG\n",
      "2_woman (93).JPG\n",
      "2_woman (94).JPG\n",
      "2_woman (95).JPG\n",
      "2_woman (96).JPG\n",
      "2_woman (97).JPG\n",
      "2_woman (98).JPG\n",
      "2_woman (99).JPG\n",
      "3_men (1).JPG\n",
      "3_men (10).JPG\n",
      "3_men (100).JPG\n",
      "3_men (101).JPG\n",
      "3_men (102).JPG\n",
      "3_men (103).JPG\n",
      "3_men (104).JPG\n",
      "3_men (105).JPG\n",
      "3_men (106).JPG\n",
      "3_men (107).JPG\n",
      "3_men (108).JPG\n",
      "3_men (109).JPG\n",
      "3_men (110).JPG\n",
      "3_men (111).JPG\n",
      "3_men (112).JPG\n",
      "3_men (113).JPG\n",
      "3_men (114).JPG\n",
      "3_men (115).JPG\n",
      "3_men (116).JPG\n",
      "3_men (117).JPG\n",
      "3_men (118).JPG\n",
      "3_men (119).JPG\n",
      "3_men (120).JPG\n",
      "3_men (121).JPG\n",
      "3_men (122).JPG\n",
      "3_men (123).JPG\n",
      "3_men (124).JPG\n",
      "3_men (125).JPG\n",
      "3_men (126).JPG\n",
      "3_men (127).JPG\n",
      "3_men (128).JPG\n",
      "3_men (129).JPG\n",
      "3_men (130).JPG\n",
      "3_men (131).JPG\n",
      "3_men (132).JPG\n",
      "3_men (133).JPG\n",
      "3_men (135).JPG\n",
      "3_men (136).JPG\n",
      "3_men (137).JPG\n",
      "3_men (138).JPG\n",
      "3_men (139).JPG\n",
      "3_men (14).JPG\n",
      "3_men (142).JPG\n",
      "3_men (143).JPG\n",
      "3_men (144).JPG\n",
      "3_men (145).JPG\n",
      "3_men (146).JPG\n",
      "3_men (147).JPG\n",
      "3_men (148).JPG\n",
      "3_men (149).JPG\n",
      "3_men (15).JPG\n",
      "3_men (150).JPG\n",
      "3_men (151).JPG\n",
      "3_men (152).JPG\n",
      "3_men (153).JPG\n",
      "3_men (154).JPG\n",
      "3_men (155).JPG\n",
      "3_men (156).JPG\n",
      "3_men (157).JPG\n",
      "3_men (158).JPG\n",
      "3_men (159).JPG\n",
      "3_men (16).JPG\n",
      "3_men (160).JPG\n",
      "3_men (161).JPG\n",
      "3_men (162).JPG\n",
      "3_men (163).JPG\n",
      "3_men (164).JPG\n",
      "3_men (165).JPG\n",
      "3_men (166).JPG\n",
      "3_men (167).JPG\n",
      "3_men (168).JPG\n",
      "3_men (169).JPG\n",
      "3_men (17).JPG\n",
      "3_men (170).JPG\n",
      "3_men (171).JPG\n",
      "3_men (172).JPG\n",
      "3_men (173).JPG\n",
      "3_men (174).JPG\n",
      "3_men (175).JPG\n",
      "3_men (176).JPG\n",
      "3_men (177).JPG\n",
      "3_men (178).JPG\n",
      "3_men (179).JPG\n",
      "3_men (18).JPG\n",
      "3_men (180).JPG\n",
      "3_men (181).JPG\n",
      "3_men (182).JPG\n",
      "3_men (19).JPG\n",
      "3_men (2).JPG\n",
      "3_men (20).JPG\n",
      "3_men (21).JPG\n",
      "3_men (22).JPG\n",
      "3_men (23).JPG\n",
      "3_men (24).JPG\n",
      "3_men (25).JPG\n",
      "3_men (26).JPG\n",
      "3_men (27).JPG\n",
      "3_men (28).JPG\n",
      "3_men (29).JPG\n",
      "3_men (3).JPG\n",
      "3_men (30).JPG\n",
      "3_men (31).JPG\n",
      "3_men (32).JPG\n",
      "3_men (33).JPG\n",
      "3_men (35).JPG\n",
      "3_men (36).JPG\n",
      "3_men (37).JPG\n",
      "3_men (39).JPG\n",
      "3_men (4).JPG\n",
      "3_men (40).JPG\n",
      "3_men (41).JPG\n",
      "3_men (42).JPG\n",
      "3_men (43).JPG\n",
      "3_men (44).JPG\n",
      "3_men (45).JPG\n",
      "3_men (46).JPG\n",
      "3_men (48).JPG\n",
      "3_men (49).JPG\n",
      "3_men (5).JPG\n",
      "3_men (50).JPG\n",
      "3_men (51).JPG\n",
      "3_men (52).JPG\n",
      "3_men (53).JPG\n",
      "3_men (54).JPG\n",
      "3_men (55).JPG\n",
      "3_men (56).JPG\n",
      "3_men (57).JPG\n",
      "3_men (58).JPG\n",
      "3_men (59).JPG\n",
      "3_men (6).JPG\n",
      "3_men (60).JPG\n",
      "3_men (61).JPG\n",
      "3_men (62).JPG\n",
      "3_men (63).JPG\n",
      "3_men (64).JPG\n",
      "3_men (65).JPG\n",
      "3_men (66).JPG\n",
      "3_men (67).JPG\n",
      "3_men (68).JPG\n",
      "3_men (69).JPG\n",
      "3_men (7).JPG\n",
      "3_men (70).JPG\n",
      "3_men (71).JPG\n",
      "3_men (72).JPG\n",
      "3_men (73).JPG\n",
      "3_men (74).JPG\n",
      "3_men (75).JPG\n",
      "3_men (76).JPG\n",
      "3_men (77).JPG\n",
      "3_men (78).JPG\n",
      "3_men (79).JPG\n",
      "3_men (8).JPG\n",
      "3_men (80).JPG\n",
      "3_men (81).JPG\n",
      "3_men (82).JPG\n",
      "3_men (83).JPG\n",
      "3_men (84).JPG\n",
      "3_men (85).JPG\n",
      "3_men (86).JPG\n",
      "3_men (87).JPG\n",
      "3_men (89).JPG\n",
      "3_men (9).JPG\n",
      "3_men (90).JPG\n",
      "3_men (91).JPG\n",
      "3_men (92).JPG\n",
      "3_men (93).JPG\n",
      "3_men (94).JPG\n",
      "3_men (95).JPG\n",
      "3_men (96).JPG\n",
      "3_men (97).JPG\n",
      "3_men (98).JPG\n",
      "3_men (99).JPG\n",
      "3_woman (1).JPG\n",
      "3_woman (10).JPG\n",
      "3_woman (100).JPG\n",
      "3_woman (101).JPG\n",
      "3_woman (102).JPG\n",
      "3_woman (103).JPG\n",
      "3_woman (104).JPG\n",
      "3_woman (105).JPG\n",
      "3_woman (106).JPG\n",
      "3_woman (107).JPG\n",
      "3_woman (108).JPG\n",
      "3_woman (109).JPG\n",
      "3_woman (11).JPG\n",
      "3_woman (110).JPG\n",
      "3_woman (111).JPG\n",
      "3_woman (112).JPG\n",
      "3_woman (113).JPG\n",
      "3_woman (114).JPG\n",
      "3_woman (115).JPG\n",
      "3_woman (116).JPG\n",
      "3_woman (117).JPG\n",
      "3_woman (118).JPG\n",
      "3_woman (119).JPG\n",
      "3_woman (12).JPG\n",
      "3_woman (120).JPG\n",
      "3_woman (121).JPG\n",
      "3_woman (122).JPG\n",
      "3_woman (123).JPG\n",
      "3_woman (124).JPG\n",
      "3_woman (125).JPG\n",
      "3_woman (126).JPG\n",
      "3_woman (127).JPG\n",
      "3_woman (128).JPG\n",
      "3_woman (129).JPG\n",
      "3_woman (13).JPG\n",
      "3_woman (130).JPG\n",
      "3_woman (131).JPG\n",
      "3_woman (132).JPG\n",
      "3_woman (133).JPG\n",
      "3_woman (134).JPG\n",
      "3_woman (135).JPG\n",
      "3_woman (136).JPG\n",
      "3_woman (14).JPG\n",
      "3_woman (15).JPG\n",
      "3_woman (16).JPG\n",
      "3_woman (17).JPG\n",
      "3_woman (18).JPG\n",
      "3_woman (19).JPG\n",
      "3_woman (2).JPG\n",
      "3_woman (20).JPG\n",
      "3_woman (21).JPG\n",
      "3_woman (22).JPG\n",
      "3_woman (23).JPG\n",
      "3_woman (24).JPG\n",
      "3_woman (25).JPG\n",
      "3_woman (26).JPG\n",
      "3_woman (27).JPG\n",
      "3_woman (28).JPG\n",
      "3_woman (29).JPG\n",
      "3_woman (3).JPG\n",
      "3_woman (30).JPG\n",
      "3_woman (31).JPG\n",
      "3_woman (32).JPG\n",
      "3_woman (33).JPG\n",
      "3_woman (34).JPG\n",
      "3_woman (35).JPG\n",
      "3_woman (36).JPG\n",
      "3_woman (37).JPG\n",
      "3_woman (38).JPG\n",
      "3_woman (39).JPG\n",
      "3_woman (4).JPG\n",
      "3_woman (40).JPG\n",
      "3_woman (41).JPG\n",
      "3_woman (42).JPG\n",
      "3_woman (43).JPG\n",
      "3_woman (44).JPG\n",
      "3_woman (45).JPG\n",
      "3_woman (46).JPG\n",
      "3_woman (47).JPG\n",
      "3_woman (48).JPG\n",
      "3_woman (49).JPG\n",
      "3_woman (5).JPG\n",
      "3_woman (50).JPG\n",
      "3_woman (51).JPG\n",
      "3_woman (52).JPG\n",
      "3_woman (53).JPG\n",
      "3_woman (54).JPG\n",
      "3_woman (55).JPG\n",
      "3_woman (56).JPG\n",
      "3_woman (57).JPG\n",
      "3_woman (58).JPG\n",
      "3_woman (59).JPG\n",
      "3_woman (6).JPG\n",
      "3_woman (60).JPG\n",
      "3_woman (61).JPG\n",
      "3_woman (62).JPG\n",
      "3_woman (63).JPG\n",
      "3_woman (64).JPG\n",
      "3_woman (65).JPG\n",
      "3_woman (66).JPG\n",
      "3_woman (67).JPG\n",
      "3_woman (68).JPG\n",
      "3_woman (69).JPG\n",
      "3_woman (7).JPG\n",
      "3_woman (70).JPG\n",
      "3_woman (71).JPG\n",
      "3_woman (72).JPG\n",
      "3_woman (73).JPG\n",
      "3_woman (74).JPG\n",
      "3_woman (75).JPG\n",
      "3_woman (76).JPG\n",
      "3_woman (77).JPG\n",
      "3_woman (78).JPG\n",
      "3_woman (79).JPG\n",
      "3_woman (8).JPG\n",
      "3_woman (80).JPG\n",
      "3_woman (81).JPG\n",
      "3_woman (82).JPG\n",
      "3_woman (83).JPG\n",
      "3_woman (84).JPG\n",
      "3_woman (85).JPG\n",
      "3_woman (86).JPG\n",
      "3_woman (87).JPG\n",
      "3_woman (88).JPG\n",
      "3_woman (89).JPG\n",
      "3_woman (9).JPG\n",
      "3_woman (90).JPG\n",
      "3_woman (91).JPG\n",
      "3_woman (92).JPG\n",
      "3_woman (93).JPG\n",
      "3_woman (94).JPG\n",
      "3_woman (95).JPG\n",
      "3_woman (96).JPG\n",
      "3_woman (97).JPG\n",
      "3_woman (98).JPG\n",
      "3_woman (99).JPG\n",
      "4_men (1).JPG\n",
      "4_men (10).JPG\n",
      "4_men (100).JPG\n",
      "4_men (101).JPG\n",
      "4_men (102).JPG\n",
      "4_men (103).JPG\n",
      "4_men (104).JPG\n",
      "4_men (105).JPG\n",
      "4_men (106).JPG\n",
      "4_men (107).JPG\n",
      "4_men (108).JPG\n",
      "4_men (109).JPG\n",
      "4_men (11).JPG\n",
      "4_men (110).JPG\n",
      "4_men (111).JPG\n",
      "4_men (112).JPG\n",
      "4_men (113).JPG\n",
      "4_men (114).JPG\n",
      "4_men (115).JPG\n",
      "4_men (116).JPG\n",
      "4_men (117).JPG\n",
      "4_men (118).JPG\n",
      "4_men (119).JPG\n",
      "4_men (12).JPG\n",
      "4_men (120).JPG\n",
      "4_men (121).JPG\n",
      "4_men (122).JPG\n",
      "4_men (123).JPG\n",
      "4_men (124).JPG\n",
      "4_men (125).JPG\n",
      "4_men (126).JPG\n",
      "4_men (127).JPG\n",
      "4_men (128).JPG\n",
      "4_men (129).JPG\n",
      "4_men (13).JPG\n",
      "4_men (130).JPG\n",
      "4_men (131).JPG\n",
      "4_men (132).JPG\n",
      "4_men (133).JPG\n",
      "4_men (134).JPG\n",
      "4_men (135).JPG\n",
      "4_men (136).JPG\n",
      "4_men (137).JPG\n",
      "4_men (138).JPG\n",
      "4_men (139).JPG\n",
      "4_men (14).JPG\n",
      "4_men (140).JPG\n",
      "4_men (142).JPG\n",
      "4_men (143).JPG\n",
      "4_men (144).JPG\n",
      "4_men (145).JPG\n",
      "4_men (146).JPG\n",
      "4_men (147).JPG\n",
      "4_men (15).JPG\n",
      "4_men (151).JPG\n",
      "4_men (152).JPG\n",
      "4_men (153).JPG\n",
      "4_men (154).JPG\n",
      "4_men (155).JPG\n",
      "4_men (156).JPG\n",
      "4_men (157).JPG\n",
      "4_men (158).JPG\n",
      "4_men (159).JPG\n",
      "4_men (16).JPG\n",
      "4_men (160).JPG\n",
      "4_men (161).JPG\n",
      "4_men (162).JPG\n",
      "4_men (163).JPG\n",
      "4_men (164).JPG\n",
      "4_men (165).JPG\n",
      "4_men (166).JPG\n",
      "4_men (167).JPG\n",
      "4_men (168).JPG\n",
      "4_men (169).JPG\n",
      "4_men (17).JPG\n",
      "4_men (170).JPG\n",
      "4_men (171).JPG\n",
      "4_men (172).JPG\n",
      "4_men (173).JPG\n",
      "4_men (174).JPG\n",
      "4_men (18).JPG\n",
      "4_men (19).JPG\n",
      "4_men (2).JPG\n",
      "4_men (20).JPG\n",
      "4_men (21).JPG\n",
      "4_men (22).JPG\n",
      "4_men (23).JPG\n",
      "4_men (24).JPG\n",
      "4_men (25).JPG\n",
      "4_men (27).JPG\n",
      "4_men (28).JPG\n",
      "4_men (29).JPG\n",
      "4_men (3).JPG\n",
      "4_men (30).JPG\n",
      "4_men (31).JPG\n",
      "4_men (32).JPG\n",
      "4_men (33).JPG\n",
      "4_men (34).JPG\n",
      "4_men (35).JPG\n",
      "4_men (36).JPG\n",
      "4_men (37).JPG\n",
      "4_men (38).JPG\n",
      "4_men (39).JPG\n",
      "4_men (4).JPG\n",
      "4_men (40).JPG\n",
      "4_men (41).JPG\n",
      "4_men (42).JPG\n",
      "4_men (43).JPG\n",
      "4_men (44).JPG\n",
      "4_men (45).JPG\n",
      "4_men (46).JPG\n",
      "4_men (47).JPG\n",
      "4_men (48).JPG\n",
      "4_men (49).JPG\n",
      "4_men (50).JPG\n",
      "4_men (51).JPG\n",
      "4_men (52).JPG\n",
      "4_men (53).JPG\n",
      "4_men (54).JPG\n",
      "4_men (56).JPG\n",
      "4_men (57).JPG\n",
      "4_men (58).JPG\n",
      "4_men (59).JPG\n",
      "4_men (60).JPG\n",
      "4_men (61).JPG\n",
      "4_men (62).JPG\n",
      "4_men (64).JPG\n",
      "4_men (65).JPG\n",
      "4_men (66).JPG\n",
      "4_men (67).JPG\n",
      "4_men (68).JPG\n",
      "4_men (69).JPG\n",
      "4_men (7).JPG\n",
      "4_men (70).JPG\n",
      "4_men (71).JPG\n",
      "4_men (72).JPG\n",
      "4_men (73).JPG\n",
      "4_men (74).JPG\n",
      "4_men (75).JPG\n",
      "4_men (76).JPG\n",
      "4_men (77).JPG\n",
      "4_men (78).JPG\n",
      "4_men (79).JPG\n",
      "4_men (8).JPG\n",
      "4_men (80).JPG\n",
      "4_men (81).JPG\n",
      "4_men (82).JPG\n",
      "4_men (83).JPG\n",
      "4_men (84).JPG\n",
      "4_men (85).JPG\n",
      "4_men (86).JPG\n",
      "4_men (87).JPG\n",
      "4_men (88).JPG\n",
      "4_men (89).JPG\n",
      "4_men (9).JPG\n",
      "4_men (90).JPG\n",
      "4_men (91).JPG\n",
      "4_men (92).JPG\n",
      "4_men (93).JPG\n",
      "4_men (94).JPG\n",
      "4_men (95).JPG\n",
      "4_men (96).JPG\n",
      "4_men (97).JPG\n",
      "4_men (98).JPG\n",
      "4_men (99).JPG\n",
      "4_woman (1).JPG\n",
      "4_woman (10).JPG\n",
      "4_woman (100).JPG\n",
      "4_woman (101).JPG\n",
      "4_woman (102).JPG\n",
      "4_woman (103).JPG\n",
      "4_woman (104).JPG\n",
      "4_woman (105).JPG\n",
      "4_woman (106).JPG\n",
      "4_woman (107).JPG\n",
      "4_woman (108).JPG\n",
      "4_woman (109).JPG\n",
      "4_woman (11).JPG\n",
      "4_woman (110).JPG\n",
      "4_woman (111).JPG\n",
      "4_woman (112).JPG\n",
      "4_woman (113).JPG\n",
      "4_woman (114).JPG\n",
      "4_woman (115).JPG\n",
      "4_woman (116).JPG\n",
      "4_woman (117).JPG\n",
      "4_woman (118).JPG\n",
      "4_woman (119).JPG\n",
      "4_woman (12).JPG\n",
      "4_woman (120).JPG\n",
      "4_woman (121).JPG\n",
      "4_woman (122).JPG\n",
      "4_woman (123).JPG\n",
      "4_woman (124).JPG\n",
      "4_woman (125).JPG\n",
      "4_woman (126).JPG\n",
      "4_woman (127).JPG\n",
      "4_woman (128).JPG\n",
      "4_woman (129).JPG\n",
      "4_woman (13).JPG\n",
      "4_woman (130).JPG\n",
      "4_woman (131).JPG\n",
      "4_woman (132).JPG\n",
      "4_woman (133).JPG\n",
      "4_woman (14).JPG\n",
      "4_woman (15).JPG\n",
      "4_woman (16).JPG\n",
      "4_woman (17).JPG\n",
      "4_woman (18).JPG\n",
      "4_woman (19).JPG\n",
      "4_woman (2).JPG\n",
      "4_woman (20).JPG\n",
      "4_woman (21).JPG\n",
      "4_woman (22).JPG\n",
      "4_woman (23).JPG\n",
      "4_woman (24).JPG\n",
      "4_woman (25).JPG\n",
      "4_woman (26).JPG\n",
      "4_woman (27).JPG\n",
      "4_woman (28).JPG\n",
      "4_woman (29).JPG\n",
      "4_woman (3).JPG\n",
      "4_woman (30).JPG\n",
      "4_woman (31).JPG\n",
      "4_woman (32).JPG\n",
      "4_woman (33).JPG\n",
      "4_woman (34).JPG\n",
      "4_woman (35).JPG\n",
      "4_woman (36).JPG\n",
      "4_woman (37).JPG\n",
      "4_woman (38).JPG\n",
      "4_woman (39).JPG\n",
      "4_woman (4).JPG\n",
      "4_woman (40).JPG\n",
      "4_woman (41).JPG\n",
      "4_woman (42).JPG\n",
      "4_woman (43).JPG\n",
      "4_woman (44).JPG\n",
      "4_woman (45).JPG\n",
      "4_woman (46).JPG\n",
      "4_woman (47).JPG\n",
      "4_woman (48).JPG\n",
      "4_woman (49).JPG\n",
      "4_woman (5).JPG\n",
      "4_woman (50).JPG\n",
      "4_woman (51).JPG\n",
      "4_woman (52).JPG\n",
      "4_woman (53).JPG\n",
      "4_woman (54).JPG\n",
      "4_woman (55).JPG\n",
      "4_woman (56).JPG\n",
      "4_woman (57).JPG\n",
      "4_woman (58).JPG\n",
      "4_woman (59).JPG\n",
      "4_woman (6).JPG\n",
      "4_woman (60).JPG\n",
      "4_woman (61).JPG\n",
      "4_woman (62).JPG\n",
      "4_woman (63).JPG\n",
      "4_woman (64).JPG\n",
      "4_woman (65).JPG\n",
      "4_woman (66).JPG\n",
      "4_woman (67).JPG\n",
      "4_woman (68).JPG\n",
      "4_woman (69).JPG\n",
      "4_woman (7).JPG\n",
      "4_woman (70).JPG\n",
      "4_woman (71).JPG\n",
      "4_woman (72).JPG\n",
      "4_woman (73).JPG\n",
      "4_woman (74).JPG\n",
      "4_woman (75).JPG\n",
      "4_woman (76).JPG\n",
      "4_woman (77).JPG\n",
      "4_woman (78).JPG\n",
      "4_woman (8).JPG\n",
      "4_woman (80).JPG\n",
      "4_woman (81).JPG\n",
      "4_woman (82).JPG\n",
      "4_woman (83).JPG\n",
      "4_woman (84).JPG\n",
      "4_woman (85).JPG\n",
      "4_woman (86).JPG\n",
      "4_woman (87).JPG\n",
      "4_woman (88).JPG\n",
      "4_woman (89).JPG\n",
      "4_woman (9).JPG\n",
      "4_woman (90).JPG\n",
      "4_woman (91).JPG\n",
      "4_woman (92).JPG\n",
      "4_woman (93).JPG\n",
      "4_woman (94).JPG\n",
      "4_woman (95).JPG\n",
      "4_woman (96).JPG\n",
      "4_woman (97).JPG\n",
      "4_woman (98).JPG\n",
      "4_woman (99).JPG\n",
      "5_men (1).JPG\n",
      "5_men (10).JPG\n",
      "5_men (100).JPG\n",
      "5_men (101).JPG\n",
      "5_men (102).JPG\n",
      "5_men (103).JPG\n",
      "5_men (104).JPG\n",
      "5_men (105).JPG\n",
      "5_men (106).JPG\n",
      "5_men (107).JPG\n",
      "5_men (108).JPG\n",
      "5_men (109).JPG\n",
      "5_men (11).JPG\n",
      "5_men (110).JPG\n",
      "5_men (111).JPG\n",
      "5_men (112).JPG\n",
      "5_men (113).JPG\n",
      "5_men (114).JPG\n",
      "5_men (115).JPG\n",
      "5_men (116).JPG\n",
      "5_men (117).JPG\n",
      "5_men (118).JPG\n",
      "5_men (119).JPG\n",
      "5_men (12).JPG\n",
      "5_men (120).JPG\n",
      "5_men (121).JPG\n",
      "5_men (122).JPG\n",
      "5_men (123).JPG\n",
      "5_men (124).JPG\n",
      "5_men (125).JPG\n",
      "5_men (126).JPG\n",
      "5_men (127).JPG\n",
      "5_men (128).JPG\n",
      "5_men (129).JPG\n",
      "5_men (13).JPG\n",
      "5_men (130).JPG\n",
      "5_men (131).JPG\n",
      "5_men (132).JPG\n",
      "5_men (133).JPG\n",
      "5_men (134).JPG\n",
      "5_men (135).JPG\n",
      "5_men (136).JPG\n",
      "5_men (137).JPG\n",
      "5_men (138).JPG\n",
      "5_men (139).JPG\n",
      "5_men (14).JPG\n",
      "5_men (140).JPG\n",
      "5_men (141).JPG\n",
      "5_men (142).JPG\n",
      "5_men (143).JPG\n",
      "5_men (144).JPG\n",
      "5_men (145).JPG\n",
      "5_men (146).JPG\n",
      "5_men (147).JPG\n",
      "5_men (148).JPG\n",
      "5_men (149).JPG\n",
      "5_men (15).JPG\n",
      "5_men (150).JPG\n",
      "5_men (151).JPG\n",
      "5_men (152).JPG\n",
      "5_men (153).JPG\n",
      "5_men (154).JPG\n",
      "5_men (155).JPG\n",
      "5_men (156).JPG\n",
      "5_men (157).JPG\n",
      "5_men (158).JPG\n",
      "5_men (159).JPG\n",
      "5_men (16).JPG\n",
      "5_men (160).JPG\n",
      "5_men (161).JPG\n",
      "5_men (162).JPG\n",
      "5_men (163).JPG\n",
      "5_men (164).JPG\n",
      "5_men (165).JPG\n",
      "5_men (166).JPG\n",
      "5_men (167).JPG\n",
      "5_men (168).JPG\n",
      "5_men (169).JPG\n",
      "5_men (17).JPG\n",
      "5_men (170).JPG\n",
      "5_men (171).JPG\n",
      "5_men (172).JPG\n",
      "5_men (173).JPG\n",
      "5_men (174).JPG\n",
      "5_men (175).JPG\n",
      "5_men (176).JPG\n",
      "5_men (18).JPG\n",
      "5_men (19).JPG\n",
      "5_men (2).JPG\n",
      "5_men (20).JPG\n",
      "5_men (21).JPG\n",
      "5_men (22).JPG\n",
      "5_men (23).JPG\n",
      "5_men (24).JPG\n",
      "5_men (25).JPG\n",
      "5_men (26).JPG\n",
      "5_men (27).JPG\n",
      "5_men (28).JPG\n",
      "5_men (29).JPG\n",
      "5_men (3).JPG\n",
      "5_men (30).JPG\n",
      "5_men (31).JPG\n",
      "5_men (32).JPG\n",
      "5_men (33).JPG\n",
      "5_men (34).JPG\n",
      "5_men (35).JPG\n",
      "5_men (36).JPG\n",
      "5_men (37).JPG\n",
      "5_men (38).JPG\n",
      "5_men (39).JPG\n",
      "5_men (4).JPG\n",
      "5_men (40).JPG\n",
      "5_men (41).JPG\n",
      "5_men (42).JPG\n",
      "5_men (43).JPG\n",
      "5_men (44).JPG\n",
      "5_men (45).JPG\n",
      "5_men (46).JPG\n",
      "5_men (47).JPG\n",
      "5_men (48).JPG\n",
      "5_men (49).JPG\n",
      "5_men (5).JPG\n",
      "5_men (50).JPG\n",
      "5_men (51).JPG\n",
      "5_men (52).JPG\n",
      "5_men (53).JPG\n",
      "5_men (54).JPG\n",
      "5_men (55).JPG\n",
      "5_men (56).JPG\n",
      "5_men (57).JPG\n",
      "5_men (58).JPG\n",
      "5_men (59).JPG\n",
      "5_men (6).JPG\n",
      "5_men (60).JPG\n",
      "5_men (61).JPG\n",
      "5_men (62).JPG\n",
      "5_men (63).JPG\n",
      "5_men (64).JPG\n",
      "5_men (65).JPG\n",
      "5_men (66).JPG\n",
      "5_men (67).JPG\n",
      "5_men (68).JPG\n",
      "5_men (69).JPG\n",
      "5_men (7).JPG\n",
      "5_men (70).JPG\n",
      "5_men (71).JPG\n",
      "5_men (72).JPG\n",
      "5_men (73).JPG\n",
      "5_men (74).JPG\n",
      "5_men (75).JPG\n",
      "5_men (76).JPG\n",
      "5_men (77).JPG\n",
      "5_men (78).JPG\n",
      "5_men (79).JPG\n",
      "5_men (8).JPG\n",
      "5_men (80).JPG\n",
      "5_men (81).JPG\n",
      "5_men (82).JPG\n",
      "5_men (83).JPG\n",
      "5_men (84).JPG\n",
      "5_men (85).JPG\n",
      "5_men (86).JPG\n",
      "5_men (87).JPG\n",
      "5_men (88).JPG\n",
      "5_men (89).JPG\n",
      "5_men (9).JPG\n",
      "5_men (90).JPG\n",
      "5_men (91).JPG\n",
      "5_men (92).JPG\n",
      "5_men (93).JPG\n",
      "5_men (94).JPG\n",
      "5_men (95).JPG\n",
      "5_men (96).JPG\n",
      "5_men (97).JPG\n",
      "5_men (98).JPG\n",
      "5_men (99).JPG\n",
      "5_men.JPG\n",
      "5_woman (1).JPG\n",
      "5_woman (10).JPG\n",
      "5_woman (100).JPG\n",
      "5_woman (101).JPG\n",
      "5_woman (102).JPG\n",
      "5_woman (103).JPG\n",
      "5_woman (104).JPG\n",
      "5_woman (105).JPG\n",
      "5_woman (106).JPG\n",
      "5_woman (107).JPG\n",
      "5_woman (108).JPG\n",
      "5_woman (109).JPG\n",
      "5_woman (11).JPG\n",
      "5_woman (110).JPG\n",
      "5_woman (111).JPG\n",
      "5_woman (112).JPG\n",
      "5_woman (113).JPG\n",
      "5_woman (114).JPG\n",
      "5_woman (115).JPG\n",
      "5_woman (116).JPG\n",
      "5_woman (117).JPG\n",
      "5_woman (118).JPG\n",
      "5_woman (119).JPG\n",
      "5_woman (12).JPG\n",
      "5_woman (120).JPG\n",
      "5_woman (121).JPG\n",
      "5_woman (122).JPG\n",
      "5_woman (123).JPG\n",
      "5_woman (124).JPG\n",
      "5_woman (125).JPG\n",
      "5_woman (126).JPG\n",
      "5_woman (127).JPG\n",
      "5_woman (128).JPG\n",
      "5_woman (129).JPG\n",
      "5_woman (13).JPG\n",
      "5_woman (130).JPG\n",
      "5_woman (131).JPG\n",
      "5_woman (132).JPG\n",
      "5_woman (14).JPG\n",
      "5_woman (15).JPG\n",
      "5_woman (16).JPG\n",
      "5_woman (17).JPG\n",
      "5_woman (18).JPG\n",
      "5_woman (19).JPG\n",
      "5_woman (2).JPG\n",
      "5_woman (20).JPG\n",
      "5_woman (21).JPG\n",
      "5_woman (22).JPG\n",
      "5_woman (23).JPG\n",
      "5_woman (24).JPG\n",
      "5_woman (25).JPG\n",
      "5_woman (26).JPG\n",
      "5_woman (27).JPG\n",
      "5_woman (28).JPG\n",
      "5_woman (29).JPG\n",
      "5_woman (3).JPG\n",
      "5_woman (30).JPG\n",
      "5_woman (31).JPG\n",
      "5_woman (32).JPG\n",
      "5_woman (33).JPG\n",
      "5_woman (34).JPG\n",
      "5_woman (35).JPG\n",
      "5_woman (36).JPG\n",
      "5_woman (37).JPG\n",
      "5_woman (38).JPG\n",
      "5_woman (39).JPG\n",
      "5_woman (4).JPG\n",
      "5_woman (40).JPG\n",
      "5_woman (41).JPG\n",
      "5_woman (42).JPG\n",
      "5_woman (43).JPG\n",
      "5_woman (44).JPG\n",
      "5_woman (45).JPG\n",
      "5_woman (46).JPG\n",
      "5_woman (47).JPG\n",
      "5_woman (48).JPG\n",
      "5_woman (49).JPG\n",
      "5_woman (5).JPG\n",
      "5_woman (50).JPG\n",
      "5_woman (51).JPG\n",
      "5_woman (52).JPG\n",
      "5_woman (53).JPG\n",
      "5_woman (54).JPG\n",
      "5_woman (55).JPG\n",
      "5_woman (56).JPG\n",
      "5_woman (57).JPG\n",
      "5_woman (58).JPG\n",
      "5_woman (59).JPG\n",
      "5_woman (6).JPG\n",
      "5_woman (60).JPG\n",
      "5_woman (61).JPG\n",
      "5_woman (62).JPG\n",
      "5_woman (63).JPG\n",
      "5_woman (64).JPG\n",
      "5_woman (65).JPG\n",
      "5_woman (66).JPG\n",
      "5_woman (67).JPG\n",
      "5_woman (68).JPG\n",
      "5_woman (69).JPG\n",
      "5_woman (7).JPG\n",
      "5_woman (70).JPG\n",
      "5_woman (71).JPG\n",
      "5_woman (72).JPG\n",
      "5_woman (73).JPG\n",
      "5_woman (74).JPG\n",
      "5_woman (75).JPG\n",
      "5_woman (76).JPG\n",
      "5_woman (77).JPG\n",
      "5_woman (78).JPG\n",
      "5_woman (79).JPG\n",
      "5_woman (8).JPG\n",
      "5_woman (82).JPG\n",
      "5_woman (85).JPG\n",
      "5_woman (86).JPG\n",
      "5_woman (87).JPG\n",
      "5_woman (88).JPG\n",
      "5_woman (89).JPG\n",
      "5_woman (9).JPG\n",
      "5_woman (90).JPG\n",
      "5_woman (91).JPG\n",
      "5_woman (92).JPG\n",
      "5_woman (93).JPG\n",
      "5_woman (94).JPG\n",
      "5_woman (95).JPG\n",
      "5_woman (96).JPG\n",
      "5_woman (97).JPG\n",
      "5_woman (98).JPG\n",
      "5_woman (99).JPG\n"
     ]
    }
   ],
   "source": [
    "# The Fourier elliptical features are extracted from each of the images and we proceed to save them in a. txt file.\n",
    "base = \"./\"\n",
    "def EF_oper(img_rgb):\n",
    "    img_binary = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_binary = cv2.threshold(img_binary, 127, 255, 0)\n",
    "    contours, _ = cv2.findContours(img_binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    maxcontour = max(contours, key=cv2.contourArea)\n",
    "    # cv2.drawContours(img_rgb,[maxcontour],0,(255,9,9))\n",
    "    # plt_t('cont',img_rgb)\n",
    "    coeffs = []\n",
    "    # Find the coefficients of all contours\n",
    "    coeffs.append(elliptic_fourier_descriptors(np.squeeze(maxcontour), order=13))\n",
    "    # print(\"coeff\",coeffs)\n",
    "    coeffs2 = []\n",
    "    for row in coeffs:\n",
    "        for elem in row:\n",
    "            coeffs2.append(elem)\n",
    "    coeffs = []\n",
    "    for row in coeffs2:\n",
    "        for elem in row:\n",
    "            coeffs.append(elem)\n",
    "    return np.array(coeffs)\n",
    "\n",
    "\n",
    "def EllipticFourier():\n",
    "    print(\"EF\\n\")\n",
    "    path_EF = base + r\"Feature-Extraction\"\n",
    "    if not os.path.exists(path_EF):\n",
    "        os.makedirs(path_EF)\n",
    "\n",
    "    file = open(base + r\"Feature-Extraction/Elliptic-Fourier.txt\", \"w\")\n",
    "    # file = open(r\"C:\\Users\\Ever\\Desktop\\Elliptic-Fourier.txt\", \"w\")\n",
    "    lstFiles = []  # nombre de imagenes\n",
    "    path = r\"./Image-Segmentation-masks\"\n",
    "    for (path, _, archivos) in walk(path):\n",
    "        for arch in archivos:\n",
    "            (nomArch, ext) = os.path.splitext(arch)\n",
    "            if (ext == \".JPG\"):\n",
    "                lstFiles.append(nomArch + ext)\n",
    "                direc = path + \"/\" + nomArch + ext\n",
    "                name = nomArch + ext\n",
    "                print(nomArch + ext)\n",
    "                img_binary = cv2.imread(direc)\n",
    "                coeffs = EF_oper(img_binary)\n",
    "                file.write(name)\n",
    "                for item in range(len(coeffs)):\n",
    "                    file.write(\",%.4f\" % coeffs[item])\n",
    "                file.write(\",\" + name[0] + \"\\n\")\n",
    "\n",
    "    file.close()\n",
    "EllipticFourier()\n",
    "# img_binary = cv2.imread(r'Image-Segmentation2\\0_men (4).JPG')\n",
    "# coeffs = EF_oper(img_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def extract_sift_features(img):\n",
    "    # image_descriptors = []\n",
    "    # sift = cv2.xfeatures2d.SIFT_create()\n",
    "    orb = cv2.ORB_create()\n",
    "    _, descriptors = orb.detectAndCompute(img, None)\n",
    "    # image_descriptors.append(descriptor)\n",
    "    return descriptors\n",
    "\n",
    "def kmean_bow(all_descriptors, num_cluster):\n",
    "    bow_dict = []\n",
    "    kmeans = KMeans(n_clusters = num_cluster)\n",
    "    kmeans.fit(all_descriptors)\n",
    "\n",
    "    bow_dict = kmeans.cluster_centers_\n",
    "\n",
    "    if not os.path.isfile('./Feature-Extraction/bow_dictionary.pkl'):\n",
    "        pickle.dump(bow_dict, open('./Feature-Extraction/bow_dictionary.pkl', 'wb'))\n",
    "    return bow_dict\n",
    "\n",
    "def create_feature_bow(image_descriptors, BoW, num_cluster):\n",
    "\n",
    "    X_features = []\n",
    "\n",
    "    for i in range(len(image_descriptors)):\n",
    "        features = np.array([0] * num_cluster)\n",
    "\n",
    "        if image_descriptors[i] is not None:\n",
    "            distance = cdist(image_descriptors[i], BoW)\n",
    "\n",
    "            argmin = np.argmin(distance, axis = 1)\n",
    "\n",
    "            for j in argmin:\n",
    "                features[j] += 1\n",
    "        X_features.append(features)\n",
    "\n",
    "    return X_features\n",
    "\n",
    "\n",
    "# The Histogram of Oriented Gradients features are extracted from each of the images and we proceed to save them in a. txt file\n",
    "def SIFT():\n",
    "    print(\"SIFT\\n\")\n",
    "    file  = open(r\"./Feature-Extraction/SIFT.txt\", \"w\")\n",
    "    lstFiles = []  # nombre de imagenes\n",
    "    path = r\"./Image-Segmentation2\"\n",
    "    all_descriptors = []\n",
    "    image_desctiptors = []\n",
    "    all_names = []\n",
    "    for (path, _, archivos) in walk(path):\n",
    "        for arch in archivos:\n",
    "            (nomArch, ext) = os.path.splitext(arch)\n",
    "            if (ext == \".JPG\"):\n",
    "                lstFiles.append(nomArch + ext)\n",
    "                direc = path + \"/\" + nomArch + ext\n",
    "                name = nomArch + ext\n",
    "                print(name)\n",
    "                all_names.append(name)\n",
    "                # print(nomArch + ext)\n",
    "                img_binary = cv2.imread(direc)\n",
    "                descriptors = extract_sift_features(img_binary)\n",
    "\n",
    "\n",
    "                # Load SIFT descriptors\n",
    "                # descriptors = np.load(\"descriptors.npy\")\n",
    "\n",
    "                # Normalize descriptors\n",
    "                scaler = StandardScaler()\n",
    "                descriptors_norm = scaler.fit_transform(descriptors)\n",
    "\n",
    "                # Cluster descriptors using k-means\n",
    "                kmeans = KMeans(n_clusters=100)\n",
    "                kmeans.fit(descriptors_norm)\n",
    "\n",
    "                # Compute visual word histograms for each image\n",
    "                labels = kmeans.predict(scaler.transform(descriptors))\n",
    "\n",
    "                # Compute histogram of visual words\n",
    "                histogram, _ = np.histogram(labels, bins=range(100), density=True)\n",
    "\n",
    "\n",
    "                # image_desctiptors.append(desc)\n",
    "    #             kmeans = KMeans(n_clusters=50)\n",
    "    #             kmeans.fit(desc)\n",
    "    # #             create histogram\n",
    "    #             histogram1 = np.zeros(100)\n",
    "    #             for descriptor in desc:\n",
    "    #                 index = kmeans.predict([descriptor.astype(np.double)])\n",
    "    #                 histogram1[index] += 1\n",
    "                file.write(name)\n",
    "                for item in range(len(histogram)):\n",
    "                    file.write(\",%.3f\" % histogram[item])\n",
    "                file.write(\",\" + name[0] + \"\\n\")\n",
    "\n",
    "    # all_descriptors = []\n",
    "    # for descriptor in image_desctiptors:\n",
    "    #     if descriptor is not None:\n",
    "    #         for des in descriptor:\n",
    "    #             all_descriptors.append(des)\n",
    "                \n",
    "                \n",
    "    # num_cluster = 150\n",
    "    # BoW = kmean_bow(all_descriptors, num_cluster)\n",
    "    # X_features = create_feature_bow(image_desctiptors, BoW, num_cluster)\n",
    "    # print(len(X_features))\n",
    "    # print(X_features[0])\n",
    "    \n",
    "    # for i in range(len(all_names)):\n",
    "    #     file.write(all_names[i])\n",
    "    #     for item in range(len(X_features[i])):\n",
    "    #         file.write(\",%.3f\" % X_features[i][item])\n",
    "    #     file.write(\",\" + all_names[i][0] + \"\\n\")\n",
    "    # file.close()\n",
    "    \n",
    "SIFT()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAM9Kz24QRs6",
    "outputId": "8e09888e-414c-4b43-9bc3-93cbaa80de43",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def HOG_oper(img_binary):\n",
    "    (H) = feature.hog(img_binary, orientations=9, pixels_per_cell=(16,16),\n",
    "                                  cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L1\",channel_axis=-1) \n",
    "    pca = joblib.load(r\"./Feature-Extraction/pca.pkl\") #PCA(0.97).fit_transform(H.reshape(1, -1))\n",
    "    components = pca.transform(H.reshape(1, -1))\n",
    "    # joblib.dump(pca, r\"./Feature-Extraction/pca.pkl\")\n",
    "    return components\n",
    "\n",
    "def HOG_PCA():\n",
    "    data_HOG = pd.read_csv(r'./Feature-Extraction/Histogram-of-Oriented-Gradients.txt', sep=',', header=None)\n",
    "    file2 = open(r\"./Feature-Extraction/Histogram-of-Oriented-Gradients-PCA.txt\", \"w\")\n",
    "    name_HOG = data_HOG.iloc[:, 0]\n",
    "    value_HOG = data_HOG.iloc[:, 1:-1]\n",
    "    tag_HOG = data_HOG.iloc[:, -1] # 0,1,2,3,4,5\n",
    "    print(\"PCA\")\n",
    "    pca = PCA(0.97).fit(value_HOG)\n",
    "    joblib.dump(pca, r\"./Feature-Extraction/pca.pkl\")\n",
    "    \n",
    "    components = pca.transform(value_HOG)\n",
    "    print(components.shape)\n",
    "    for row in range(len(components)):\n",
    "        file2.write(name_HOG[row])\n",
    "        for colm in range(len(components[row])):\n",
    "            file2.write(\",%.4f\" %components[row][colm])\n",
    "        file2.write(\",%s\" %tag_HOG[row] + \"\\n\")\n",
    "    file2.close()\n",
    "\n",
    "# The Histogram of Oriented Gradients features are extracted from each of the images and we proceed to save them in a. txt file\n",
    "# def HOG():\n",
    "#     print(\"HOG\\n\")\n",
    "#     file  = open(r\"./Feature-Extraction/Histogram-of-Oriented-Gradients.txt\", \"w\")\n",
    "#     lstFiles = []  # nombre de imagenes\n",
    "#     path = r\"./Image-Segmentation2\"\n",
    "#     for (path, _, archivos) in walk(path):\n",
    "#         for arch in archivos:\n",
    "#             (nomArch, ext) = os.path.splitext(arch)\n",
    "#             if (ext == \".JPG\"):\n",
    "#                 lstFiles.append(nomArch + ext)\n",
    "#                 direc = path + \"/\" + nomArch + ext\n",
    "#                 name = nomArch + ext\n",
    "#                 # print(nomArch + ext)\n",
    "#                 img_binary = cv2.imread(direc)\n",
    "                \n",
    "#                 (H) = feature.hog(img_binary, orientations=9, pixels_per_cell=(16,16),\n",
    "#                                   cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L1\",channel_axis=-1)  # ,visualize=True\n",
    "#                 # hogImage = exposure.rescale_intensity(hogImage, out_range=(0, 255))     ,hogImage\n",
    "#                 # hogImage = hogImage.astype(\"uint8\")\n",
    "                \n",
    "#                 # plt.imshow(\"HOG Image\", hogImage)\n",
    "#                 file.write(name)\n",
    "#                 for item in range(len(H)):\n",
    "#                     file.write(\",%.3f\" % H[item])\n",
    "#                 file.write(\",\" + name[0] + \"\\n\")\n",
    "#     file.close()\n",
    "\n",
    "\n",
    "\n",
    "def HOG():\n",
    "    print(\"HOG\\n\")\n",
    "    file  = open(r\"./Feature-Extraction/Histogram-of-Oriented-Gradients.txt\", \"w\")\n",
    "    lstFiles = []  # nombre de imagenes\n",
    "    path = r\"./Image-Segmentation2\"\n",
    "    for (path, _, archivos) in walk(path):\n",
    "        for arch in archivos:\n",
    "            (nomArch, ext) = os.path.splitext(arch)\n",
    "            if (ext == \".JPG\"):\n",
    "                lstFiles.append(nomArch + ext)\n",
    "                direc = path + \"/\" + nomArch + ext\n",
    "                name = nomArch + ext\n",
    "                # print(nomArch + ext)\n",
    "                img_binary = cv2.imread(direc)\n",
    "\n",
    "                image = cv2.imread(\"Image-Segmentation2/\" + arch)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                image = cv2.resize(image, (461, 260))\n",
    "                \n",
    "                (H, hogImage) = feature.hog(image, orientations=9,  pixels_per_cell=(32, 32), cells_per_block=(2, 2), transform_sqrt=True, block_norm=\"L1\", visualize=True, feature_vector=True)\n",
    "\n",
    "\n",
    "                file.write(name)\n",
    "                for item in range(len(H)):\n",
    "                    file.write(\",%.3f\" % H[item])\n",
    "                file.write(\",\" + name[0] + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "    \n",
    "HOG()\n",
    "HOG_PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcWQ_TIEQRs6",
    "outputId": "b2d393be-96d8-4900-8655-18f7a5cf26d2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The Hu Moments features are extracted from each of the images and we proceed to save them in a. txt file\n",
    "# %pip install tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "def HU_oper(img_binary):\n",
    "    # https://www.pyimagesearch.com/2014/10/27/opencv-shape-descriptor-hu-moments-example/\n",
    "    img_binary = cv2.cvtColor(img_binary, cv2.COLOR_BGR2GRAY)\n",
    "    HU = cv2.HuMoments(cv2.moments(img_binary)).flatten()\n",
    "    return HU\n",
    "\n",
    "def HU():\n",
    "    print(\"HU\\n\")\n",
    "\n",
    "    file = open(\"./Feature-Extraction/Hu-Moments.txt\", \"w\")\n",
    "\n",
    "    lstFiles = []  # nombre de imagenes\n",
    "    path = r\"./Image-Segmentation2\"\n",
    "    for (path, _, archivos) in tqdm(walk(path)):\n",
    "        for arch in archivos:\n",
    "            (nomArch, ext) = os.path.splitext(arch)\n",
    "            if (ext == \".JPG\"):\n",
    "                lstFiles.append(nomArch + ext)\n",
    "                direc = path + \"/\" + nomArch + ext\n",
    "                name = nomArch + ext\n",
    "                #print(nomArch + ext)\n",
    "                img_binary = cv2.imread(direc)\n",
    "                \n",
    "                HU = HU_oper(img_binary)\n",
    "                file.write(name)\n",
    "                for item in range(len(HU)):\n",
    "                    # print(HU[item])\n",
    "                    num = str(HU[item])\n",
    "                    file.write(\",%s\" % num[0:25])\n",
    "                    # print(num[0:22])\n",
    "                file.write(\",\" + name[0] + \"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "    file = open(r\"./Feature-Extraction/Hu-Moments-Nmz.txt\", \"w\")\n",
    "\n",
    "    data = pd.read_csv(r'./Feature-Extraction/Hu-Moments.txt', sep=',', header=None)\n",
    "\n",
    "    name = data.iloc[:, 0]\n",
    "    value = data.iloc[:, 1:-1]\n",
    "    tag = data.iloc[:, -1]\n",
    "\n",
    "    # print(value)\n",
    "    normalizedata = normalize(value, axis=0, norm='max')\n",
    "    # print(normalizedata)\n",
    "\n",
    "\n",
    "    for row in range(len(normalizedata)):\n",
    "        file.write(name[row])\n",
    "        for colm in range(len(normalizedata[row])):\n",
    "            # print(HU[item])\n",
    "            num = str(normalizedata[row][colm])\n",
    "            file.write(\",%s\" % num[0:25])\n",
    "            # print(num[0:22])\n",
    "        file.write(\",\" + str(tag[row]) + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "# HU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmKHmlXWQRs7",
    "outputId": "41b9b1f0-e30b-4ab5-9213-4167c3667a5b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def featureNormalize(X):\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma = np.std(X, axis=0)\n",
    "    normalized_X = (X - mu) / sigma\n",
    "    \n",
    "    return (normalized_X, mu, sigma)\n",
    "\n",
    "def GM_oper(img_binary):\n",
    "    img_binary = cv2.cvtColor(img_binary, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, img_binary = cv2.threshold(img_binary, 127, 255, 0)\n",
    "    contours, hierarchy = cv2.findContours(img_binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    cnt = max(contours, key=cv2.contourArea)\n",
    "    # reshape contour to 2d array\n",
    "    # cnt = cnt.reshape(cnt.shape[0], cnt.shape[2])\n",
    "    print(cnt.shape)\n",
    "    # apply PCA to contour and keep first 25 components\n",
    "    # pca = PCA(n_components=2)\n",
    "    # cnt_pca = pca.fit_transform(cnt).flatten()\n",
    "    # print(cnt_pca.shape)\n",
    "    # return cnt_pca\n",
    "    # print(cnt.shape)\n",
    "    # # Area\n",
    "    # area = cv2.contourArea(cnt)\n",
    "    # # Perimetro\n",
    "    # perimeter = cv2.arcLength(cnt, True)\n",
    "\n",
    "    # # Relacin de aspecto\n",
    "    # x, y, w, h = cv2.boundingRect(cnt)\n",
    "    # aspect_ratio = float(w) / h\n",
    "\n",
    "    # # Grado\n",
    "    # rect_area = w * h\n",
    "    # extent = float(area) / rect_area\n",
    "\n",
    "    # # ConvexHull\n",
    "    # hull = cv2.convexHull(cnt)\n",
    "    # hull_area = cv2.contourArea(hull)\n",
    "\n",
    "    # # Solidez\n",
    "    # solidity = float(area) / hull_area\n",
    "\n",
    "    # # Dimetro equivalente\n",
    "    # equi_diameter = np.sqrt(4 * area / np.pi)\n",
    "    \n",
    "    return cnt\n",
    "\n",
    "\n",
    "# The Contour Features are extracted from each of the images and we proceed to save them in a. txt file\n",
    "def GM():\n",
    "    print(\"GM\\n\")\n",
    "\n",
    "    file = open(\"./Feature-Extraction/Geometric.txt\", \"w\")\n",
    "\n",
    "    lstFiles = []  # nombre de imagenes\n",
    "    path = r\"./Image-Segmentation2\"\n",
    "    for (path, _, archivos) in walk(path):\n",
    "        for arch in archivos:\n",
    "            (nomArch, ext) = os.path.splitext(arch)\n",
    "            if (ext == \".JPG\"):\n",
    "                lstFiles.append(nomArch + ext)\n",
    "                direc = path + \"/\" + nomArch + ext\n",
    "                name = nomArch + ext\n",
    "                # print(nomArch + ext)\n",
    "                img_binary = cv2.imread(direc)\n",
    "                cnt_pca = GM_oper(img_binary)\n",
    "                print(len(cnt_pca))\n",
    "                file.write(name)\n",
    "                for item in range(len(cnt_pca)):\n",
    "                    # print(HU[item])\n",
    "                    num = str(cnt_pca[item])\n",
    "                    file.write(\",%s\" % num)\n",
    "                    # print(num[0:22])\n",
    "                # file.write(\",\" + str(cnt_pca) + \"\\n\")\n",
    "                file.write(\",\" + name[0] + \"\\n\")\n",
    "                # file.write(\",%.4f\" % area)\n",
    "                # file.write(\",%.4f\" % perimeter)\n",
    "                # file.write(\",%.4f\" % aspect_ratio)\n",
    "                # file.write(\",%.4f\" % extent)\n",
    "                # file.write(\",%.4f\" % hull_area)\n",
    "                # file.write(\",%.4f\" % solidity)\n",
    "                # file.write(\",%.4f\" % equi_diameter)\n",
    "                # file.write(\",\" + name[0] + \"\\n\")\n",
    "    file.close()\n",
    "GM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYciicz8QRs7",
    "outputId": "e5d39aa7-8d77-4bee-a1b1-a56cce8a7bb9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cof\n",
      "\n",
      "EF:  (1803, 52)\n",
      "HOG:  (1803, 6804)\n"
     ]
    }
   ],
   "source": [
    "# # After obtaining the characteristics individually we proceed to make a unification \n",
    "def combineFeatures(preprocced_img):\n",
    "    value_EF = EF_oper(preprocced_img)\n",
    "    print(\"size EF: \",value_EF.shape)\n",
    "    # value_HU = HU_oper(preprocced_img)\n",
    "    # print(\"size HU: \",value_HU.shape)\n",
    "    # normalized_HU = normalize(value_HU.reshape(-1,1),norm='max')\n",
    "    # print(\"size HU: \",normalized_HU.shape)\n",
    "    # value_GM = GM_oper(preprocced_img)\n",
    "    # print(\"size GM: \",len(value_GM))\n",
    "    VALUR_HOG = HOG_oper(preprocced_img)\n",
    "    print(\"size HOG: \",VALUR_HOG.shape)\n",
    "\n",
    "    # combine all values \n",
    "    value = np.concatenate((value_EF, VALUR_HOG), axis=None)\n",
    "    return value\n",
    "\n",
    "def CoF():\n",
    "    print(\"Cof\\n\")\n",
    "\n",
    "    file = open(\"./Feature-Extraction/CoF.txt\", \"w\")\n",
    "    file2 = open(\"./Feature-Extraction/HOG_EF.txt\", \"w\")\n",
    "\n",
    "    data_EF = pd.read_csv(r'./Feature-Extraction/Elliptic-Fourier.txt', sep=',', header=None)\n",
    "    name_EF = data_EF.iloc[:, 0]\n",
    "    value_EF = data_EF.iloc[:, 1:-1]\n",
    "    tag_EF = data_EF.iloc[:, -1]\n",
    "    print(\"EF: \",value_EF.shape)\n",
    "    # -------------------------------- HM---------------------------------#\n",
    "    # data_HM = pd.read_csv(base + r'Feature-Extraction/Hu-Moments.txt', sep=',', header=None)\n",
    "    # value_HM = data_HM.iloc[:, 1:-1]\n",
    "    # normalizedata = normalize(value_HM, axis=0, norm='max')\n",
    "    # print(\"HM: \",normalizedata.shape)\n",
    "    # -------------------------------- GM---------------------------------#\n",
    "    # data_GM = pd.read_csv(base + r'Feature-Extraction/Geometric.txt', sep=',', header=None)\n",
    "    # value_GM = data_GM.iloc[:, 1:-1]\n",
    "    # print(\"GM: \",value_GM.shape)\n",
    "    # -------------------------------- HOG---------------------------------#\n",
    "    data_HOG = pd.read_csv(base + r'Feature-Extraction/Histogram-of-Oriented-Gradients.txt', sep=',', header=None)\n",
    "    value_HOG = data_HOG.iloc[:, 1:-1]\n",
    "    print(\"HOG: \",value_HOG.shape)\n",
    "    # -------------------------------- Save Cof ---------------------------------#\n",
    "    \n",
    "    for row in range(len(value_EF)):\n",
    "        # file.write(name_EF[row])\n",
    "        file2.write(name_EF[row])\n",
    "        for colm in range(value_EF.shape[1]):\n",
    "            # file.write(\",%.4f\" %value_EF.iloc[row,colm])\n",
    "            file2.write(\",%.4f\" %value_EF.iloc[row,colm])\n",
    "        # for colm in range(len(normalizedata[row])):\n",
    "        #     num = str(normalizedata[row][colm])\n",
    "        #     file.write(\",%s\" % num[0:25])\n",
    "        # for colm in range(value_GM.shape[1]):\n",
    "        #     file.write(\",%.4f\" %value_GM.iloc[row,colm])\n",
    "        for colm in range(value_HOG.shape[1]):\n",
    "            # file.write(\",%.4f\" %value_HOG.iloc[row,colm])\n",
    "            file2.write(\",%.4f\" %value_HOG.iloc[row,colm])\n",
    "        file.write(\",%s\" %tag_EF[row] + \"\\n\")\n",
    "        file2.write(\",%s\" %tag_EF[row] + \"\\n\")\n",
    "        \n",
    "    file.close()\n",
    "    file2.close()\n",
    "\n",
    "CoF()\n",
    "# EF:  (1827, 52)\n",
    "# HM:  (1827, 7)\n",
    "# GM:  (1827, 7)\n",
    "# HOG:  (1827, 1250)\n",
    "\n",
    "# img = preprocess(r\"dataset\\men\\0\\0_men (7).JPG\")\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "# value = HOG_oper(img)\n",
    "# print(value.shape)\n",
    "\n",
    "# # load model and predict class\n",
    "# clf = joblib.load(r'Feature-Extraction\\SVM\\modelo_entrenado-Histogram-of-Oriented-Gradients-PCA-20%.pkl')\n",
    "# # clf.predict(value)\n",
    "\n",
    "# # loop over the testing images in us folder\n",
    "\n",
    "# path = r\"./dataset/\"\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# for (path, _, archivos) in walk(path):\n",
    "#     for arch in archivos:\n",
    "#             (nomArch, ext) = os.path.splitext(arch)\n",
    "#             if (ext == \".JPG\"):\n",
    "#                 # load the image, convert it to grayscale, and resize it to be a fixed\n",
    "#                 # 64x64 pixels, ignoring aspect ratio\n",
    "#                 direc = path + \"/\" + nomArch + ext\n",
    "#                 # print(direc)\n",
    "#                 image = preprocess(direc)\n",
    "#                 # plt_t(\"after preprocess\",image, cmap='gray')\n",
    "#                 image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "#                 value = HOG_oper(image)\n",
    "#                 # value = combineFeatures(image)\n",
    "#                 # load the image and classify it\n",
    "#                 # print(path[-1])\n",
    "#                 is_corr = 1 if (clf.predict(value)[0]) == path[-1] else 0\n",
    "#                 if(is_corr == 0):\n",
    "#                     print(\"incorrect: \",direc)\n",
    "#                     plt_t(\"incorrect\",image, cmap='gray')\n",
    "                 \n",
    "#                 correct += is_corr\n",
    "#                 total+=1\n",
    "#                 # show the prediction\n",
    "# print(\"correct: \",correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PCA \n",
    "\n",
    "def featureNormalize(X):\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma = np.std(X, axis=0)\n",
    "    normalized_X = (X - mu) / sigma\n",
    "    \n",
    "    return (normalized_X, mu, sigma)\n",
    "\n",
    "\n",
    "\n",
    "def PCAA():\n",
    "    print(\"HU\\n\")\n",
    "\n",
    "    file = open(\"./Feature-Extraction/pca.txt\", \"w\")\n",
    "\n",
    "    lstFiles = []  # nombre de imagenes\n",
    "    path = r\"./Image-Segmentation2\"\n",
    "    for (path, _, archivos) in walk(path):\n",
    "        for arch in archivos:\n",
    "            (nomArch, ext) = os.path.splitext(arch)\n",
    "            if (ext == \".JPG\"):\n",
    "                lstFiles.append(nomArch + ext)\n",
    "                direc = path + \"/\" + nomArch + ext\n",
    "                name = nomArch + ext\n",
    "                #print(nomArch + ext)\n",
    "                img_binary = cv2.imread(direc)\n",
    "                img_binary = cv2.cvtColor(img_binary, cv2.COLOR_BGR2GRAY)\n",
    "                # make returned image as float32 datatype\n",
    "                img_binary = np.float32(img_binary/255.0)\n",
    "                \n",
    "                X = normalize(img_binary, axis=0, norm='max')\n",
    "                # take the most significant 25 vectors of the image and flatten it using PCA\n",
    "                pca = PCA(n_components=25)\n",
    "                X = pca.fit_transform(X)\n",
    "                # print(X)\n",
    "                file.write(name)\n",
    "                for item in range(len(X)):\n",
    "                    for item2 in range(len(X[item])):\n",
    "                        file.write(\",%s\" % item2)\n",
    "                        # print(HU[item])\n",
    "                    # print(num[0:22])\n",
    "    #             file.write(name)\n",
    "    #             for item in range(len(HU)):\n",
    "    #                 # print(HU[item])\n",
    "    #                 num = str(HU[item])\n",
    "    #                 file.write(\",%s\" % num[0:25])\n",
    "    #                 # print(num[0:22])\n",
    "                file.write(\",\" + name[0] + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "\n",
    "PCAA()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JEB98uEZQRs7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We then proceed to create our classification methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZkiEc6i7QRs7",
    "outputId": "c933619a-7d4c-489c-d3e2-5dd0c232b7c9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#As the first method of classification we use Support Vector Machine \n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "base = \"./\"\n",
    "\n",
    "def SVM(txt,test_percentage):\n",
    "    pathsvm = base + \"Feature-Extraction/SVM\"\n",
    "    \n",
    "    if not os.path.exists(pathsvm):\n",
    "        os.makedirs(pathsvm)\n",
    "        \n",
    "    data = pd.read_csv(base + '/Feature-Extraction/'+txt+'.txt',sep=',',header=None)\n",
    "    \n",
    "    # we shuffle it for better performance \n",
    "    # data=shuffle(data, random_state=42)\n",
    "    \n",
    "    s=data.shape\n",
    "    # print(s)\n",
    "    col=[]\n",
    "    #data.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n",
    "     \n",
    "    for x in range(0, s[1]):\n",
    "        if x==0:\n",
    "            col.append(\"NAME\")\n",
    "        elif x ==s[1]-1:\n",
    "            col.append(\"TAG\")\n",
    "        else:\n",
    "            col.append(\"VALOR-\"+str(x))\n",
    "    \n",
    "    #se asigna el vector con los nombres de las columnas creado previamente y se las asignamos a la tabla\n",
    "    data.columns = col\n",
    "    \n",
    "    ##print(data.groupby(['TAG'])['TAG'].count())\n",
    "    vals_to_replace = { '0':'0', '1':'1', '2':'2', '3':'3', '4':'4', '5':'5',\n",
    "                         0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5'}\n",
    "    \n",
    "    data['TAG'] = data['TAG'].map(vals_to_replace)\n",
    "    \n",
    "    #print(data.tail())\n",
    "    \n",
    "    no_col=['NAME','TAG']\n",
    "    #obtener todas las columnas\n",
    "    allValuesName = [x for x in col if x not in no_col]\n",
    "    #se obtienen solo los coefficientes\n",
    "    value=data[allValuesName]\n",
    "    # print value type\n",
    "    # print(type(value))\n",
    "    # convert to float\n",
    "    # value=value.astype(float)\n",
    "    \n",
    "    tags=data[col[-1]] #columna de tags\n",
    "    \n",
    "    data['gender'] = data['NAME'].map(lambda x: 'woman' in x.lower())\n",
    "    \n",
    "    # i added a stratify to the train_test_split to make sure that the train and test sets have the same proportion of class labels as the input data\n",
    "    # its based on gender\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(value,tags,test_size=test_percentage,stratify=data['gender'], random_state=42)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train,Y_train,test_size=test_percentage,stratify=Y_train, random_state=42)\n",
    "    C_range=[0.01, 0.1, 1, 10, 100, 1000]\n",
    "    gamma_range=[1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5]\n",
    "    parameters= [\n",
    "        {\n",
    "            'kernel': ['rbf'],\n",
    "            'gamma': [1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5],\n",
    "            'C': [0.01, 0.1, 1, 10, 100, 1000]\n",
    "        }#, \n",
    "        #{\n",
    "        #    'kernel': ['linear'],\n",
    "        #    'C': [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "        #}, \n",
    "        #{\n",
    "        #    'kernel': ['sigmoid'],\n",
    "        #    'gamma': [1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5],\n",
    "        #    'C': [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "        #}, \n",
    "        # {\n",
    "        #    'kernel': ['poly'],\n",
    "        #    'gamma': [1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5],\n",
    "        #    'C': C_range\n",
    "        # }\n",
    "        \n",
    "    ]\n",
    "    # \n",
    "    clf =GridSearchCV(svm.SVC(decision_function_shape='ovr'), param_grid=parameters,cv=3)\n",
    "    # pipe = Pipeline([('scaler', StandardScaler()), ('svm', clf)])\n",
    "    clf.fit(X_train.values,Y_train)\n",
    "    scores = clf.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "    print(\"The best parameters are %s with a score of %0.2f\" % (clf.best_params_, clf.best_score_))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot)\n",
    "    plt.xlabel('Gamma')\n",
    "    plt.ylabel('C')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "    plt.yticks(np.arange(len(C_range)), C_range)\n",
    "    fig=plt.title('Heat map '+txt+'-'+str(int(test_percentage*100))+'%')\n",
    "    fig.get_figure().savefig(base + r'Feature-Extraction/SVM/Heatmap-'+txt+'-'+str(int(test_percentage*100))+'%.jpg')\n",
    "    plt.show()\n",
    "    print(clf.best_params_)#mejor parametro\n",
    "    \n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    params = clf.cv_results_['params']\n",
    "    for m, s, p in zip(means, stds, params):\n",
    "        print(\"%0.3f (+/-%0.3f) para %r\"%(m, 2*s, p))\n",
    "    \n",
    "    y_pred = clf.predict(X_val)\n",
    "    \n",
    "    target_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "    \n",
    "    table=classification_report(Y_val,y_pred, target_names=target_names)\n",
    "    table=str(table)\n",
    "    print(table)\n",
    "    file = open(base +r\"Feature-Extraction/SVM/Reports.txt\", \"a+\")\n",
    "    file.write(txt+'-'+str(int(test_percentage*100))+'%\\n\\n')\n",
    "    file.write(table+'\\n')\n",
    "    file.write(\"Accuracy: \"+str(clf.score(value,tags)))\n",
    "    mat=confusion_matrix(Y_val, y_pred)\n",
    "    \n",
    "    Matrizconf=sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True,\n",
    "               xticklabels=target_names, yticklabels= target_names )\n",
    "    \n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    mat=plt.title('Confusion map '+txt+'-'+str(int(test_percentage*100))+'%')\n",
    "    \n",
    "    Matrizconf.get_figure().savefig(base + r'Feature-Extraction/SVM/Confusionmap-'+txt+'-'+str(int(test_percentage*100))+'%.png')\n",
    "    print(Y_train.groupby(Y_train).count())#datos de entrenamiento\n",
    "    print(Y_val.groupby(Y_val).count(),collections.Counter(y_pred))#datos de testeo\n",
    "    \n",
    "    joblib.dump(clf,base +r'Feature-Extraction/SVM/modelo_entrenado-'+txt+'-'+str(int(test_percentage*100))+'%.pkl')\n",
    "    \n",
    "    # se llama el modelo\n",
    "    #clf=joblib.load('modelo_entrenado.pkl')\n",
    "    # se toma todo el dataset\n",
    "    print(clf.score)\n",
    "    print(\"Accuracy: \"+str(clf.score(X_test,Y_test)))\n",
    "    file.close()\n",
    "    \n",
    "    print(\"Accuracy: \"+str(clf.score(value,tags)))\n",
    "# porcentaje_test=[0.30,0.25,0.20]\n",
    "# SVM(\"Elliptic-Fourier\",0.2)\n",
    "SVM(\"Geometric\" ,0.2)\n",
    "# SVM(\"HOG_EF\" ,0.2)\n",
    "# SVM(\"Cof\" ,0.2)\n",
    "# SVM(\"VHIST\" ,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7utyeV3fQRs8",
    "outputId": "81cd0534-eb59-450f-e8cf-1da64d07bb0b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#As a second method of classification we use K-Nearest Neighbour Classifier\n",
    "def KNN(txt,test):\n",
    "       \n",
    "    pathknn = base +\"Feature-Extraction/KNN\"\n",
    "    if not os.path.exists(pathknn):\n",
    "        os.makedirs(pathknn)\n",
    "        \n",
    "    data = pd.read_csv(base +'Feature-Extraction/'+txt+'.txt',sep=',',header=None)\n",
    "    data=shuffle(data, random_state=0)\n",
    "    \n",
    "    s=data.shape# tamao de dataframe\n",
    "    col=[]\n",
    "    #data.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n",
    "     \n",
    "    for x in range(0, s[1]):\n",
    "        if x==0:\n",
    "            col.append(\"NAME\")\n",
    "        elif x ==s[1]-1:\n",
    "            col.append(\"TAG\")\n",
    "        else:\n",
    "            col.append(\"VALOR-\"+str(x))\n",
    "    \n",
    "    #se asigna el vector con los nombres de las columnas creado previamente y se las asignamos a la tabla\n",
    "    data.columns = col\n",
    "    \n",
    "    ##print(data.groupby(['TAG'])['TAG'].count())\n",
    "    vals_to_replace = { '0':'0', '1':'1', '2':'2', '3':'3', '4':'4', '5':'5',\n",
    "                         0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5'}\n",
    "    \n",
    "    data['TAG'] = data['TAG'].map(vals_to_replace)\n",
    "    \n",
    "    #print(data.tail())\n",
    "    \n",
    "    no_col=['NAME','TAG']\n",
    "    #obtener todas las columnas\n",
    "    Name_value = [x for x in col if x not in no_col]\n",
    "    #se obtienen solo los coefficientes\n",
    "    value=data[Name_value]\n",
    "    \n",
    "    tags=data[col[-1]] #columna de tags\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(value,tags,test_size=test, random_state=0)\n",
    "    C_range=[1,2,5,25,50,100]\n",
    "    gamma_range=[1,2,5,10]\n",
    "    parameters= [\n",
    "        {\n",
    "            'n_neighbors': [1,2,5,25,50,100],\n",
    "            'metric': ['minkowski'],\n",
    "            'p': [1,2,5,10]\n",
    "        }        \n",
    "    ]\n",
    "    \n",
    "    clf = GridSearchCV(KNeighborsClassifier(), param_grid=parameters, cv=5)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    \n",
    "    scores = clf.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "    print(\"The best parameters are %s with a score of %0.2f\" % (clf.best_params_, clf.best_score_))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot)\n",
    "    plt.xlabel('P')\n",
    "    plt.ylabel('N neighbors')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "    plt.yticks(np.arange(len(C_range)), C_range)\n",
    "    fig=plt.title('Heat map '+txt+'-'+str(int(test*100))+'%')\n",
    "    fig.get_figure().savefig(base + 'Feature-Extraction/KNN/Heatmap-'+txt+'-'+str(int(test*100))+'%.jpg')\n",
    "    plt.show()\n",
    "    print(clf.best_params_)#mejor parametro\n",
    "    \n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    params = clf.cv_results_['params']\n",
    "    for m, s, p in zip(means, stds, params):\n",
    "        print(\"%0.3f (+/-%0.3f) para %r\"%(m, 2*s, p))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    target_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "    \n",
    "    table=classification_report(Y_test,y_pred, target_names=target_names)\n",
    "    table=str(table)\n",
    "    print(table)\n",
    "    file = open(base +\"Feature-Extraction/KNN/Reports.txt\", \"a+\")\n",
    "    file.write(txt+'-'+str(int(test*100))+'%\\n\\n')\n",
    "    file.write(table+'\\n')\n",
    "    mat=confusion_matrix(Y_test, y_pred)\n",
    "    \n",
    "    Matrizconf=sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True,\n",
    "               xticklabels=target_names, yticklabels= target_names )\n",
    "    \n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    mat=plt.title('Confusion map '+txt+'-'+str(int(test*100))+'%')\n",
    "    \n",
    "    Matrizconf.get_figure().savefig(base + 'Feature-Extraction/KNN/Confusionmap-'+txt+'-'+str(int(test*100))+'%.png')\n",
    "    print(Y_train.groupby(Y_train).count())#datos de entrenamiento\n",
    "    print(Y_test.groupby(Y_test).count(),collections.Counter(y_pred))#datos de testeo\n",
    "    \n",
    "    joblib.dump(clf,base + 'Feature-Extraction/KNN/modelo_entrenado-'+txt+'-'+str(int(test*100))+'%.pkl')\n",
    "    \n",
    "    # se llama el modelo\n",
    "    #clf=joblib.load('modelo_entrenado.pkl')\n",
    "    # se toma todo el dataset\n",
    "    print(clf.score(X_test,Y_test))\n",
    "    file.close()\n",
    "\n",
    "\n",
    "# porcentaje_test=[0.30,0.25,0.20]\n",
    "# KNN(\"Elliptic-Fourier\",porcentaje_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PGEK89ZeQRs8",
    "outputId": "9ec65ef6-f410-4d9a-87c6-b01af6a7b413",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#As Tecer method of classification we use Neural Networks\n",
    "def NN(txt,test):\n",
    "    \n",
    "    pathnn = base + r\"Feature-Extraction/NN\"\n",
    "    if not os.path.exists(pathnn):\n",
    "        os.makedirs(pathnn)\n",
    "        \n",
    "    data = pd.read_csv(base +'Feature-Extraction/'+txt+'.txt',sep=',',header=None)\n",
    "    data=shuffle(data, random_state=0)\n",
    "    \n",
    "    s=data.shape# tamao de dataframe\n",
    "    col=[]\n",
    "    #data.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n",
    "     \n",
    "    for x in range(0, s[1]):\n",
    "        if x==0:\n",
    "            col.append(\"NAME\")\n",
    "        elif x ==s[1]-1:\n",
    "            col.append(\"TAG\")\n",
    "        else:\n",
    "            col.append(\"VALOR-\"+str(x))\n",
    "    \n",
    "    #se asigna el vector con los nombres de las columnas creado previamente y se las asignamos a la tabla\n",
    "    data.columns = col\n",
    "    \n",
    "    ##print(data.groupby(['TAG'])['TAG'].count())\n",
    "    vals_to_replace = { '0':'0', '1':'1', '2':'2', '3':'3', '4':'4', '5':'5',\n",
    "                         0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5'}\n",
    "    \n",
    "    data['TAG'] = data['TAG'].map(vals_to_replace)\n",
    "    \n",
    "    #print(data.tail())\n",
    "    \n",
    "    no_col=['NAME','TAG']\n",
    "    #obtener todas las columnas\n",
    "    Name_value = [x for x in col if x not in no_col]\n",
    "    #se obtienen solo los coefficientes\n",
    "    value=data[Name_value]\n",
    "    \n",
    "    tags=data[col[-1]] #columna de tags\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(value,tags,test_size=test, random_state=0)\n",
    "    C_range=[1,0.1,0.01,0.001,0.0001,0]\n",
    "    gamma_range=[(100,1), (100,2), (100,3)]\n",
    "    parameters= [\n",
    "        {\n",
    "            'solver':['lbfgs'], \n",
    "            'alpha':[1,0.1,0.01,0.001,0.0001,0],\n",
    "            'hidden_layer_sizes':[(100,1), (100,2), (100,3)]\n",
    "        }\n",
    "    ]\n",
    "        \n",
    "    clf =GridSearchCV(MLPClassifier(), param_grid=parameters, cv=5)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    \n",
    "    scores = clf.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "    print(\"The best parameters are %s with a score of %0.2f\" % (clf.best_params_, clf.best_score_))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot)\n",
    "    plt.xlabel('hidden_layer_sizes')\n",
    "    plt.ylabel('Alpha')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "    plt.yticks(np.arange(len(C_range)), C_range)\n",
    "    fig=plt.title('Validation accuracy')\n",
    "    fig.get_figure().savefig(base + r'Feature-Extraction/NN/Heatmap-'+txt+'-'+str(int(test*100))+'%.jpg')\n",
    "    plt.show()\n",
    "    print(clf.best_params_)#mejor parametro\n",
    "    \n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    params = clf.cv_results_['params']\n",
    "    for m, s, p in zip(means, stds, params):\n",
    "        print(\"%0.3f (+/-%0.3f) para %r\"%(m, 2*s, p))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    target_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "    \n",
    "    table=classification_report(Y_test,y_pred, target_names=target_names)\n",
    "    table=str(table)\n",
    "    print(table)\n",
    "    file = open(base + r\"Feature-Extraction/NN/Reports.txt\", \"a+\")\n",
    "    file.write(txt+'-'+str(int(test*100))+'%\\n\\n')\n",
    "    file.write(table+'\\n')\n",
    "    mat=confusion_matrix(Y_test, y_pred)\n",
    "    \n",
    "    Matrizconf=sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True,\n",
    "               xticklabels=target_names, yticklabels= target_names )\n",
    "    \n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    mat=plt.title('Confusion map '+txt+'-'+str(int(test*100))+'%')\n",
    "    \n",
    "    Matrizconf.get_figure().savefig(base + r'Feature-Extraction/NN/Confusionmap-'+txt+'-'+str(int(test*100))+'%.png')\n",
    "    print(Y_train.groupby(Y_train).count())#datos de entrenamiento\n",
    "    print(Y_test.groupby(Y_test).count(),collections.Counter(y_pred))#datos de testeo\n",
    "    \n",
    "    joblib.dump(clf,base + r'Feature-Extraction/NN/modelo_entrenado-'+txt+'-'+str(int(test*100))+'%.pkl')\n",
    "    \n",
    "    # se llama el modelo\n",
    "    #clf=joblib.load('modelo_entrenado.pkl')\n",
    "    # se toma todo el dataset\n",
    "    print(clf.score(X_test,Y_test))\n",
    "    file.close()\n",
    "\n",
    "# porcentaje_test=[0.30,0.25,0.20]\n",
    "# NN(\"Elliptic-Fourier\",porcentaje_test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "#As Tecer method of classification we use Neural Networks\n",
    "def RandomForest(txt,test):\n",
    "\n",
    "    pathnn = base + r\"Feature-Extraction/RNDMFOREST\"\n",
    "    if not os.path.exists(pathnn):\n",
    "        os.makedirs(pathnn)\n",
    "\n",
    "    data = pd.read_csv(base +'Feature-Extraction/'+txt+'.txt',sep=',',header=None)\n",
    "    data=shuffle(data, random_state=0)\n",
    "\n",
    "    s=data.shape# tamao de dataframe\n",
    "    col=[]\n",
    "    #data.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n",
    "\n",
    "    for x in range(0, s[1]):\n",
    "        if x==0:\n",
    "            col.append(\"NAME\")\n",
    "        elif x ==s[1]-1:\n",
    "            col.append(\"TAG\")\n",
    "        else:\n",
    "            col.append(\"VALOR-\"+str(x))\n",
    "\n",
    "    #se asigna el vector con los nombres de las columnas creado previamente y se las asignamos a la tabla\n",
    "    data.columns = col\n",
    "\n",
    "    ##print(data.groupby(['TAG'])['TAG'].count())\n",
    "    vals_to_replace = { '0':'0', '1':'1', '2':'2', '3':'3', '4':'4', '5':'5',\n",
    "                         0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5'}\n",
    "\n",
    "    data['TAG'] = data['TAG'].map(vals_to_replace)\n",
    "\n",
    "    #print(data.tail())\n",
    "\n",
    "    no_col=['NAME','TAG']\n",
    "    #obtener todas las columnas\n",
    "    Name_value = [x for x in col if x not in no_col]\n",
    "    #se obtienen solo los coefficientes\n",
    "    value=data[Name_value]\n",
    "\n",
    "    tags=data[col[-1]] #columna de tags\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(value,tags,test_size=test, random_state=0)\n",
    "\n",
    "    \n",
    "    rr = GridSearchCV(RandomForestClassifier(),param_grid={'n_estimators': [100,1000]},cv=3,verbose=0,n_jobs=-1)\n",
    "    # clf = SGDClassifier(loss='hinge')\n",
    "    clf = Pipeline(steps=[('std', StandardScaler()),('classifier', rr)])\n",
    "    clf.fit(X_train.values,Y_train)\n",
    "\n",
    "    # scores = clf.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "    # print(\"The best parameters are %s with a score of %0.2f\" % (clf['classifier'].best_params_, clf['classifier'].best_score_))\n",
    "    #\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "    # plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot)\n",
    "    # plt.xlabel('hidden_layer_sizes')\n",
    "    # plt.ylabel('Alpha')\n",
    "    # plt.colorbar()\n",
    "    # plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "    # plt.yticks(np.arange(len(C_range)), C_range)\n",
    "    fig=plt.title('Validation accuracy')\n",
    "    fig.get_figure().savefig(base + r'Feature-Extraction/RNDMFOREST/Heatmap-'+txt+'-'+str(int(test*100))+'%.jpg')\n",
    "    # plt.show()\n",
    "    # print(clf.best_params_)#mejor parametro\n",
    "\n",
    "    # means = clf.cv_results_['mean_test_score']\n",
    "    # stds = clf.cv_results_['std_test_score']\n",
    "    # params = clf.cv_results_['params']\n",
    "    # for m, s, p in zip(means, stds, params):\n",
    "    #     print(\"%0.3f (+/-%0.3f) para %r\"%(m, 2*s, p))\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    target_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "\n",
    "    table=classification_report(Y_test,y_pred, target_names=target_names)\n",
    "    table=str(table)\n",
    "    print(table)\n",
    "    file = open(base + r\"Feature-Extraction/RNDMFOREST/Reports.txt\", \"a+\")\n",
    "    file.write(txt+'-'+str(int(test*100))+'%\\n\\n')\n",
    "    file.write(table+'\\n')\n",
    "    mat=confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "    Matrizconf=sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True,\n",
    "               xticklabels=target_names, yticklabels= target_names )\n",
    "\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    mat=plt.title('Confusion map '+txt+'-'+str(int(test*100))+'%')\n",
    "\n",
    "    Matrizconf.get_figure().savefig(base + r'Feature-Extraction/RNDMFOREST/Confusionmap-'+txt+'-'+str(int(test*100))+'%.png')\n",
    "    print(Y_train.groupby(Y_train).count())#datos de entrenamiento\n",
    "    print(Y_test.groupby(Y_test).count(),collections.Counter(y_pred))#datos de testeo\n",
    "\n",
    "    joblib.dump(clf,base + r'Feature-Extraction/RNDMFOREST/modelo_entrenado-'+txt+'-'+str(int(test*100))+'%.pkl')\n",
    "\n",
    "    # se llama el modelo\n",
    "    #clf=joblib.load('modelo_entrenado.pkl')\n",
    "    # se toma todo el dataset\n",
    "    print(clf.score(X_test,Y_test))\n",
    "    file.close()\n",
    "\n",
    "# porcentaje_test=[0.30,0.25,0.20]\n",
    "# NN(\"Elliptic-Fourier\",porcentaje_test[1])\n",
    "RandomForest(\"Histogram-of-Oriented-Gradients-PCA\",0.2)\n",
    "# RandomForest(\"Elliptic-Fourier\",0.2)\n",
    "# RandomForest(\"pca\",0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aatta\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but PCA was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        56\n",
      "           1       0.90      0.95      0.93        60\n",
      "           2       0.85      0.82      0.84        57\n",
      "           3       0.69      0.72      0.71        58\n",
      "           4       0.82      0.79      0.81        63\n",
      "           5       0.96      0.96      0.96        67\n",
      "\n",
      "    accuracy                           0.87       361\n",
      "   macro avg       0.87      0.87      0.87       361\n",
      "weighted avg       0.87      0.87      0.87       361\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aatta\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but PCA was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG\n",
      "0    231\n",
      "1    240\n",
      "2    249\n",
      "3    250\n",
      "4    234\n",
      "5    238\n",
      "Name: TAG, dtype: int64\n",
      "TAG\n",
      "0    56\n",
      "1    60\n",
      "2    57\n",
      "3    58\n",
      "4    63\n",
      "5    67\n",
      "Name: TAG, dtype: int64 Counter({'5': 67, '1': 63, '3': 61, '4': 61, '2': 55, '0': 54})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aatta\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but PCA was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8698060941828255\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAHJCAYAAABkEFswAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABtyUlEQVR4nO3dd1gU19fA8e/SpQliwRIb9o4RSyzYY2wJlvgz9ha7UVGxKzbsvSuWRI0NNdbYEmPvJSZ2ROwNQbDQ9/2Dl40rqIi7O8icj88+j3tnmDl3YffsLXNHo9VqtQghhBBCFcyUDkAIIYQQpiOJXwghhFARSfxCCCGEikjiF0IIIVREEr8QQgihIpL4hRBCCBWRxC+EEEKoiCR+IYQQQkUk8QtVkHWq0if5vRqXvL7p02eb+C9evMjAgQOpXr06pUqVolatWgwfPpw7d+4Y7Zw7d+6kRo0alCxZkpEjRxrsuIULF2bOnDkGO97npk2bNrRp0+ad22vWrMngwYPf+fxD9u/fj4+PzyfFmF6cOHGCr7/+mhIlStCpU6cP7v/HH3/QuXNnKlSoQKlSpfj666/x8/PjwYMHKTrfnDlzKFy48KeGnUR0dDR+fn5s27bNIMf7mL+pyMhIVqxYQYsWLahQoQIlS5akTp06jBkzJsWvS2qdOHGCwoULc+LECQA2bdpE4cKFuXv3rsHPtWDBAvz9/Q1yrN27d9OsWTPKli2Lp6cngwcP5unTp3r7PH78mP79+1OhQgXKli1Lnz59ePTokd4+e/fupVatWlSoUIEJEyYQFxent93Pz48RI0YYJOb0zELpAFJj9erVTJgwgQoVKuDt7U3WrFm5ffs2S5cuZc+ePSxfvpzixYsb/Ly+vr7kzZuXiRMnki1bNoMdd926dbi6uhrseOnd3Llzsbe3T/H+K1asMF4wn5lJkyYRHx/P4sWLcXFxee++vr6+rFmzhvr16zN27FgcHR25ceMGv/zyC5s3b2b27NlUrFjxvcdo3rw5VatWNWQVgIQksWLFCvz8/Ax+7Pd59OgRnTt35sGDB/zwww/07NkTGxsbrly5wsqVK9mxYwdr1qzBzc3NJPFUr16ddevWkTVrVoMfe+bMmfTq1euTj7Nr1y769u1LixYt6Nu3L0+fPmX27Nm0a9eOTZs2YW1tTWxsLF26dOHVq1eMHj2a2NhYpk2bRseOHdmyZQuWlpY8e/aMgQMH0q5dO0qWLMmIESPInz8///vf/wC4e/cumzZtYvv27Z8cc3r32SX+M2fOMH78eFq1asWwYcN05RUqVKBWrVo0adKEIUOGsHXrVoOfOywsjMqVK1OhQgWDHrdMmTIGPV56V6xYMaVD+GyFhYXh4eHBV1999d79Vq9ezZo1axg3bhzNmzfXlVesWJHvvvuOLl260LdvX7Zv307mzJnfeRxXV9d086VWq9UyaNAgHjx4wMaNG8mbN69uW/ny5WncuDFeXl5MmDDBYC3lD8mUKROZMmUyyblSa/78+Xh6ejJmzBhdWf78+WnevDl//vkn9erV4/fff+fKlSts376dggULAlC0aFEaNmzIzp07+fbbbzl79izm5ub07dsXjUbD8ePHOXr0qC7xz5gxgxYtWhi0UZZefXZd/f7+/jg4ONC/f/8k2zJlysTgwYOpW7cuL1680JXv3LmTJk2a4O7uTuXKlRk5ciTPnz/XbZ8zZw516tThwIEDNGrUiBIlSvD111+zefNm4L/uNYB58+bputYGDx5MzZo19WK4e/cuhQsXZtOmTbqyX375hXr16lGyZEmqVq3K6NGj9eJ7u6v/8ePHDBkyBE9PT0qVKkWzZs3Yv3+/3nkKFy7M6tWrGTZsGOXLl8fd3Z0+ffok6T5LLrbdu3fTo0cPypQpw1dffcX8+fN58eIFQ4cO5csvv+Srr75iypQpeuN7d+/eZdCgQVSpUoXixYtTqVIlBg0aRGhoqG6fmjVrMmPGDPz8/Chfvjzly5dn4MCBevsYwtvdsjt37qRx48aUKlWKihUrMmDAAB4/fgwkDCOcPHmSkydP6nWRpuQ1fvHiBSNHjqRSpUq4u7vTr18/VqxYodd13aZNGwYMGECfPn0oW7YsP/7440e9XnPnzsXPz48KFSrg7u6Ot7c3L1++ZPHixVSrVo0vv/yS3r17p+g1vHXrFn369KFy5cqUKVOGNm3acObMGV08hQsX5t69e2zZskXvtXhbXFwcCxYsoHLlynpJP5G9vT3jxo0jNDSU1atX6x1/+fLlfPPNN5QvX55NmzYl29W/b98+mjRpQsmSJalcuTLjxo3j1atXuu0fej/evXuXWrVqATBkyBC99+Dp06dp3bo1pUuXpnz58vj4+PDs2TO981+5coUOHTrg7u5OjRo1UtxIOH36NMePH6dfv356ST+Rk5MTffr0IVeuXMTHxwMwePBg2rVrx6hRoyhXrhxeXl7Exsby7NkzfH19qVGjBiVKlKB8+fL07NkzSZf92rVr+frrrylVqhStW7fm/v37etuT6+r/0GuwadMmihUrxoULF2jRogUlS5akevXqLFmyRLdP4u9s7ty5uv9HRUXh6+tLtWrVKFGiBPXq1WPZsmXvfc3i4+OpXLky33//vV55vnz5ALh9+zYAhw8fJl++fLqkD1CgQAHc3Nw4ePAgABqNBisrKzQaDQCWlpa61/nSpUscPnxY9/4T7/dZJX6tVsvhw4epVKkSGTJkSHafevXq0atXL11X8Pz58+nXrx+lS5dm9uzZ9OzZk927d9OmTRsiIyN1P/fkyRPGjBlD27ZtWbx4Mbly5WLw4MEEBgZSvHhx1q1bB0CzZs0+qmttx44dTJo0iVatWuHv70/Pnj357bffGDduXLL7P336lGbNmnHy5En69evHnDlzyJkzJz179kzyATVjxgzi4+OZPn06gwYN4sCBA0yYMOGDMQ0bNoxChQqxYMECKlasyKxZs2jWrBk2NjbMmjWLmjVrsnTpUn7//XcAXr9+Tdu2bQkMDGTUqFH4+/vTunVrtm/fzvTp0/WOvWbNGs6cOcOECRMYMGAABw8epHPnzro36LtotVpiY2OTfbzPmTNnGDBgAHXr1mXJkiUMGTKE48eP4+3tDcCoUaMoVqwYxYoVY926dRQvXjzFr3HPnj3ZtWsXvXv3ZsaMGbx8+ZJp06YliWHXrl1YWloyb9482rZt+1Gv1/Lly7l//z4zZsygW7dubN++naZNm3LkyBHGjh1L79692b9/P7Nnz37v63Djxg2aNGnCnTt3GD58OFOnTkWj0dCuXTtOnjxJ1qxZWbduHVmyZMHT01P3WiTn8uXLPHnyRJdck+Pm5kaRIkWSfFmaMWMGnTp1Yty4cckOA2zbto2ePXuSP39+5s2bR69evdi6dSs9evTQ+6L5vvdj1qxZmTt3LgDdu3fX/f/UqVO0b98eGxsbZs6cydChQzl58iRt27bVvdcfPXpE69atef78OVOmTOGnn35i6tSpScaSk7Nv3z40Gg0NGjR45z5eXl74+vpiZvbfR+vp06cJDg5mzpw59OzZE3Nzc7p27cqRI0fw9vbG39+fHj16cPToUb25Q6tWrWLUqFFUrVqV+fPnU7p06Q+OX6fkNYCEhNy3b1/q16/P4sWL+fLLL5k6dSqHDh0CSPJ5BzB+/Hj++usvfHx88Pf3p1atWkyaNEmvkfM2MzMzBg8eTO3atfXK9+zZA0ChQoUACAwMTPbLVO7cuQkKCgKgRIkSREREsG/fPh49esSBAwf48ssvAZgyZQpdunTB0dHxva+PSPBZdfWHhoYSFRVFrly5UrT/8+fPWbBgAc2bN2fUqFG68kKFCtGqVSs2bdrEDz/8ACQkt/Hjx1OpUiUA8ubNS40aNfjrr7/o2LGjrjve1dX1o7rmT5w4Qc6cOWnVqhVmZmaUL18eW1vbd7bgli9fzrNnz9i1axdffPEFAJ6enrRv357JkyfTsGFD3YdKoUKF9MY4//77b12yfp+qVavSt29fIOFb9Y4dO3BxcdF96FSuXJldu3Zx9uxZvvnmG27duoWrqysTJ04kd+7cQEKX78WLFzl58qTesTUaDcuXL8fBwQFI6IXp2bMnBw8epHr16u+M6dSpU6mal3HmzBmsra3p0qUL1tbWQELL6+LFi2i1WgoUKKD7Epj4e1uwYMEHX+MTJ05w/Phx5syZQ926dQGoVq0ajRo14saNG3oxmJmZMXbsWGxtbYGExJnS18vOzo4ZM2ZgYWHBV199xebNm3n8+DEbNmzAwcEBT09Pjh8/ztmzZ9/7OsydOxdLS0t+/vln3WtfvXp1GjZsyJQpU9iwYQNlypTBysqKTJkyvfdvOLH1+KH3WZ48eThy5IheWd26dWnWrFmy+2u1WqZOnUrVqlWZOnWqrjxv3ry0b9+ev/76S/c38qH3Y9GiRYGExJA49DNt2jTy5cvHokWLMDc3B6B06dI0aNCAgIAAWrVqxYoVK4iNjWXJkiW6OQ758uVL0iJNzu3bt3FycsLJyUmvPC4uLsnsd3Nzc13LNDY2Fl9fX/LkyQMkfPnIkCEDPj4+lCtXDkgYqrx79y5r167VvVbz58/n66+/Zvjw4QBUqVKFFy9e6PZJTkpeg8Tj9+jRQ9ej8+WXX7J3714OHDhA1apVk/28O3nyJF999ZXui0+FChWwtbXF2dn5g6/dm27dusXkyZMpXrw41apVAyA8PFz3+rzJzs6Oly9fApAtWzZGjRrFoEGDiIyM5Ouvv6ZVq1YcOnSImzdvsnDhQgICAlixYgVOTk4MGTJEhgXf4bNq8ScmvLdncr7L+fPniY6OplGjRnrl5cqVI2fOnEm6Ot/8MEwcl3yzCzI1KlasyK1bt2jSpAnz58/n0qVLNGrUiHbt2iW7/8mTJ3F3d9clpESNGzfmyZMn3Lx5M9l4E2N+/fr1B2Nyd3fX/T9LlixAwodDIo1GQ8aMGYmIiAASxtrWrFlDrly5uHPnDocOHWLZsmXcvHmTmJgYvWPXqFFDl3ggoTvb0tKS06dPvzem4sWLs3HjxmQfiTEmx8PDg8jISBo1asSMGTM4c+YMVapUoVevXroP3rel5DU+fvw4lpaWei0VMzMzvvnmmyTHy5Urly7pf+zrVapUKSws/vv+nSVLFvLnz6/3Gjo5Oel+F/Hx8cn2iJw8eTLJa29hYUGDBg24ePGi7sPzbW8fS6vV6pLYm3Elx9zcPEnCS2zBJefmzZs8fPiQmjVr6p3Tw8MDe3v7JF8iPub9+Pr1ay5cuICnp6de79EXX3yBm5ub7thnzpyhTJkyehMbS5cuTY4cOXTP336NEz9v3nVpW+vWrSlevLje480veDY2NrovgJCQwH7++WfKlSvH/fv3OXbsGKtWreLs2bO6v4+bN28SEhKSpNclub+/j30NEr35OZD4hfB9n3cVKlRgw4YNdOnShTVr1nDv3j169uxJjRo1gITP5Tdft+R6+QIDA2nbti1WVlbMmjVL95mu1WqTfb9qtVq93pPmzZtz+vRpzp07x4wZM7C0tGTatGn07t2boKAgxo0bx8iRI6lduzbdu3cnOjr6nfVRs8+qxe/k5ISdnV2Sca43vXr1iujoaJycnHTj+MlNPsqcObPuwzTRm8MHb/5Bfor69esTHx/PmjVrmDt3LrNmzSJnzpx4e3sn22X4/PnzZFtaiXUIDw9PNt7EmFMSb3Iz4t81dJJo+fLlLFq0iNDQUDJnzkzx4sXJkCFDktfw7SEQMzMznJyc9OJOjp2dHSVLlkx2m5WV1Tt/zt3dncWLF7NixQr8/f1ZuHAhWbJkoUuXLu/8cpWS1zg0NBQnJye9D5039/lQWUpfr4/9XcybN0/XtZ3o6tWrPH/+/J2xabVaXrx4gZ2dnd62N8fKE/n5+VGgQAEA7t279844AO7cuUPOnDmTnO9dwsLCgISrBXx9fZNsT5yXkehj3o/h4eHEx8ezZMkSvbHqRIm9Qe/63b/55XLo0KG6+QQAOXPm5I8//iBnzpwcOHCAFy9e6P3exo8fr/ti9e+//+r1LgK4uLgkSWpbt25l+vTpPHjwACcnJ4oUKYKNjY1ue+Jn19sT9973JTilr0GiN88HH/78GDZsGK6urmzdulX3+3N3d2fkyJEUK1aMOnXq6P3NeHl5MXHiRN3z48eP07t3b+zs7Fi2bJneF28HBwe9eU+JXr16pfdlNjHOxLr89ttvREdH4+Xlxdy5cylXrhweHh58+eWXzJw5k/Pnz1O+fPl31kmtPqvEDwndXSdOnCAqKirJHzIkTFwZP348a9asIWPGjEDCuPnbl9c8efIkSYvvY2k0miS9D8l9Y27YsCENGzYkIiKCw4cPs2TJEgYOHEi5cuWSzEDNmDFjshP0njx5AvDR3WqGsG3bNiZOnIi3tzfNmjXTfRj99NNPXLx4UW/fxA/3RHFxcYSGhhp15nHVqlWpWrUqr1+/5vjx4/z8889MmDCBMmXK6PVkJErJa5wtWzZCQ0OJj4/XS/4hISEfjOdjXq+P9f333yc7ZJKav5usWbOyceNGvbJcuXKRMWNGsmbNyu7du9/ZBX7nzh0uXbpEly5dUhx74vjroEGDkv0wTny/poadnR0ajYb27dsn+4U68UuEs7Nzsq/Tm3+3vXr10nWJw39fPGvVqsWqVavYs2cPTZo00W3Pnz+/7v8p6SE8ffo0Pj4+tG7dmk6dOul6MyZPnqybjJn4+3r77+3t99ebUvoapJaVlRXdu3ene/fu3L9/nz///JP58+fj7e3Nrl27WLBggV4L+82/uW3btjFkyBDy5s3L0qVLk1zpkS9fPi5fvpzknLdv36ZUqVLJxhMdHc3s2bMZOnQo5ubmhISE6P6GzMzMsLe3f+9kZzX7rLr6ATp27EhYWBgzZsxIsi0kJISlS5eSJ08e3Ye+lZVVkkU+Tp8+zf379ylbtuwnxWJnZ6ebd5Do7bHYvn376q6FdXBw4JtvvqFHjx7ExcUlaeFAQtf1uXPnkixEtHXrVrJkyZLsOJixnTlzBgcHB3788UddEnv58iVnzpxJ0p136NAhvTf//v37iY2N1Y3VGtqkSZNo1qwZWq2WDBkyUKNGDd1iPYmLqbzdak/Ja1y+fHliY2P5448/9PbZt2/fB2P6mNfrY2XLlo2SJUvqPRLr9Oeff+r1KMTFxbFjxw5KliyZbK+JlZVVkmM5OztjZmZGr169OHz4MOvXr0/yc5GRkQwdOhQHBwfdHJmUyJ8/Py4uLty9e1fvnK6urkybNo1Lly6l+FiJ49eJ7O3tKVasGDdv3tQ7dsGCBZk7d65uWK9ixYqcO3dObzLfjRs39P4WcuXKpXeMxFntlSpVonz58kyZMkVvyO1N169f/2Ds586dIz4+nj59+ugSYFxcHEePHgUShhry5s1L9uzZk8zZ+fPPP9953JS+Bin15vsmcUw9cRZ/jhw5aNWqFQ0aNODhw4dAwpUAb543sWclcUKgu7s7v/76a7KXd1apUoXAwEC9+TM3btwgMDCQypUrJxvfL7/8QtasWXXDcS4uLrpEHx0dTVhYWJq/1FEpn12Lv0yZMvz000/MnDmTwMBAvLy8cHZ25vr16yxbtkx3KZRGo8HJyYkff/xRN/GpVq1a3L17l1mzZlGgQAG9b+2pUaNGDX755ReGDh1K8+bNdTG8+aFUsWJFRo0axaRJk6hWrRrh4eHMnTuXvHnzUqRIkSTH7NChA1u3bqVDhw706tULZ2dntmzZwvHjx5kwYUKSJGYKpUqV4tdff2XixInUqFGDx48f4+/vz9OnT5O00h4+fEj37t1p27YtDx48YPr06VSpUsXgax8kqlSpEsuXL2fw4ME0btyYmJgYli5dipOTk25WuaOjI+fOnePYsWMUK1YsRa+xh4cHlStXZtiwYTx9+pQcOXKwceNGrly58s65A6l5vQylV69eHDx4kLZt2/Ljjz9iZWXFqlWruHPnDkuXLv3o47Vo0YLAwEBGjhzJiRMn+Oabb8iYMSM3b95k5cqVPHnyhJkzZ37UNdPm5ub069ePkSNHYm5uTo0aNQgPD2f+/Pk8evTooyZ3Jnb/Hjt2DDc3N0qXLk3//v358ccf8fb2pnHjxsTFxbFs2TIuXLhA9+7dAWjXrh0bN26kU6dO9O7dm7i4OGbOnImlpeUHz6nRaJg+fTrdu3enSZMmNG/enIoVK+Lg4MCtW7fYvn07J06coHTp0snOUE+U2IIdM2YMTZs2JTw8nFWrVnHlyhUgodfA3t6eAQMG4O3tzfDhw6lXrx7nz5/n119/fW+MKXkNUirxfXPq1CnKlStH8eLFdZ+lhQsXJigoiM2bN/P111+/8xhRUVEMGzYMOzs7unXrRmBgoN72xHUe6tevz8KFC+nSpYvuipxp06ZRqFAh6tWrl+S44eHhLFq0iPnz5+vKatSoweLFi9m8eTPXrl3D0dFR1kh5h88u8UPCJTzFihVj9erV+Pn5ERYWhqurK9WqVaNbt256E3V69+5N5syZWbVqFRs2bMDJyYl69erRt2/fT+76qly5Mj4+Pvzyyy/s2bNH98ZIXFAC4H//+x8xMTGsXbuWNWvWYGNjQ6VKlRg4cGCyHzZZsmTh119/Zdq0aYwfP56YmBiKFCnC/Pnz33t5lTF5eXlx9+5dAgICWLNmDdmyZcPT05MffviBESNGcOPGDd24cIMGDXB0dKRv377Y2tri5eVFv379jBZbtWrVmDp1KsuWLdNN6Pvyyy/5+eefdbOvW7VqxT///EOXLl3w8/OjUaNGKXqNZ8yYwcSJE5k2bRqxsbHUqlWLli1bsmXLlvfG9DGvl6EULFiQNWvWMH36dIYOHYpGo6FUqVK6SWSpMXToUKpWrcrq1asZPXo04eHhZM+enerVq9OuXTu991lKNW/eHDs7O5YuXcq6deuwtbWlbNmyTJ069aOG3uzt7enQoQPr1q3jwIEDHDlyhCpVquDv78/cuXPp06cPlpaWFC9enOXLl+sSgLOzM7/++ivjx49n8ODB2NnZ0blzZ3bu3Jmi8ya+P7ds2cK2bdvYsWMH4eHhuisl5s+fT82aNd/75bBChQqMHDmS5cuX8/vvv5M5c2YqVKjA3Llz6dmzJ2fOnMHT01N3Bc/8+fP57bffKFSoEGPGjEl2DZNEKXkNUqpbt27Mnz+fLl26sHPnTsaMGcPMmTNZtmwZT548wcXFhWbNmvHTTz+98xhnz57VDTd17NgxyfZevXrRu3dvrKysWL58OePHj2fEiBFYWlpSuXJlhgwZkuwk04ULF+Lu7q73t12qVCn69+/P5MmTyZgxIzNnzkwyj0Ek0GjlLgzCQGrWrEn58uX1JvR8ru7du8f58+epVauW3odHnz59uHPnjt7kLyGE+Jx8li1+IYwtceGRWrVq0axZM8zNzTl48CB79uwx+frwQghhSJL4hUhG9uzZWbJkCfPmzaNv377Exsbi5ubG1KlTadiwodLhCSFEqklXvxBCCKEin93lfEIIIYRIPUn8QgghhIpI4hdCCCFURBK/EEIIoSKqmdX/+rfJSodgcg7NZykdghBCGERs9PtvGmUIMU+TX4o5NSwz5//wTgpRTeIXQggh3is+Zbd8/9xJV78QQgihItLiF0IIIQC0n3b3zM+FJH4hhBAC4BNvm/25kMQvhBBCAFqVtPhljF8IIYRQEWnxCyGEECBd/UIIIYSqSFe/EEIIIdIbafELIYQQoJoFfCTxCyGEECBd/UIIIYRIf6TFL4QQQoDM6hdCCCHURBbwEUIIIUS6Iy1+IYQQAqSrXwghhFAV6eoXQgghVCQ+znCPT7Blyxbq169PyZIladCgAbt27dJtu3z5Mq1bt6ZMmTJUr14df3//jz6+JH4hhBAijfjtt98YOnQoLVq0YPv27dSvX5/+/ftz7tw5QkND6dChA3nz5iUgIIDevXsza9YsAgICPuoc0tUvhBBCgOJd/VqtllmzZtGuXTvatWsHQM+ePTl79iwnT57k5MmTWFlZMXr0aCwsLHBzcyM4OJglS5bQtGnTFJ9HWvxCCCEEJEzuM9QjFW7evMm9e/do1KiRXrm/vz9du3bl9OnTeHh4YGHxX5u9YsWKBAUFERISkuLzSItfCCGEMLBatWq9d/v+/fuTlN26dQuAV69e0alTJy5dukSuXLno3r07NWvW5OHDhxQqVEjvZ7JmzQrA/fv3cXFxSVFs0uIXQgghIKGr31CPVHjx4gUAPj4+NGzYkGXLllG5cmV69OjBsWPHiIyMxMrKSu9nrK2tAYiKikrxeaTFbwCvo2OpPOJn4rVavXIrC3NOTmifZP/Vh/9hytYT7Bj8PTkzOZgoStP4um51fH0HUaxoIZ48CWHxkl+YNHmu0mEZnRrrrcY6g9Q7XdfbgNfxJ9ei/xBLS0sAOnXqhJeXFwBFixbl0qVLLF++HBsbG6Kjo/V+JjHh29rapvg8kvgN4PqDZ8RrtUz8oTo5nP9L5BqNJsm+wU+eM2fXaVOGZzKVKpZj86blrN+wjVGjJlO5cnnGjvHBzMwMv4mzlQ7PaNRYbzXWGaTeaqu3qbm6ugIk6c4vUKAABw4cIGfOnDx+/FhvW+LzbNmypfg8kvgN4Or9ECzNzahVMh+W5u8ePYmLj2fE+oNktLUh8vlLE0ZoGiOG9+PChX9p36EPALv3HMDS0oJBA3syY+ZiIiMjFY7QONRYbzXWGaTe6b3eWu2nXX//qYoVK4adnR0XLlygXLlyuvJr166RO3duypYty9q1a4mLi8Pc3ByAY8eOkS9fvhSP74OM8RvE1fvPyJ/N6b1JH+Dnvy7yLOI1HWqUMlFkpmNlZYWnZyU2b9mlVx4QsAMHB3uqVimvUGTGpcZ6q7HOIPVWRb0VHuO3sbGhc+fOzJs3j+3bt3P79m0WLFjAkSNH6NChA02bNuXFixcMGzaMGzdusGnTJlauXEnXrl0/6jyKtvhjY2PZs2cPp0+f5v79+0RHR5MhQwZcXV0pV64cderU0btsIa26+iAEM42Grkt2ceHWY6wszKhTKh/9G5THziZhIsaNh6Es3HuOeZ2+5l5ohMIRG17+/Lmxtrbm2vWbeuU3Am8BULBgfvbuO6hAZMalxnqrsc4g9VZbvZXSo0cPMmTIwIwZM3j06BFubm7MmTOHChUqALB06VLGjx+Pl5cXWbJkYdCgQbr5ACmlWFa9ffs2Xbp04dGjRxQrVoysWbOSMWNGoqKiuHz5MgEBAcyZM4elS5eSI0cOpcL8oPh4LdcfhGJupuGn+h78WKsM/955yqJ957j5KAz/bg2I12oZue4gXuULU84tO/dOp7/E75QxIwAR4S/0yiMiEp47OqavSYyJ1FhvNdYZpN6qqHcauUlPhw4d6NChQ7LbSpUqxbp16z7p+Iolfl9fX3LlysXGjRtxcEj6hxMeHk6/fv0YM2YMCxcuVCDClNGiZU7HumR2yEC+rE4AfJk/Oy4OGRi29i+OXrvLP3eeEP46ip/ql3v/wT5jZmYJExm1b13ZkCg+jbyhDE2N9VZjnUHqrYp6q+QmPYol/jNnzrBu3bpkkz6Ao6MjAwcOpFWrViaO7OOYm5nh4ZY9SXnVol8ACeP//n9cYG7Hr7E0Nyc2Lp7E90+8VktcfDzmZp//VIuw5+EAODja65U7OCQ8f/48/fVygDrrrcY6g9RbFfX+xJvrfC4US/yOjo48fvyYwoULv3Of+/fvY2NjY8KoPt6j5y85fOUOVQp/QTYnO115VEzCH9C6Y5eIiYun65JdSX620aQNfJnfFf9uDUwWr7EEBgYTGxtLAbe8euWJzy9fvmb6oExAjfVWY51B6q22eqdnijU1mzVrxpAhQ1i/fj3BwcG6RQmio6O5c+cOAQEBDBs2jCZNmigVYorExMYxNuAIASeu6JXvvnATM42GCf+rzurejfUeXWu7AzCrfR1GNKmsRNgGFxUVxaFDJ/D6rr5eedOmDQgNDePkqfPKBGZkaqy3GusMUm9V1FvhWf2moliLv3fv3piZmTFp0iRevXqVZLudnR2tWrXip59+UiC6lMvl4kjDsgVYfuBvLC3MKZU7K+duPcT/jwt8X6ko5ZIZBrjxKBSAAq7O6Wrlvgl+s9j9+1rW/rqIFSvWUqlSObz7d2fI0PHp5jrf5Kix3mqsM0i9032909N8hffQaN81Y8NEYmJiuHz5Mo8ePeL169fY2Njg6upKkSJFkqxJ/Cle/zbZYMd6W1RMLCv/usj2szd4GPaSrI62NKlQmHaeJZMdv//t9DVGrT9k9CV7HZrPMtqx3+Xbb+sxaqQ3hQu5ce/eQxYsXMmMmYtMHoepqbHeaqwzSL2Vqnds9D2jnyPy+KfNln+TTcUWBjuWoSme+E3FmIk/rVIi8QshhDGYJPEf+9Vgx7Kp1NJgxzK0tL86jhBCCGEKKunq//yvIxNCCCFEikmLXwghhADVtPgl8QshhBAof3c+U5GufiGEEEJFpMUvhBBCgHT1CyGEEKqSxlfcMxRJ/EIIIQSopsUvY/xCCCGEikiLXwghhADp6hdCCCFURbr6hRBCCJHeSItfCCGEAOnqF0IIIVRFuvqFEEIIkd5Ii18IIYQA1bT4JfELIYQQoJoxfunqF0IIIVREWvxCCCEESFe/EEIIoSoq6eqXxC+EEEKAalr8MsYvhBBCqIi0+IUQQgiQrn4hhBBCVVTS1a+axO/cYq7SIZjci/0TlQ5BEbkajFU6BEWERb5UOgSTs7W0VjoERbyKiVI6BPEZU03iF0IIId5LWvxCCCGEimi1SkdgEjKrXwghhFARafELIYQQIF39QgghhKqoJPFLV78QQgihItLiF0IIIUAW8BFCCCFURSVd/ZL4hRBCCJDL+YQQQgiR/kiLXwghhADp6hdCCCFURSWJX7r6hRBCCBWRFr8QQggBqrmcT1r8QgghBKCN1xrskVr37t2jcOHCSR4bNmwA4PLly7Ru3ZoyZcpQvXp1/P39P/oc0uIXQggh0oirV69ibW3Nvn370Gg0unIHBwdCQ0Pp0KEDtWvXxtfXl/Pnz+Pr64uTkxNNmzZN8Tkk8QshhBCQJib3Xbt2jXz58pE1a9Yk21auXImVlRWjR4/GwsICNzc3goODWbJkyUclfunqF0IIISBhjN9Qj1S6evUqBQoUSHbb6dOn8fDwwMLivzZ7xYoVCQoKIiQkJMXnkBa/EEIIYWC1atV67/b9+/cnW37t2jWyZMnCDz/8wK1bt8iTJw89evSgatWqPHz4kEKFCuntn9gzcP/+fVxcXFIUmyR+IYQQAuATJuUZQnR0NLdu3SJDhgwMGjQIW1tbtm7dSpcuXVi+fDmRkZFYWVnp/Yy1tTUAUVFRKT6PJH4hhBACDDrG/64W/ftYWVlx6tQpLCwsdAm+RIkSBAYG4u/vj42NDdHR0Xo/k5jwbW1tU3weGeMXQgghICHxG+qRSra2tkla9YUKFeLRo0e4urry+PFjvW2Jz7Nly5bic0jiF0IIIdKAK1eu4O7uzunTp/XK//nnHwoUKICHhwdnzpwhLi5Ot+3YsWPky5cvxeP7IF39JpErV3ZOn97D99934eDB40qHYzCvo2L4qtdk4t+6laWVhTmnFg6hdOdx7/zZcoXz4D+wjbFDNAkzMzN6/dSZ1u2akz17NgJv3GLe7KVsWLdV6dCM6uu61fH1HUSxooV48iSExUt+YdLkuUqHZXTtO/yPH7u1JW/eL3jyJIRdO/czfuwMIiJeKB2aUani963wbXkLFSpEwYIF8fX1ZdSoUTg7O7N+/XrOnz/Pxo0byZw5M0uXLmXYsGF07tyZv//+m5UrV+Lr6/tR55HEb2S5c+dk27ZfcHLKqHQoBnf97iPitVom/uhFTpf/6pe46MQvQ9on+Zn9Z6+yYvcxmnmWNVWYRjd8VH+69WyP37hZnD/3D3XqerJgyVTi4+MJ2LBd6fCMolLFcmzetJz1G7YxatRkKlcuz9gxPpiZmeE3cbbS4RnNT/1+ZNToAcyauYS/Dhwlf/48DB/Rj6LFCvFtw/TxRTY5qvl9K3wdv5mZGQsXLmTq1Kn07duX8PBwihUrxvLlyylcuDAAS5cuZfz48Xh5eZElSxYGDRqEl5fXR51Ho9Uq/BXHRGxscpv0fBqNhjZtmuHnNxwAFxdn6tb93qQt/rC94416/PUHzjB57R6OzR2EpYX5B/d/EPKc5qMXU79iSYa2qme0uHI1GGu0Y7/Nzs6Wy4HHWLroF8aMmqor/23HL1hZW/FN7RYmiyUs8qXJzrVz+2qcnTNSqXJDXZnfhKF069qO7DlLExkZaZI4bC2tTXIeSHhP37pzlo3rt+Ldf5Su/Duvb/h51Tw8q3zLuXMXTRLLq5iUz+A2hLTw+46Nvmf0c7ya3sVgx7Ltv8RgxzI0GeM3kpIlizJ79nhWrdpIx459lQ7HKK7eeUT+7JlTlPQBpq7fi42VJX2a1DByZKYTGRnFN7VbsGDucr3y6JgYrN+aoJNeWFlZ4elZic1bdumVBwTswMHBnqpVyisUmXE5Otqzfu0W1q/XH8K5cSMIgHz5Tdu4MBVV/b7jtYZ7pGHS1W8kd+7co3jxaty795Bq1SoqHY5RXL3zCDONhq7TVnM+8C5WFubUKVcU7+9rY2ej3xI7f+MO+85cYUyHRthnMF0rzdji4uL4958ruudZs2amZeumeFb/in69hysYmfHkz58ba2trrl2/qVd+I/AWAAUL5mfvvoMKRGZcz59HMHBA0rHUxo0Teq8uXbpm6pBMQlW/b5XcnU8Sv5GEhj4nNPS50mEYTXy8lut3H2NupqFv01r82KgK/wQ9YNG2g9x88JRlA9tiZvbfDSZW7D5OjswZaVCxpIJRG1ez7xuxcOk0APbuPsCWTTsVjsg4nDImzOeICNefzJY4uc3R0cHkMSmlfIWy9O3flW1bd3Pl8nWlwzEK+X2nP5L4Rapo0TK3TwsyZ7QnX/bMAHxZKA+ZM9oxdOlvHP03kColE9abfvjsOX+dv8aAFnWwME+/o0tnTl+gUb0fKFAwP4OH9WHn3rXUrdGMqKjoD//wZyTxC927pgfFp4EbnZhCpa88WLdhCUE3g+nVY7DS4RiNqn7fabyL3lDS76ewMCpzMzM8iuTVJf1EVUsVBBKGARLtP3sVjQbqeRQzaYymFnTzNseOnuaXlevp1nkAxUsUodG3XysdlsGFPQ8HwMHRXq/cwSHh+fPnESaPydSaNmvIb9t+5s6dezRq2Dpd9+6p6fetjY832CMtU7TF36ZNG737Db/Pzz//bORoxMd4FBrO4Ys3qFKiANkyOerKo6JjAHC2/2/5yIMXrlO2UG5cMtonOc7nLnPmTNSq68n+PX/x9OkzXfm5swmzu3PkzK5UaEYTGBhMbGwsBdzy6pUnPr98OX2OdSfq07cLY8b6cOTwSVq26Ep4ePpJfMlR1e9bWvzGV6lSJU6dOkVISAg5c+Z870OkLTGxcYz5eScbD57VK9996hJmGg1lCyXMcNZqtfx76z5lCnyhRJhGZ2dvx7yFk2jd7nu98pq1qwLoTfxLL6Kiojh06ARe39XXK2/atAGhoWGcPHVemcBMoEPHlowbP4TNm3byXeN26T7pg7p/3+mVoi3+Hj16YGtry+zZs1m0aBG5cuVSMhzxEXJlcaZhpZIs//0YVhYWlHLLybnrd1i68wjf1/iSvK4Jy0c+ePaciNdRuL01JJBeBN+6w9o1mxng05O4uDjOn71IGfcS9B/Yg/37DrJ/bzqZ7fyWCX6z2P37Wtb+uogVK9ZSqVI5vPt3Z8jQ8Sa7ht/UsmbLjN+k4QQH32XRwp8pU6a43vabQbcJeaPXJz1Rze9bZvWbRvv27Tl8+DAzZ85k6tSpH/4BkWaMbNuA3FkzsfXY3yzefoiszg50b1yN9vUq6fYJeZ6wqIyjXQalwjS6/n2GE3gjiFZtmuIztA+PHj5m0cKVTJ88X+nQjObPA0do3qILo0Z6E7DRn3v3HuIzeBwzZi5SOjSjqft1DWxtM5AnTy727FufZHu3rgNZsypAgciMTzW/b5V09aeJlfsePXrEpUuXqFHDeAu7mHrlvrTA2Cv3pVWmXLkvLTHlyn1phSlX7ktLTL1yX1pgipX7Xo5pZbBj2Y1cbbBjGZriLX5IuJ3gx9xSUAghhDC4ND4b31DSROIXQgghFKeSrn65jl8IIYRQEWnxCyGEECCz+oUQQghVka5+IYQQQqQ30uIXQgghIM2vsW8okviFEEIIUE1XvyR+IYQQAlST+GWMXwghhFARafELIYQQIJfzCSGEEKoiXf1CCCGESG+kxS+EEEIAWpW0+CXxCyGEECBd/UIIIYRIf6TFL4QQQgDIyn1CCCGEikhXvxBCCCHSG2nxCyGEEKCaFr8kfiGEEALQaiXxCyGEEOqhkha/jPELIYQQKiItfiGEEAJU0+KXxC+EEEIgS/amO7HxcUqHYHK5GoxVOgRFBA/wUDoERRSbdVHpEEzuXkSI0iEI8dlRTeIXQggh3kta/EIIIYSKqGPFXpnVL4QQQqiJtPiFEEIIZHKfEEIIoS4qSfzS1S+EEEKoiLT4hRBCCFDN5D5J/EIIIQQyxi+EEEKoi0pa/DLGL4QQQqiIJH4hhBCChK5+Qz0MISgoCHd3dzZt2qQru3z5Mq1bt6ZMmTJUr14df3//jz6uJH4hhBACErr6DfX4RDExMQwYMIBXr17pykJDQ+nQoQN58+YlICCA3r17M2vWLAICAj7q2DLGL4QQQqQxc+bMwc7OTq9s/fr1WFlZMXr0aCwsLHBzcyM4OJglS5bQtGnTFB9bEr8QQggBaA04ua9WrVrv3b5///53bjt16hTr1q1jy5YtVK9eXVd++vRpPDw8sLD4L3VXrFiRRYsWERISgouLS4pik65+IYQQAtJEV394eDiDBg1i+PDhZM+eXW/bw4cPcXV11SvLmjUrAPfv30/xOaTFL4QQQhjY+1r07zN69GjKlClDo0aNkmyLjIzEyspKr8za2hqAqKioFJ9DEr8QQgiBYbv6U2PLli2cPn2abdu2JbvdxsaG6OhovbLEhG9ra5vi80jiF0IIIUDxBXwCAgIICQnRG9cHGDVqFP7+/uTIkYPHjx/rbUt8ni1bthSfRxK/EEIIkQZMnTqVyMhIvbK6devSp08f6tevz44dO1i7di1xcXGYm5sDcOzYMfLly5fiiX0giV8IIYQAlO/qf1er3cXFhZw5c9K0aVOWLl3KsGHD6Ny5M3///TcrV67E19f3o84jiV8IIYRA+cT/IS4uLixdupTx48fj5eVFlixZGDRoEF5eXh91HEn8QgghBGkz8V+9elXvealSpVi3bt0nHVOu4xdCCCFURBK/EX1dtzrHj+0kPOwGgddP4DOol9IhGZWZmRl9+v3IyfN7ufPobw4c2UrzFo2VDsuorJv3JUOfmbrndiNXv/Nh03aYcoEamE0GG24+PkdwyN96j6v3TikdmtGp7X2dSBX11moM90jDpKvfSCpVLMfmTctZv2Ebo0ZNpnLl8owd44OZmRl+E2crHZ5RDB/Vn2492+M3bhbnz/1DnbqeLFgylfj4eAI2bFc6PIMzL1kZi6IexIc90ZW99h+VdL+iHlh91ZCYM6lb0CMtKlq8EObm5vTqPIi7d/5bMSw+Pg32lRqQGt/XoJ56p8WufmPQaLVaw9w/MI2zsMpp0vPt3L4aZ+eMVKrcUFfmN2Eo3bq2I3vO0kku2TAGJxu7D+9kIHZ2tlwOPMbSRb8wZtRUXflvO37BytqKb2q3MFkswQM8jH4Ojb0TGbpPQhsdBdp4Xs/um/x+ji5k6OZH7N9HiP59pVFjKjbrolGP/6ZW7ZszaoIPxXJXJDY21mTnfdu9iBCTni8tvK+VkBbqHRt9z+jneFitusGO5XrwgMGOZWjS1W8EVlZWeHpWYvOWXXrlAQE7cHCwp2qV8gpFZjyRkVF8U7sFC+Yu1yuPjonB+q0lJtMDq0ZdiAu8SFzQv+/fr25rtDHRRP+x3kSRmUaxEoW5cTVQ0aRvamp8X4O66q2N1xjskZZJ4jeC/PlzY21tzbXrN/XKbwTeAqBgwfwKRGVccXFx/PvPFZ48SWiBZc2amZ/6d8Wz+lf4L1mtcHSGZeFeHfPs+YjateK9+5nlKohFsfLE/LEeol+bJDZTKVayCPHxWlYFLOLy7RNcuHGICdNGYGef8mVDPzdqfF+DuuqtjTfcIy1TNPEHBQUxZ84cxo0bx19//ZVk+4sXLxgyZIgCkX0ap4wZAYgIf6FXHhGR8NzR0cHkMZlSs+8bcenGUUaM9mb/3oNs2bRT6ZAMRpMxM1Z1WxO1czm8fvHefS2/akB86GNi/z5souhMQ6PRUKRoQfK65eb37ftp16IHc6cvoXHTb1ixdj4aTdpu7aSWWt/Xaq13eqbY5L4zZ87QqVMnsmXLhlarZfXq1dSuXZtp06bp7j4UGRnJli1b8PPzUyrMVDEzS/jge9f0ifQ+AerM6Qs0qvcDBQrmZ/CwPuzcu5a6NZoRFRX94R9O46wbdyHu+nnirrx/9rrGMRPmhb4kes+qtP/1/yNpNBo6tOzJk8dPCbx+C4CTx87w5PFTZi2aiGfNyhzYn76+7IB639dqqrc2jc/GN5QUJ/4tW7Z81IG/++67926fNm0azZo1Y/jw4QDs2rWLYcOG0a1bNxYtWoSlpeVHnS8tCXseDoCDo71euYNDwvPnzyNMHpMpBd28TdDN2xw7eppbQbfZvP1nGn37NRvXJ3/Hqc+FhUcdzLLm5vXCwaD5/86yxM8JjRlotUDCh6N5EQ9AS+y/x5QI1aji4+M5fuR0kvI/9hwCoGiJQuky8av1fa2meqez7+jvlOLEP3jwYL3nid15b34LfLOL70OJ/+rVq0yYMEH3/JtvviFr1qx07tyZQYMGMWPGjJSGluYEBgYTGxtLAbe8euWJzy9fvmb6oIwsc+ZM1Krryf49f/H06TNd+bmzCTPNc+TMrlRoBmNRtDwaO0dsvecn2WY34hei/wog5q9NCfsWcic++Aq8DDd1mEaXLXtWatSuyoH9h3l4/5Gu3CZDwn3BQ0PCFIrMuNT4vgb11js9S/EY//79+3WPuXPnkiFDBvr378++ffv4+++/+euvvxg5ciTOzs4sXLjwg8ezt7cnNDRUr+zLL79kypQp7N69+7Pr3n9TVFQUhw6dwOu7+nrlTZs2IDQ0jJOnzisTmBHZ2dsxb+EkWrf7Xq+8Zu2qAPz7zxUlwjKoqB3LeL1kuN4j9tpZ4iNCE/5/5g/dvmY58hN3J31+IFpZWTJp5ih+aNtUr7zhd/WIi4vj5PGzCkVmXGp8X4O66q2WWf0pbvHnzPnfdfC9e/eme/fudOnSRVeWLVs2WrZsSUxMDFOmTMHT0/O9x/P09GTMmDGMHj2aYsWK6br2a9euzdChQxk3bhwPHjz42PqkGRP8ZrH797Ws/XURK1aspVKlcnj3786QoePT5bW+wbfusHbNZgb49CQuLo7zZy9Sxr0E/Qf2YP++g+zfe1DpED+ZNuQBb49yal+9gLhY4h8E6co0GTOjsbEj/onxrztWwp3gewSs20a3Ph2Jjo7h3Om/KVfBnZ79OvPLsnXcvHFL6RCNRm3v60Rqqbc6VrVJ5eS+wMBAihYtmuy2fPnycffu3Q8ew9vbm379+vG///2PRYsWUa1aNd221q1bY2ZmpjcU8Ln588ARmrfowqiR3gRs9OfevYf4DB7HjJmLlA7NaPr3GU7gjSBatWmKz9A+PHr4mEULVzJ9ctKu8fRMY+eY8J/Il8oGYkRD+vlyKzCYpi0a0dv7Rx49eMyMSfNZNGeF0qEZlRrf16Ceeqf1lrqhpGrlvm+//ZZChQoxZcqUJNt69erF48ePWb8+ZQuW3L59G2dnZxwckl4SEhQUxJ49e+jatevHhpiEqVfuSwtMuXJfWmKKlfvSIlOu3JdWmHrlPqEcU6zcF1y2tsGOlefsPoMdy9BS1eLv2bMnP/30E7du3aJWrVpkypSJp0+fsmfPHm7cuMGSJUtSfKzcuXO/c1u+fPkMkvSFEEKID1FLiz9Vib9u3brMmzePefPmMWvWLLRaLWZmZri7u7NixQrKlStn6DiFEEIIo5Ix/g+oWbMmNWvWJCoqiufPn+Pk5KRbeEcIIYQQadMnrdwXGBjIkSNHePLkCa1bt+bOnTsUKVIEe3v7D/+wEEIIkYZIV/97xMXFMWrUKAICAtBqtWg0GurVq8e8efO4c+cOq1atwtXV1dCxCiGEEEajliV7U3WTngULFrBt2zbGjRvHkSNHdKv3+fj4EB8f/1mvuieEEEKkZ6lK/AEBAfTp04emTZvi5OSkKy9SpAh9+vThyJEjhopPCCGEMAm13JY3VV39T58+fecCPtmyZSM8PP2tTy6EECJ9i5eu/nfLkycPf/31V7LbTp48SZ48eT4pKCGEEEIYR6pa/O3atWPkyJHExMRQo0YNNBoNwcHBnDhxgmXLliW5k58QQgiR1qllcl+qEn/z5s159uwZCxcu5Ndff0Wr1dK/f38sLS3p3LkzLVu2NHScQgghhFHJ5Xwf0LVrV1q1asW5c+cICwvD0dGR0qVL6032E0IIIT4Xalm5L1Vj/EOGDOHOnTvY29tTtWpVGjVqhKenJ05OTty8eZNu3boZOk4hhBBCGECKW/z379/X/X/Lli3Url0bc3PzJPsdPHiQo0ePGiY6IYQQwkSkq/8tY8aM0ZvJ36tXr2T302q1VK5c+dMjE0IIIUxILZfzpTjx+/r6cvToUbRaLUOHDqV79+5JbqlrZmaGo6MjFSpUMHigQgghhPh0KU782bJlw8vLCwCNRkP16tWxt7fH0tISgNevXxMVFSWT+4QQQnyW1HI5X6om9zVo0IBp06bx/fff68rOnTtHlSpVGD9+PHFxcQYLUAghhDAFrdZwj7QsVYl/9uzZ7Ny5k++++05XVrx4cXx8fNi8eTNLliwxVHxCCCGEMKBUXce/Y8cOfHx8aNGiha4sY8aMtGnTBjMzM1asWCGX9AkhhPisyOS+9wgNDSVXrlzJbsuXLx+PHj36pKCEEEIIU5Mx/vdwc3Nj9+7dyW7bu3ev3KRHCCGESKNS1eLv2LEj3t7ehIWFUbt2bVxcXHj27Bn79u1jz549+Pn5GTpOIYQQwqjS+qQ8Q0lV4m/QoAERERHMnTuXPXv26MqdnZ0ZMWKE3qQ/IYQQ4nOgljF+jVab+u84Wq2WoKAg3U168ufPj5lZqkYPjM7GJveHd0pnYuPVeVllYefk55+kd0fr2isdgsnV2R+rdAiKuPL8jtIhmFz4y5tGP8epnF4GO5bHvc0GO5ahpfrufJCwkE/+/PkNFYsQQgghjCzFib9o0aKsW7eOUqVKUaRIETSad3eJaDQaLl26ZJAAhRBCCFNQS1d/ihN/z549yZYtm+7/70v8QgghxOdGJXP7Up7437wbX+/evY0SjBBCCCGMK8WJ//79+x914Bw5cnx0MEIIIYRSpKv/LTVr1vyo7v3Lly+nKiAhhBBCCWpZuS/FiX/ChAm6xP/8+XOmTp1KpUqV+Oabb8iSJQthYWH88ccfHDhwgMGDBxstYCGEECK9CgkJYeLEiRw6dIioqCg8PDwYNGgQBQoUABIa1ePHj+eff/7BycmJNm3a0KlTp486R4oTf5MmTXT/79mzJ15eXowdO1Zvn0aNGjF+/Hh27dqldwMfIYQQIq2LVzoAoHv37piZmbFkyRJsbW2ZNWsW7du3Z+/evURGRtKhQwdq166Nr68v58+fx9fXFycnJ5o2bZric6TqOv4jR44wb968ZLdVr16d9evXp+awQgghhGK0KNvVn3gDvO7du1OwYEEAevTowbfffsv169c5duwYVlZWjB49GgsLC9zc3AgODmbJkiUflfhTtcyes7Mz58+fT3bb8ePHdZf9CSGEECJlnJ2dmT59ui7pP336FH9/f1xdXSlQoACnT5/Gw8MDC4v/2uwVK1YkKCiIkJCQFJ8nVS3+5s2bM3/+fF6/fk3NmjXJlCkTT58+5ffff+fXX39l6NChqTmsEEIIoZh4A17IX6tWrfdu379//3u3jxgxgvXr12NlZcWCBQuwtbXl4cOHFCpUSG+/rFmzAglX3rm4uKQotlQl/u7duxMREcGKFSvw9/cHEtbtt7Gx4aeffqJVq1apOawQQgihmHiFu/rf1K5dO1q0aMGvv/5Kz549WbNmDZGRkVhZWentZ21tDUBUVFSKj52qxK/RaPDx8aFHjx6cP3+e58+f4+zsjLu7O7a2tqk5pBBCCKEoQ47xf6hF/yGJs/jHjh3L+fPnWbVqFTY2NkRHR+vtl5jwPyb3ftKt9Ozs7MiSJQuOjo6ULl06SUBCCCGESJmQkBC2b99OXNx/d1Y1MzPDzc2Nx48f4+rqyuPHj/V+JvH5x8ytS/Xd+X777TemTZvGkydP0Gg0bNiwgTlz5mBpacm0adOSdEcIIYQQaZnSl/M9fvwYb29vXFxcqFSpEgAxMTFcunSJmjVrkjlzZtauXUtcXBzm5uYAHDt2jHz58qV4fB9S2eLfuXMnPj4+VKxYkenTpxMfn/By1a1bl4MHDzJ//vzUHFYIIYRQjBaNwR6pUaRIEapUqYKvry+nT5/m2rVr+Pj4EB4eTvv27WnatCkvXrxg2LBh3Lhxg02bNrFy5Uq6du36UedJVYt/4cKF/O9//2P06NF6XRJNmjQhJCSE9evX07dv39QcWgghhFAljUbDzJkzmTZtGn379iUiIoJy5cqxevVq3f1vli5dyvjx4/Hy8iJLliwMGjQILy+vjzpPqhJ/UFAQPj4+yW4rXbo0c+bMSc1hhRBCCMUo3dUP4ODgwOjRoxk9enSy20uVKsW6des+6Ryp6up3cXEhMDAw2W2BgYEfNdYghBBCpAXxBnykZalK/PXr12f27Nn8/vvvupn8Go2Gf/75h/nz51OvXj2DBimEEEIIw0hVV3/fvn25du0affv2xcws4btDmzZtePXqFeXKleOnn34yaJBCCCGEsSm9Vr+ppCrxW1lZsXTpUo4cOcLx48cJCwvDwcGB8uXL4+npqbt9rxBCCPG5iFdJ6kpV4u/WrRtt27alcuXKVK5c2dAxCSGEEMJIUjXGf+rUKd3iAUIIIUR6EI/GYI+0LFWJv3LlymzYsOGjbgqgZrlyZefhw4tUq1ZR6VCM7uu61Tl+bCfhYTcIvH4Cn0G9lA7JqDy+Ksu/j06889Hdu5PSIRqcbZ/ROExfrVdmXqQ0dsOm47hwCw5zNmDbZzRmWXMoFKHxaDQaWnVrQcCR1Ry6uYf1B3+mRaeU3wf9c9W+w/84emIn9x9d5MI/B5g4eQQODvZKh2VwWgM+0rJUdfVbW1uza9cu9u7dS65cuZJcvqfRaFi5cqVBAvzc5c6dk23bfsHJKaPSoRhdpYrl2LxpOes3bGPUqMlUrlyesWN8MDMzw2/ibKXDM4pLf1+lZf2kyb3P4K6UKFOMnZv3KBCV8Vh+VRtLj6rEP3moKzMvUAw7n8nEnjvKqwUTwMoGm29bYTdiFi+GdEL7IlzBiA2r76getPzxewJW/saB3w+SM3cOug7qRI4vXJkxep7S4RnFT/1+ZNToAcyauYS/Dhwlf/48DB/Rj6LFCvFtwzZKh2dQaf0yPENJVeJ/+PAh7u7uuudarf73m7efq5FGo6FNm2b4+Q1XOhSTGTG8Hxcu/Ev7Dn0A2L3nAJaWFgwa2JMZMxcTGRmpcISG9/LFS/4+849eWY161ahUrTz9Og0h+OYdhSIzPI2TCzZtehIfon+TEOtGLYm/f5tXc8bA/7/3X177B4dZa7Gs9jXROzcoEa7BZcyUkeYdm7B51TYmDZmuK3947xHTVvqxadU2gm/cVjBCw9NoNPT37s5y/1/xHTUFgAN/HuHZs1B+XjUPd/eSnDt3UeEoxcf66MT/999/88MPP5A7d26KFy9ujJjShZIlizJ79ngWLfqFP/44zG+/pe8eECsrKzw9K+E7ZppeeUDADgYO6EnVKuXZu++gQtGZjrWNNcPGe3Ng72H2bP9D6XAMKkNnb2L/OQMx0VgUKa0rj7t5hZgzR3RJH0D7/Bna1y/TVXd/7vy5sLCw4NDeo3rlZ49dwNzcnK9qVEh3id/R0Z71a7ewceN2vfIbN4IAyJc/d7pK/PEquSItxYk/PDycrl27cv78eV1ZmTJlmD59OtmzZ0/VyaOiorh+/ToFChTAxsaGy5cvs2rVKh49ekTBggVp164drq6uqTq20u7cuUfx4tW4d++hKsb28+fPjbW1Ndeu39QrvxF4C4CCBfOrIvG37fo/srhmpmPTnkqHYlCWnvUxz1uIF4M7YvNDN71tUb+tTrK/edEymNk7En/3lokiNL6wkDAAcnyh/5mUK2/Cl5scuVP3OZiWPX8ewcABvknKGzdOWKTt0qVrpg7JqNTSV53iyX0zZ87k0qVL9O7dm0WLFuHj40NQUBAjRoxI1YkDAwOpXbs2zZo1o379+hw9epSWLVty4cIF7Ozs2LdvH99+++07lwZO60JDn3Pv3sMP75hOOGVMmMMQEf5CrzwiIuG5o6ODyWMyNUtLC1p3bsGuLXu5feuu0uEYjMYlKxladeP1ilkpGq/XOGQkQ6f+xIc8JvrQbhNEaBp3gu5x/uTfdOnfnur1qmLnYEehEgUZPs2HqMgoMtjaKB2iSZSvUJa+/buybeturly+rnQ4IhVS3OL/888/6d+/P+3atQOgWrVqZMuWjQEDBvDq1StsbW0/6sSTJ0/G3d2dHj164O/vT/fu3WncuDFjxoxBo9EQGxvLoEGD8PPzY+nSpR9XK2FyZmYJXWTvmt+ReOvm9Kxu41pkzurC8nlJW8CfM9suA4m5cJLY04c+uK/GyQW7QRMxc3Tipd9AiEpf8zoGdx7JkMneTF42DoDwsAjmjFtIp35tef0qfdU1OZW+8mDdhiUE3QymV4/BSodjcOn/UypBihP/kydPkozpV6hQgbi4OB48eICbm9tHnfjkyZMEBASQP39+fHx82LZtGy1bttSt+mdhYUG3bt1o0aLFRx1XKCPseUJL0MFR/xKfxEt+nj+PMHlMpla3YU2uXwnk6qX00wqyqv0tZl/k59XQzmCW2EH4/+OgZmYJ4/r//2XPLFc+7LzHg00GXk4ZTFzQVWWCNqJnT0MZ2HE49o72ZMnmwt3g+8THxeMzsR/hYenn6oXkNG3WkAWLpnD9+k28vm1HaOhzpUMyOFm57y2xsbFYWVnplWX8/+7d1FzPb2Njo5vlnTlzZr7//nusra319gkPD8fBIf13EacHgYHBxMbGUsAtr1554vPLl9PXWODbLCzM+ap6BZbN+UXpUAzKsnw1zBydcJy7Mcm2jCv3ErlpJVGbf8a8WBns+o5B++olL8f3S1dj+2+q821Ngq7d4sblm7z4/2GtoqUKY2FhwZWL6fdvvE/fLowZ68ORwydp2aIr4eHp/4t8epaqy/nelprL96pUqcLYsWMZN24cbm5ujBkzRu94J0+exNfXl9q1axsiRGFkUVFRHDp0Aq/v6jNt+kJdedOmDQgNDePkqfPKBWcCBYsWwNY2A2dPXVA6FIN6vWwGmgz6w3jWXm0xz1uQVzNGEB8aglmeAtj1H0f8k4e8nDwYbehThaI1vo4/teHGlSBG9Pjv86rlj80JD4vg7NHzygVmRB06tmTc+CEEbNzOj529iYmJUToko0nrK+4ZikESf2puyjNkyBC6devG/PnzmTZN/xKwnTt34u3tTdWqVenfv78hQhQmMMFvFrt/X8vaXxexYsVaKlUqh3f/7gwZOj5dXsP/pkJFE4a6Aq8GKRyJYcU/TDpJUfsiHGJjiQtKaOHaeY8HcwsiN/2MWaYskCnLf/tGhBH/+IHJ4jW2df6bGDypP0FXg7hw6h/qfFuTek3qMNFnGi9fvFI6PIPLmi0zfpOGExx8l0ULf6ZMGf3h3ptBtwl5+kyh6AxPLbP6Pyrxjx49Gnv7/8ZwE1v6I0aMwM7OTleekpX7MmXKxPr16wkLC0uyrVKlSmzZsoUiRYp8THhCYX8eOELzFl0YNdKbgI3+3Lv3EJ/B45gxc5HSoRmdS5ZMAISrYC7DmzRZsmOetyAAdn1GJdkefWg3rxdPNnVYRrNl9Tasbaz4vmMT2vVuRXDgHYb3GMOeLfuVDs0o6n5dA1vbDOTJk4s9+9Yn2d6t60DWrApQIDLxKTTaFPbTt2nzcUsz/vJL2hrrtLHJrXQIJhcbH6d0CIoo7JxL6RAUcbRu+ls7/UPq7I9VOgRFXHmeflaETKnwlzc/vNMn+jlna4Mdq+29VQY7lqGluMWf1hK5EEIIYUhyOZ8QQgihImoZ40/VbXmFEEII8XmSFr8QQgiBLOAjhBBCqIpaxvilq18IIYRQEWnxCyGEEKinxS+JXwghhAC0Khnjl65+IYQQQkWkxS+EEEIgXf1CCCGEqqgl8UtXvxBCCKEi0uIXQgghUM+SvZL4hRBCCGTlPiGEEEJVZIxfCCGEEOmOtPiFEEII1NPil8QvhBBCoJ7JfdLVL4QQQqiItPiFEEIIZFa/EEIIoSpqGeOXrn4hhBBCRaTFL4QQQqCeyX2S+IUQQgggXiWpXzWJPzY+TukQhIlcDb2rdAiKaPhHEaVDMLkDI0opHYIiMvULUjoE8RlTTeIXQggh3kctk/sk8QshhBCoZ4xfZvULIYQQJLT4DfVIrbCwMEaOHEm1atUoW7YsLVu25PTp07rtly9fpnXr1pQpU4bq1avj7+//0eeQxC+EEEKkEf379+fChQtMnz6djRs3Urx4cTp16kRgYCChoaF06NCBvHnzEhAQQO/evZk1axYBAQEfdQ7p6hdCCCFQfuW+4OBgjhw5wq+//krZsmUBGDZsGAcPHmT79u3Y2NhgZWXF6NGjsbCwwM3NjeDgYJYsWULTpk1TfB5p8QshhBAkXM5nqEdqODs7s3jxYkqUKKEr02g0aLVanj9/zunTp/Hw8MDC4r82e8WKFQkKCiIkJCTF55EWvxBCCGFgtWrVeu/2/fv3JylzdHTE09NTr2zXrl3cvn2bKlWqMGPGDAoVKqS3PWvWrADcv38fFxeXFMUmLX4hhBCChFn9hnoYwpkzZxg6dCi1atWiZs2aREZGYmVlpbePtbU1AFFRUSk+rrT4hRBCCAx7HX9yLfqPsW/fPgYMGEDp0qWZPn06ADY2NkRHR+vtl5jwbW1tU3xsafELIYQQaciqVavo3bs31apVY8mSJdjY2ADg6urK48eP9fZNfJ4tW7YUH18SvxBCCIHyk/sA1qxZw9ixY2nVqhUzZ87U69r38PDgzJkzxMX9twT9sWPHyJcvX4rH90ESvxBCCAEoP8YfFBTEhAkTqFOnDl27diUkJIQnT57w5MkTIiIiaNq0KS9evGDYsGHcuHGDTZs2sXLlSrp27fpR55ExfiGEECIN2L17NzExMezdu5e9e/fqbfPy8mLixIksXbqU8ePH4+XlRZYsWRg0aBBeXl4fdR5J/EIIIQTK36SnW7dudOvW7b37lCpVinXr1n3SeSTxCyGEEPBJY/OfE0n8QgghBHJ3PiGEEEKkQ9LiF0IIIVB+jN9UJPELIYQQgFYlnf3S1S+EEEKoiLT4hRBCCKSrXwghhFAVtVzOJ139QgghhIpI4jeir+tW5/ixnYSH3SDw+gl8BvVSOiSjU2OdQV31zpojCzsv/UaZSqX1yr9wy8Xkn8ez6/JvbP9nMz5TB2DvaKdQlJ/udUwcX87ag/tM/UeFOft0+9x69pLeW85Sdf4fVF/4J6P3/ktEZIyCURtfrlzZefjwItWqVVQ6FINTeq1+U5GufiOpVLEcmzctZ/2GbYwaNZnKlcszdowPZmZm+E2crXR4RqHGOoO66p0tZ1amrZmEQ0Z7vXJ7RztmrpvK04chjOszkUxZnOk+7Eey5siC9w8+CkX7aa4/jSBeC37flCSHYwZduZlGA0BEZAxdN50mi501Y78uwbNX0cw8fI1HEZEsaPKlUmEbVe7cOdm27RecnDIqHYpRqKWrXxK/kYwY3o8LF/6lfYc+AOzecwBLSwsGDezJjJmLiYyMVDhCw1NjnUEd9dZoNHzTvC49Ria/jvh3bRvjkNGeTnW7EvbsOQCPHzxl6io/SnqU4OKpf0wZrkFcfRKBpbmGWgWyYWmetHN0/d93CI+M4dcfKpHJNuHWqVntren92znO3QvFPaezqUM2Go1GQ5s2zfDzG650KMIApKvfCKysrPD0rMTmLbv0ygMCduDgYE/VKuUVisx41FhnUE+93Yrlp79fX37fsIdxffySbC/vWY6/T1zUJX2AkwdO8TLiJZVqVTBlqAZz9UkE+TPZJ5v0AY4Fh1A2p7Mu6QN8lTczdlbmHL711FRhmkTJkkWZPXs8q1ZtpGPHvkqHYzTxBnykZZL4jSB//txYW1tz7fpNvfIbgbcAKFgwvwJRGZca6wzqqfeje49pWaUNc30XEPk6Ksn2PAXzcOfmXb0yrVbLgzsP+SJ/LlOFaVDXnkRgpoFum05Tae4+PBf8wbh9l3gZHQtAUOhLcjvrz2Ew02jI4ZiB4NCXSoRsNHfu3KN48Wr4+Izl9evXSodjNFoD/kvL0mTib9SoEQ8ePFA6jFRzypgw/hUR/kKvPCIi4bmjo4PJYzI2NdYZ1FPviLAInjx4dyvW3tGOly9eJSl/9eIVtva2xgzNKOK1Wq4/jeB22CtqumVj7ndl6VQ+P79fe0DvLWeJ12qJiIrB3so8yc/aWVnwMjpOgaiNJzT0OffuPVQ6DKNTS4tfsTH+LVu2vHNbcHAwu3btIlOmTAB89913pgnKQMzMEib/aLXJf+uLj0/rfxYfT411BvXW+20ajSbZ10Cj0aD9DF8DrRbmfFsWFztr8mVKaNV/mSsTme2sGfb7RY7eekpCdTXJ/qxZ0mIh0gzFEr+vr69u0lNyHxiTJ08GEj44PrfEH/Y8HAAHR/2Zzw4OCc+fP48weUzGpsY6g3rr/baXES+xs0966V4Guww8fvBEgYg+jbmZhnJfZEpSXjVvZgCuPX2BvbWFrtv/Ta9iYslmb230GIXhpfUuekNRrKt/06ZNFCtWjAoVKvDXX39x5coV3SNDhgzs3buXK1eucPnyZaVCTLXAwGBiY2Mp4JZXrzzx+eXL10wflJGpsc6g3nq/7XbgHXLly6FXptFoyP6FK7euBSsUVeo9fhHJpot3eRShf0VGZFxC74VTBkvyOttxJ0x/eCNeq+V++Gvyu+h/ERSfB7V09SuW+PPly8e6desoVaoU3377LTt37lQqFIOLiori0KETeH1XX6+8adMGhIaGcfLUeWUCMyI11hnUW++3nfrrDKUrlsYp03/Xd5ev7oGdgx2nDp5RMLLUiY6LZ+z+SwT8oz9hcc/Vh5hpoGwOZyrmduHMvVCevYrWbT966ykvo+OomNvF1CELkWKKXsdvYWFB//79qVq1Kj4+Puzfv5/Ro0crGZLBTPCbxe7f17L210WsWLGWSpXK4d2/O0OGjk8X13UnR411BvXW+02bV/5G047fMX3tZJZP/5mMzhnpPqwLx/af4N8zl5QO76PlymhLg6LZWXE6CCtzM0q6ZuT8/TD8T92keakvyJvJju9Lf8HaC7fpvukMXSvmJywyhlmHrlE5b2ZK53BSugoiFeLfMVcnvUkTs/o9PDx0k/0aNmxITMznv+TlnweO0LxFFwoVyk/ARn9a/s8Ln8HjmDZ9odKhGY0a6wzqrfebnoeG06e5N8+fPWfk3KF08enInzsOMqr7WKVDS7URtYrRuXx+tl26T5/fzrH98n26VSzAQM8iADhnsGJJ03I4ZbBk2O8XmXf0BnUKujKpfimFIxeppZYlezXad01HVsiWLVvYtGkTU6dOJWvWrAY7roVVToMdS4i0qFKWIkqHYHK7hxdTOgRFZOr3m9IhmFxk5G2jn6N1niYGO9aq4E0GO5ahpbkle7/77rvPbha/EEKIz5+s1S+EEEKoiFzOJ4QQQoh0R1r8QgghBGn/+ntDkcQvhBBCIGP8QgghhKrIGL8QQggh0h1p8QshhBDIGL8QQgihKmlsPTujka5+IYQQQkWkxS+EEEIgs/qFEEIIVVHLGL909QshhBAqIi1+IYQQAvVcxy+JXwghhEA9Y/zS1S+EEEKoiLT4hRBCCNRzHb8kfiGEEAL1zOqXxC+EEEKgnsl9MsYvhBBCqIi0+IUQQgjUM6tfEr8QQgiBeib3SVe/EEIIoSLS4hdCCCFQT1e/tPiFEEIIEmb1G+qfocyfP582bdrolV2+fJnWrVtTpkwZqlevjr+//0cdU1r8QqQTp0KuKx2CybkOCFI6BEVE3D2gdAjCBFasWMHs2bPx8PDQlYWGhtKhQwdq166Nr68v58+fx9fXFycnJ5o2bZqi40riF0IIIYD4NDK579GjRwwbNowzZ86QL18+vW3r16/HysqK0aNHY2FhgZubG8HBwSxZsiTFiV+6+oUQQghAa8DHp/j333/JmDEjW7dupXTp0nrbTp8+jYeHBxYW/7XbK1asSFBQECEhISk6vrT4hRBCCAOrVavWe7fv37//ndtq1qxJzZo1k9328OFDChUqpFeWNWtWAO7fv4+Li8sHY5PEL4QQQmDoWf0aAx7rP5GRkVhZWemVWVtbAxAVFZWiY0jiF0IIITBs4t+//w+DHetNNjY2REdH65UlJnxbW9sUHUMSvxBCCMHnsXKfq6srjx8/1itLfJ4tW7YUHUMm9wkhhBCfCQ8PD86cOUNcXJyu7NixY+TLly9F4/sgiV8IIYQAErr6DfUwlqZNm/LixQuGDRvGjRs32LRpEytXrqRr164pPoZ09QshhBBg0BX3jMXFxYWlS5cyfvx4vLy8yJIlC4MGDcLLyyvFx9BoP4dBDQOwsMqpdAhCGJWFmbnSIZiclbk62y4hwfuUDsHkLDPnN/o5PHJUM9ixTt0/aLBjGZo63zVCCCHEW1TSDpbEL4QQQoDcnU8IIYQQ6ZC0+IUQQgikq18IIYRQFbV09UviF0IIIfg8LuczBBnjF0IIIVREWvxCCCEEEC9j/EIIIYR6SFe/EEIIIdIdafELIYQQSFe/EEIIoSrS1S+EEEKIdEcSvxF9Xbc6x4/tJDzsBoHXT+AzqJfSIRmdGusM6q13oly5svPw4UWqVauodChG177D/zh6Yif3H13kwj8HmDh5BA4O9kqHZVAX/rlMh14+eNT6jmoNWzJ07FRCQsOS3feX9VsoUfkb7j14ZNogjSBeqzXYIy2TxG8klSqWY/Om5Vy5coPm33dm9ZoAxo7xYcjgPkqHZjRqrDOot96JcufOyY4dq3Fyyqh0KEb3U78fmT5zDLt//5Mf/teNWTMW8/33jVn16wKlQzOYf69cp2PvwWTIYMPMCSPo370jR0+dpc/gMUn2Db5zj1kLV5g+SCPRGvBfWqbRqmRxYgurnCY9387tq3F2zkilyg11ZX4ThtKtazuy5yxNZGSkSeMxBTXWGdJOvS3MzE1ynkQajYY2bZrh5zccABcXZ+rW/Z6DB4+bLAYrc9NNU9JoNNy6c5aN67fi3X+Urvw7r2/4edU8PKt8y7lzF00SS0jwPqMdu2PvwURFRfHzgqmYmyf8Te09cISJsxayct4UcuVwBSAuLo62PQby8PETHj1+yu6NK8iZPZvR4rLMnN9ox05UMMuXBjvW9SdnDHYsQ5MWvxFYWVnh6VmJzVt26ZUHBOzAwcGeqlXKKxSZ8aixzqDeegOULFmU2bPHs2rVRjp27Kt0OEbn6GjP+rVbWL9+q175jRtBAOTLn1uJsAwq7Hk4p879TYsmDXVJH6BO9crs3/yLLukDrPg1gJBnoXRu/b0SoRqFdPUb2caNG4mOjtYrO378OD/++CONGzfG29ubGzduKBTdp8mfPzfW1tZcu35Tr/xG4C0AChY0/jdXU1NjnUG99Qa4c+cexYtXw8dnLK9fv1Y6HKN7/jyCgQN8OXFcvyXXuHE9AC5duqZEWAZ17UYQWq0WF2cnfEZPonztJnjU9sLHdzLPwyN0+924Gcx8/9WMHdqPDDY2CkZsWGrp6lcs8Y8YMYKIiP/+kA4fPkyHDh2Ij4+nSpUqPHnyhKZNm3L27FmlQkw1p4wJY50R4S/0yiMiEp47OjqYPCZjU2OdQb31BggNfc69ew+VDkNR5SuUpW//rmzbupsrl68rHc4nexb2HIARE2ZgbW3N7IkjGNCzM4eOnaLHgJHEx8cTGxvH0HHTaNroazzcSykcsWFptfEGe6Rlil3H//bUgvnz59O2bVuGDBmiK/Pz82Pq1KmsWbPG1OF9EjMzDfDuezvHx6ftP4rUUGOdQb31FlDpKw/WbVhC0M1gevUYrHQ4BhETGwtAscIFGDOkLwAVy7nj4GDHoFGTOHbqHBf+vUJ4RAR9u3dUMFLxKdLMGH9wcDDffvutXlmLFi24dOmSQhGlXtjzcAAcHPUv8Um85Of584gkP/O5U2OdQb31VrumzRry27afuXPnHo0atiY09LnSIRmEnW0GADwr689NqVKhHABXrgey5Oe1jPbpg5WlJbGxccT/f+s2Li6OuLg40wZsYPFoDfZIyxRr8Ws0Gr3nefPm5dWrV3ploaGhODh8fl2lgYHBxMbGUsAtr1554vPLlz//scC3qbHOoN56q1mfvl0YM9aHI4dP0rJFV8LD08+Xuzy5cgAQHR2jVx77/z0B/qs2EBMTS+efhib52fotOlHOvSQr5k42fqBGopKL3JTt6q9Vqxb58uXDzc0NKysrpkyZwqpVq7C0tOTs2bP4+vri6empVIipFhUVxaFDJ/D6rj7Tpi/UlTdt2oDQ0DBOnjqvXHBGosY6g3rrrVYdOrZk3PghBGzczo+dvYmJifnwD31G8ufNTc7s2di1/yCtmv/XA/vn4RMAzJ08GitLS72f+evoSRYsW83cSaPI80Uuk8YrUkexxP/HH39w9epVrl27xtWrV3ny5Am3bt0iLi4OS0tLOnXqROHChfH29lYqxE8ywW8Wu39fy9pfF7FixVoqVSqHd//uDBk6Pt1ez67GOoN66602WbNlxm/ScIKD77Jo4c+UKVNcb/vNoNuEPH2mUHSGodFo8O7ZCe8RfniP8KNpo68JCr7DrEUrqVO9MmVLFU/yMzduBgNQ0C2fUa/jN4W03kVvKGlqAZ+YmBgs///b5NWrVylUqFCSIYHUMvUCPgDffluPUSO9KVzIjXv3HrJg4UpmzFxk8jhMSY11hrRRb1Mv4POmatUqsmfP+nS9gE/rts2Zv2DSO7d36zqQNasCTBKLMRfwAThw5AQLl6/hWmAQGR0caFC3Bn1+bIuVlVWSfbfs2MvwCdPTxQI+OZ2TfrFJrXuh/xrsWIaWphK/MSmR+IUwJSUTv1JMmfjTEmMn/rRIEr/hqPNdI4QQQrwlra+4ZyiS+IUQQghI8yvuGUqauY5fCCGEEMYnLX4hhBACuY5fCCGEUBW1XM4niV8IIYRAPS1+GeMXQgghVERa/EIIIQRyOZ8QQgihKtLVL4QQQoh0R1r8QgghBDKrXwghhFAV6eoXQgghRLojLX4hhBACmdUvhBBCqIrcpEcIIYQQ6Y60+IUQQgikq18IIYRQFbXM6pfEL4QQQiBj/EIIIYRIhyTxCyGEECR09RvqkVrx8fHMnj2bqlWrUrp0aTp27EhwcLABaymJXwghhADSRuKfP38+a9euZdy4caxbtw6NRkOXLl2Ijo42WD0l8QshhBBpQHR0NMuWLaN37954enpSpEgRZsyYwaNHj9i7d6/BziOT+4QQQggw6NS+WrVqvXf7/v37k5RduXKFly9fUrFiRV2Zo6MjxYoV49SpUzRo0MAgsakm8cdG31M6BCGEEGmYIfPEhxJ/ch4+fAhA9uzZ9cqzZs3KgwcPDBIXqCjxCyGEEKaSXIv+Q16/fg2AlZWVXrm1tTXPnz83SFwgY/xCCCFEmmBjYwOQZCJfVFQUGTJkMNh5JPELIYQQaUBiF//jx4/1yh8/foyrq6vBziOJXwghhEgDihQpgr29PSdOnNCVhYeHc+nSJcqVK2ew88gYvxBCCJEGWFlZ0bp1a6ZOnUqmTJnImTMnU6ZMwdXVlTp16hjsPJL4hRBCiDSiT58+xMbGMnz4cCIjI/Hw8MDf3z/JhL9PodGq5XZEQgghhJAxfiGEEEJNJPELIYQQKiKJXwghhFARSfxCCCGEikjiF0IIIVREEr8QQgihIpL4jSQ+Pp7Zs2dTtWpVSpcuTceOHQkODlY6LJOaP38+bdq0UToMowsLC2PkyJFUq1aNsmXL0rJlS06fPq10WEYXEhLCwIEDqVixIu7u7vz444/cuHFD6bBMJigoCHd3dzZt2qR0KEZ37949ChcunOSxYcMGpUMTqSCJ30jmz5/P2rVrGTduHOvWrUOj0dClS5ckN19Ir1asWMHs2bOVDsMk+vfvz4ULF5g+fTobN26kePHidOrUicDAQKVDM6ru3btz584dlixZwsaNG7GxsaF9+/a6O4ylZzExMQwYMIBXr14pHYpJXL16FWtraw4dOsThw4d1j0aNGikdmkgFSfxGEB0dzbJly+jduzeenp4UKVKEGTNm8OjRI/bu3at0eEb16NEjOnfuzKxZs8iXL5/S4RhdcHAwR44cYdSoUZQrV478+fMzbNgwsmXLxvbt25UOz2hCQ0PJlSsXY8eOpWTJkri5udGjRw+ePHnC9evXlQ7P6ObMmYOdnZ3SYZjMtWvXyJcvH1mzZiVLliy6R+Ld5MTnRRK/EVy5coWXL19SsWJFXZmjoyPFihXj1KlTCkZmfP/++y8ZM2Zk69atlC5dWulwjM7Z2ZnFixdTokQJXZlGo0Gr1Rr0/tlpjbOzM9OnT6dgwYIAPH36FH9/f1xdXSlQoIDC0RnXqVOnWLduHZMmTVI6FJO5evVquv+9qoms1W8EDx8+BP67xWKirFmz8uDBAyVCMpmaNWtSs2ZNpcMwGUdHRzw9PfXKdu3axe3bt6lSpYpCUZnWiBEjWL9+PVZWVixYsABbW1ulQzKa8PBwBg0axPDhw5O8v9Oza9eukSVLFn744Qdu3bpFnjx56NGjB1WrVlU6NJEK0uI3gsQxzrdvqmBtbU1UVJQSIQkTOXPmDEOHDqVWrVqq+QLUrl07AgICaNy4MT179uTff/9VOiSjGT16NGXKlFHV2HZ0dDS3bt3ixYsX9O3bl8WLF1OyZEm6dOnCsWPHlA5PpIK0+I0gcdwrOjpabwwsKiqKDBkyKBWWMLJ9+/YxYMAASpcuzfTp05UOx2QSu4DHjh3L+fPnWbVqFX5+fgpHZXhbtmzh9OnTbNu2TelQTMrKyopTp05hYWGha8yUKFGCwMBA/P39qVSpksIRio8lLX4jSOwCfPz4sV7548ePcXV1VSIkYWSrVq2id+/eVKtWjSVLlqT7SU8hISFs376duLg4XZmZmRlubm5J/u7Ti4CAAEJCQqhevTru7u64u7sDMGrUKBo0aKBwdMZla2ubpAezUKFCPHr0SKGIxKeQxG8ERYoUwd7enhMnTujKwsPDuXTpEuXKlVMwMmEMa9asYezYsbRq1YqZM2ca9L7ZadXjx4/x9vbm5MmTurKYmBguXbqEm5ubgpEZz9SpU9m5cydbtmzRPSDh/umLFy9WNjgjunLlCu7u7knWpvjnn39kwt9nSrr6jcDKyorWrVszdepUMmXKRM6cOZkyZQqurq7UqVNH6fCEAQUFBTFhwgTq1KlD165dCQkJ0W2zsbHBwcFBweiMp0iRIlSpUgVfX1/GjRuHo6MjCxcuJDw8nPbt2ysdnlFky5Yt2XIXFxdy5sxp4mhMp1ChQhQsWBBfX19GjRqFs7Mz69ev5/z582zcuFHp8EQqSOI3kj59+hAbG8vw4cOJjIzEw8MDf39/VbQG1WT37t3ExMSwd+/eJGs0eHl5MXHiRIUiMy6NRsPMmTOZNm0affv2JSIignLlyrF69Wpy5MihdHjCgMzMzFi4cCFTp06lb9++hIeHU6xYMZYvX07hwoWVDk+kgkar1WqVDkIIIYQQpiFj/EIIIYSKSOIXQgghVEQSvxBCCKEikviFEEIIFZHEL4QQQqiIJH4hhBBCRSTxCyGEECoiiV+Iz5wsxSGE+BiS+IVQ0KBBgyhcuHCq1np/+PAhXbt25d69ewaP68SJExQuXFjvfhNCiPRBEr8QCnnx4gV79uyhUKFCrF+//qNb7kePHuXAgQPGCU4IkW5J4hdCITt27CAuLo7hw4dz584dDh8+rHRIQggVkMQvhEICAgKoUKECFSpUIF++fKxduzbJPjt27KBJkyaULl2a6tWrM2XKFKKjo9m0aRNDhgwBoFatWgwePBiAmjVr6v6faNOmTRQuXJi7d+/qyvbt28cPP/yAu7s7JUqUoF69eqxatcqItRVCpBWS+IVQQGBgIBcuXMDLywuAJk2a8Oeff/Lo0SPdPmvXrqV///4ULVqUuXPn0rVrV9asWcPo0aOpXr063bt3B2Du3Ln06NEjxec+cOAAPXv2pHjx4syfP585c+aQM2dOxo4dy9mzZw1bUSFEmiO35RVCARs3bsTR0ZHatWsD8N133zFz5kw2bNhAr169iI+PZ86cOdSpU4fx48frfi4qKorNmzdjb29P7ty5AShatCi5cuVK8blv3LjBd999x7Bhw3Rl7u7uVKhQgVOnTlG2bFkD1VIIkRZJ4hfCxGJjY9m6dSu1a9cmKiqKqKgobGxsqFChAhs2bKB79+7cunWLp0+f6r4YJGrfvj3t27f/pPN37twZgFevXnH79m2CgoK4ePEiADExMZ90bCFE2ieJXwgTO3DgAE+fPmXTpk1s2rQpyfY///wTZ2dnAFxcXAx+/mfPnjFq1Cj27duHRqMhT548fPnll4CsCSCEGkjiF8LENm7cSM6cOfHz80uyrU+fPqxduxYfHx8gIUm/KSwsjH///ZcyZcq88/hxcXF6z1+9eqX3fMCAAQQGBrJ8+XLKli2LlZUVr1+/ZsOGDamskRDicyKJXwgTevr0KYcOHaJjx45UqFAhyfb69euzdu1arK2tcXZ2Zv/+/Xz77be67du2bcPPz4/Dhw9jZpZ0bq69vT0PHz7UK3t7wt6ZM2do0aIFFStW1JUdPHgQgPj4+E+qnxAi7ZNZ/UKY0ObNm4mNjaVBgwbJbvfy8iI+Pp4NGzbQu3dvdu/ezejRozly5AirV69m5syZtGzZkkyZMuHo6AjA3r17CQwMBKBGjRqcOnWKhQsXcvz4cSZOnMixY8f0zlGqVCm2bdvGb7/9xokTJ1i4cCGDBw9Go9Hw+vVr474AQgjFSYtfCBPavHkzBQsWpEiRIsluL1WqFPnz5ycgIIADBw5ga2uLv78/GzduJFu2bHTs2JEff/wRgAoVKvDVV18xbdo0jh07xuLFi+natSvPnj1j2bJlxMTEUL16dcaPH6+79A9g4sSJjB07lrFjxwKQN29efH192bp1K6dPnzb+iyCEUJRGK7N5hBBCCNWQrn4hhBBCRSTxCyGEECoiiV8IIYRQEUn8QgghhIpI4hdCCCFURBK/EEIIoSKS+IUQQggVkcQvhBBCqIgkfiGEEEJFJPELIYQQKiKJXwghhFCR/wPGfCexA9JybQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#As the first method of classification we use Support Vector Machine \n",
    "\n",
    "\n",
    "base = \"./\"\n",
    "\n",
    "def SVM_PIPE(txt,test_percentage):\n",
    "    pathsvm = base + \"Feature-Extraction/SVM_PIPE/\"\n",
    "    \n",
    "    if not os.path.exists(pathsvm):\n",
    "        os.makedirs(pathsvm)\n",
    "        \n",
    "    data = pd.read_csv(base + '/Feature-Extraction/'+txt+'.txt',sep=',',header=None)\n",
    "    \n",
    "    # we shuffle it for better performance \n",
    "    # data=shuffle(data, random_state=42)\n",
    "    \n",
    "    s=data.shape\n",
    "    col=[]\n",
    "    #data.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n",
    "     \n",
    "    for x in range(0, s[1]):\n",
    "        if x==0:\n",
    "            col.append(\"NAME\")\n",
    "        elif x ==s[1]-1:\n",
    "            col.append(\"TAG\")\n",
    "        else:\n",
    "            col.append(\"VALOR-\"+str(x))\n",
    "    \n",
    "    #se asigna el vector con los nombres de las columnas creado previamente y se las asignamos a la tabla\n",
    "    data.columns = col\n",
    "    \n",
    "    ##print(data.groupby(['TAG'])['TAG'].count())\n",
    "    vals_to_replace = { '0':'0', '1':'1', '2':'2', '3':'3', '4':'4', '5':'5',\n",
    "                         0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5'}\n",
    "    \n",
    "    data['TAG'] = data['TAG'].map(vals_to_replace)\n",
    "    \n",
    "    #print(data.tail())\n",
    "    \n",
    "    no_col=['NAME','TAG']\n",
    "    #obtener todas las columnas\n",
    "    allValuesName = [x for x in col if x not in no_col]\n",
    "    #se obtienen solo los coefficientes\n",
    "    value=data[allValuesName]\n",
    "    \n",
    "    tags=data[col[-1]] #columna de tags\n",
    "    \n",
    "    data['gender'] = data['NAME'].map(lambda x: 'woman' in x.lower())\n",
    "    \n",
    "    # i added a stratify to the train_test_split to make sure that the train and test sets have the same proportion of class labels as the input data\n",
    "    # its based on gender\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(value,tags,test_size=test_percentage,stratify=data['gender'], random_state=42)\n",
    "    \n",
    "    \n",
    "    \n",
    "    C_range=[0.01, 0.1, 1, 10, 100, 1000]\n",
    "    gamma_range=[1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5]\n",
    "    parameters= [\n",
    "        {\n",
    "            'kernel': ['poly'],\n",
    "            'gamma': [1e-4, 1e-3, 1e-2, 0.1, 0.2, 0.5],\n",
    "            'C': [0.01, 0.1, 1, 10, 100, 1000]\n",
    "        },\n",
    "    ]\n",
    "    # \n",
    "    # sv =GridSearchCV(svm.SVC(decision_function_shape='ovr'), param_grid=parameters,cv=2)\n",
    "    pipe = Pipeline([ ('pca', PCA(0.97)),('svm', svm.SVC())])\n",
    "    pipe.fit(X_train.values,Y_train)\n",
    "    clf = pipe['svm']\n",
    "    # clf.fit(X_train.values,Y_train)\n",
    "    # clf.best_params_ \n",
    "    # scores = clf.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "    # print(\"The best parameters are %s with a score of %0.2f\" % (clf.best_params_, clf.best_score_))\n",
    "    \n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "    # plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot)\n",
    "    # plt.xlabel('Gamma')\n",
    "    # plt.ylabel('C')\n",
    "    # plt.colorbar()\n",
    "    # plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "    # plt.yticks(np.arange(len(C_range)), C_range)\n",
    "    # fig=plt.title('Heat map '+txt+'-'+str(int(test_percentage*100))+'%')\n",
    "    # fig.get_figure().savefig(base + r'Feature-Extraction/SVM_PIPE/Heatmap-'+txt+'-'+str(int(test_percentage*100))+'%.jpg')\n",
    "    # plt.show()\n",
    "    # print(clf.best_params_)#mejor parametro\n",
    "    \n",
    "    # means = clf.cv_results_['mean_test_score']\n",
    "    # stds = clf.cv_results_['std_test_score']\n",
    "    # params = clf.cv_results_['params']\n",
    "    # for m, s, p in zip(means, stds, params):\n",
    "    #     print(\"%0.3f (+/-%0.3f) para %r\"%(m, 2*s, p))\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    target_names=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "    \n",
    "    table=classification_report(Y_test,y_pred, target_names=target_names)\n",
    "    table=str(table)\n",
    "    print(table)\n",
    "    file = open(base +r\"Feature-Extraction/SVM_PIPE/Reports.txt\", \"a+\")\n",
    "    file.write(txt+'-'+str(int(test_percentage*100))+'%\\n\\n')\n",
    "    file.write(table+'\\n')\n",
    "    file.write(\"Accuracy: \"+str(pipe.score(X_test,Y_test)))\n",
    "    mat=confusion_matrix(Y_test, y_pred)\n",
    "    \n",
    "    Matrizconf=sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=True,\n",
    "               xticklabels=target_names, yticklabels= target_names )\n",
    "    \n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    mat=plt.title('Confusion map '+txt+'-'+str(int(test_percentage*100))+'%')\n",
    "    \n",
    "    Matrizconf.get_figure().savefig(base + r'Feature-Extraction/SVM_PIPE/Confusionmap-'+txt+'-'+str(int(test_percentage*100))+'%.png')\n",
    "    print(Y_train.groupby(Y_train).count())#datos de entrenamiento\n",
    "    print(Y_test.groupby(Y_test).count(),collections.Counter(y_pred))#datos de testeo\n",
    "    \n",
    "    joblib.dump(pipe,base +r'Feature-Extraction/SVM_PIPE/modelo_entrenado-'+txt+'-'+str(int(test_percentage*100))+'%.pkl')\n",
    "    \n",
    "    # se llama el modelo\n",
    "    #clf=joblib.load('modelo_entrenado.pkl')\n",
    "    # se toma todo el dataset\n",
    "    print(\"Accuracy: \"+str(pipe.score(X_test,Y_test)))\n",
    "    file.close()\n",
    "# porcentaje_test=[0.30,0.25,0.20]\n",
    "# SVM_PIPE(\"Elliptic-Fourier\",0.2)\n",
    "SVM_PIPE(\"Histogram-of-Oriented-Gradients\" ,0.2)\n",
    "# SVM(\"HOG_EF\" ,0.2)\n",
    "# SVM(\"Cof\" ,0.2)\n",
    "# SVM(\"VHIST\" ,0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#As Tecer method of classification we use Neural Networks\n",
    "def TRY_classifiers(txt,test):\n",
    "\n",
    "    pathnn = base + r\"Feature-Extraction/RNDMFOREST\"\n",
    "    if not os.path.exists(pathnn):\n",
    "        os.makedirs(pathnn)\n",
    "\n",
    "    data = pd.read_csv(base +'Feature-Extraction/'+txt+'.txt',sep=',',header=None)\n",
    "    data=shuffle(data, random_state=0)\n",
    "\n",
    "    s=data.shape# tamao de dataframe\n",
    "    col=[]\n",
    "    #data.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n",
    "\n",
    "    for x in range(0, s[1]):\n",
    "        if x==0:\n",
    "            col.append(\"NAME\")\n",
    "        elif x ==s[1]-1:\n",
    "            col.append(\"TAG\")\n",
    "        else:\n",
    "            col.append(\"VALOR-\"+str(x))\n",
    "\n",
    "    #se asigna el vector con los nombres de las columnas creado previamente y se las asignamos a la tabla\n",
    "    data.columns = col\n",
    "\n",
    "    ##print(data.groupby(['TAG'])['TAG'].count())\n",
    "    vals_to_replace = { '0':'0', '1':'1', '2':'2', '3':'3', '4':'4', '5':'5',\n",
    "                         0:'0', 1:'1', 2:'2', 3:'3', 4:'4', 5:'5'}\n",
    "\n",
    "    data['TAG'] = data['TAG'].map(vals_to_replace)\n",
    "\n",
    "    #print(data.tail())\n",
    "\n",
    "    no_col=['NAME','TAG']\n",
    "    #obtener todas las columnas\n",
    "    Name_value = [x for x in col if x not in no_col]\n",
    "    #se obtienen solo los coefficientes\n",
    "    value=data[Name_value]\n",
    "\n",
    "    tags=data[col[-1]] #columna de tags\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(value,tags,test_size=test, random_state=0)\n",
    "\n",
    "    # try different classifiers\n",
    "    classfiers = [RandomForestClassifier(), GaussianNB(),svm.SVC(kernel='rbf'), svm.SVC(kernel='poly'),KNeighborsClassifier(),Pipeline(steps=[('scaler', StandardScaler()), ('SVC', SGDClassifier(loss=\"hinge\", penalty=\"l2\"))])]\n",
    "    names = [\"Random Forest\", \"Naive Bayes\",\"SVM-RBF\",\"SVM-POLY\",\"KNN\",\"SGDClassifier\"]\n",
    "    for clf in classfiers:\n",
    "        clf.fit(X_train, Y_train)\n",
    "        print(\"Classifier: \"+str(names[classfiers.index(clf)]))\n",
    "        print(\"Accuracy: \"+str(clf.score(X_test,Y_test)))\n",
    "        \n",
    "    \n",
    "\n",
    "# porcentaje_test=[0.30,0.25,0.20]\n",
    "# NN(\"Elliptic-Fourier\",porcentaje_test[1])\n",
    "TRY_classifiers(\"Histogram-of-Oriented-Gradients-PCA\",0.2)\n",
    "# RandomForest(\"Elliptic-Fourier\",0.2)\n",
    "# RandomForest(\"pca\",0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DzVv387QRs8",
    "outputId": "7e4f535d-ded1-4844-dbd5-96c8f611683c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Preprocessing\n",
    "    # ImageSegmentation()\n",
    "    #Feature Extraction\n",
    "    # EllipticFourier()\n",
    "    # HOG()\n",
    "    # HU()\n",
    "    # GM()\n",
    "    # CoF()\n",
    "    porcentaje_test=[0.30,0.25,0.20]\n",
    "    #Classification\n",
    "    for j in tqdm(range(len(porcentaje_test))):\n",
    "        #Support Vector Machine\n",
    "        # SVM(\"Elliptic-Fourier\",porcentaje_test[j])\n",
    "        # SVM(\"Histogram-of-Oriented-Gradients-PCA\",porcentaje_test[j])\n",
    "        # SVM(\"Hu-Moments-Nmz\",porcentaje_test[j])\n",
    "        # SVM(\"Geometric\",porcentaje_test[j])\n",
    "        SVM(\"CoF\",porcentaje_test[j])\n",
    "        # SVM(\"HOG_EF\",porcentaje_test[j])\n",
    "        #K-Nearest Neighbors\n",
    "        # KNN(\"Elliptic-Fourier\",porcentaje_test[j])\n",
    "        # KNN(\"Histogram-of-Oriented-Gradients-PCA\",porcentaje_test[j])\n",
    "        # KNN(\"Hu-Moments-Nmz\",porcentaje_test[j])\n",
    "        # KNN(\"Geometric\",porcentaje_test[j])\n",
    "        KNN(\"CoF\",porcentaje_test[j])\n",
    "        # KNN(\"HOG_EF\",porcentaje_test[j])\n",
    "        #Neural Network\n",
    "        # NN(\"Elliptic-Fourier\",porcentaje_test[j])\n",
    "        # NN(\"Histogram-of-Oriented-Gradients-PCA\",porcentaje_test[j])\n",
    "        # NN(\"Hu-Moments-Nmz\",porcentaje_test[j])\n",
    "        # NN(\"Geometric\",porcentaje_test[j])\n",
    "        NN(\"CoF\",porcentaje_test[j])\n",
    "        # NN(\"HOG_EF\",porcentaje_test[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJ55xNeTosdj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !rm -rf /content/kaggle/Feature-Extraction\\KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EsYyYScwQRs8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion\n",
    "1. With this method for the recognition of Colombian sign language can be tried with new signs extending the dataset, also is open research because it can be tested with new methods of preprocessing, extraction of characteristics, classification being able to get to raise even more the percentages of prediction.\n",
    "\n",
    "2. According to the methods used for the extraction of characteristics, based on table 2, the characteristics of the gradient-oriented histograms (HOG) are the ones that obtained the highest percentage.\n",
    "\n",
    "3. When performing the main component analysis process, it is concluded that this process will reduce the percentage of the model's performance measure slightly.\n",
    "\n",
    "4. The geometric characteristics did not give a good result because the images contain similar characteristics such as the area or contour, this results in the model being able to predict the signs in a bad way."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
